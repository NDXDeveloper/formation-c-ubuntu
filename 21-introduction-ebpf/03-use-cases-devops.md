ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 21.3 Use Cases DevOps et ObservabilitÃ©

## Introduction

Maintenant que vous comprenez ce qu'est eBPF, son architecture, et sa toolchain, il est temps de dÃ©couvrir **pourquoi eBPF est devenu incontournable dans le monde DevOps moderne**. Cette section explore les cas d'usage concrets qui ont fait d'eBPF une technologie rÃ©volutionnaire, dÃ©ployÃ©e en production par des gÃ©ants comme Google, Facebook, Netflix, et des milliers d'entreprises Ã  travers le monde.

---

## Le dÃ©fi de l'observabilitÃ© moderne

### L'Ã©volution des infrastructures

Les infrastructures modernes ont radicalement changÃ© en 20 ans :

**AnnÃ©es 2000 : L'Ã¨re monolithique**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Serveur physique     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Application    â”‚  â”‚
â”‚   â”‚  monolithique   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Quelques serveurs physiques
- Applications monolithiques
- Infrastructure statique
- Outils de monitoring simples (Nagios, MRTG)

**AnnÃ©es 2010 : La virtualisation**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Hyperviseur (VMware, KVM)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   VM 1   â”‚   VM 2   â”‚    VM 3       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”  â”‚   â”Œâ”€â”€â”€â”€â”      â”‚
â”‚  â”‚App â”‚  â”‚  â”‚App â”‚  â”‚   â”‚App â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”˜  â”‚   â””â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Virtualisation massive
- Infrastructure as Code (Terraform)
- Monitoring plus complexe (Prometheus, Grafana)

**AnnÃ©es 2020 : Cloud-native et Kubernetes**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Cluster Kubernetes                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚Pod 1â”‚  â”‚Pod 2â”‚  â”‚Pod 3â”‚  â”‚Pod Nâ”‚  â”‚Pods â”‚  ...     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                       â”‚
â”‚  â€¢ Microservices (10-100 services)                    â”‚
â”‚  â€¢ Conteneurs Ã©phÃ©mÃ¨res (durÃ©e de vie : minutes)      â”‚
â”‚  â€¢ Infrastructure dynamique (auto-scaling)            â”‚
â”‚  â€¢ Communication inter-services complexe              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Les dÃ©fis de l'observabilitÃ© moderne

Cette Ã©volution apporte des **dÃ©fis inÃ©dits** :

| DÃ©fi | Description | Impact |
|------|-------------|--------|
| **Ã‰chelle** | Milliers de conteneurs, millions de connexions | Outils traditionnels saturent |
| **Ã‰phÃ©mÃ©ritÃ©** | Conteneurs qui vivent quelques minutes | Impossible de debugger post-mortem |
| **ComplexitÃ©** | RequÃªte traverse 10+ microservices | Difficile d'identifier le bottleneck |
| **Performance** | Ajouter de l'observabilitÃ© ralentit le systÃ¨me | Overhead de 10-50% inacceptable |
| **CoÃ»t** | Logs, mÃ©triques, traces gÃ©nÃ¨rent des PB de donnÃ©es | CoÃ»ts de stockage et processing explosifs |

**Exemple concret :**

```
RequÃªte HTTP simple dans un systÃ¨me microservices :

Client â†’ API Gateway â†’ Auth Service â†’ User Service â†’ Database
                     â†’ Cache Service
                     â†’ Logging Service
                     â†’ Metrics Service

Question : Pourquoi cette requÃªte prend 2 secondes au lieu de 200ms ?

Avec outils traditionnels :
- Logs dispersÃ©s dans 7 services diffÃ©rents
- CorrÃ©lation manuelle (trace ID)
- Overhead de logging : 15% CPU
- Analyse : 1-2 heures
- CoÃ»t : $$$

Besoin : VisibilitÃ© complÃ¨te, temps rÃ©el, sans overhead
```

---

## Les trois piliers de l'observabilitÃ©

L'observabilitÃ© moderne repose traditionnellement sur **trois piliers** :

### 1. Les MÃ©triques (Metrics)

**DÃ©finition :** Valeurs numÃ©riques agrÃ©gÃ©es dans le temps.

**Exemples :**
- CPU usage : 45%
- MÃ©moire utilisÃ©e : 2.3 GB
- RequÃªtes/seconde : 1250
- Latence P99 : 150 ms

**Outils classiques :**
- Prometheus
- Grafana
- StatsD

**Limitations :**
- âŒ Pas de dÃ©tails sur les Ã©vÃ©nements individuels
- âŒ Ne rÃ©pond pas au "pourquoi"
- âŒ RÃ©solution temporelle limitÃ©e

### 2. Les Logs

**DÃ©finition :** Ã‰vÃ©nements textuels horodatÃ©s.

**Exemples :**
```
[2024-11-27 10:45:23] INFO: User login successful, user_id=12345
[2024-11-27 10:45:24] ERROR: Database connection timeout
[2024-11-27 10:45:25] WARN: High memory usage detected
```

**Outils classiques :**
- ELK Stack (Elasticsearch, Logstash, Kibana)
- Splunk
- Loki

**Limitations :**
- âŒ Volume massif (TB/jour)
- âŒ CoÃ»teux Ã  stocker et analyser
- âŒ Difficile de corrÃ©ler entre services
- âŒ Overhead de production (I/O)

### 3. Les Traces (Distributed Tracing)

**DÃ©finition :** Suivi d'une requÃªte Ã  travers plusieurs services.

**Exemple :**
```
TraceID: abc123
â”œâ”€ [API Gateway]     10ms
â”œâ”€ [Auth Service]    45ms
â”‚  â””â”€ [DB Query]     40ms
â”œâ”€ [User Service]    120ms
â”‚  â”œâ”€ [Cache Lookup] 2ms
â”‚  â””â”€ [DB Query]     115ms  â† BOTTLENECK !
â””â”€ [Response]        5ms

Total: 180ms
```

**Outils classiques :**
- Jaeger
- Zipkin
- OpenTelemetry

**Limitations :**
- âŒ NÃ©cessite **instrumentation du code** (ajouter du code de tracing)
- âŒ Overhead non nÃ©gligeable (5-15%)
- âŒ Sampling requis (traces 1% des requÃªtes)
- âŒ Complexe Ã  configurer

---

## eBPF : Le quatriÃ¨me pilier de l'observabilitÃ©

eBPF introduit une nouvelle dimension : **l'observabilitÃ© au niveau kernel, sans instrumentation**.

### Ce qui rend eBPF unique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Applications                            â”‚
â”‚   (Node.js, Go, Python, Java, C, etc.)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    Pas besoin d'instrumenter !      â”‚
       â”‚    eBPF observe depuis le kernel    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kernel Linux                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              eBPF Programs                           â”‚  â”‚
â”‚  â”‚  â€¢ Capture TOUS les Ã©vÃ©nements systÃ¨me               â”‚  â”‚
â”‚  â”‚  â€¢ Syscalls, network, I/O, scheduler                 â”‚  â”‚
â”‚  â”‚  â€¢ Overhead < 1%                                     â”‚  â”‚
â”‚  â”‚  â€¢ PrÃ©cision : nanoseconde                           â”‚  â”‚
â”‚  â”‚  â€¢ AgrÃ©gation dans le kernel (efficace)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Avantages rÃ©volutionnaires

| Aspect | Approche traditionnelle | eBPF |
|--------|------------------------|------|
| **Instrumentation** | Modifier le code source | Aucune modification nÃ©cessaire |
| **Overhead** | 5-50% | < 1% |
| **DÃ©ploiement** | RedÃ©ployer l'application | Charger un programme eBPF |
| **Langages** | DÃ©pend du SDK (OpenTelemetry) | Tous (observe au niveau kernel) |
| **VisibilitÃ©** | Application uniquement | Application + Kernel + Hardware |
| **GranularitÃ©** | Milliseconde | Nanoseconde |
| **Production** | Sampling requis | Monitoring continu 24/7 |
| **CoÃ»t** | Ã‰levÃ© (logs, stockage) | Faible (agrÃ©gation kernel) |

---

## Les quatre domaines clÃ©s pour DevOps

eBPF rÃ©volutionne l'observabilitÃ© dans **quatre domaines critiques** pour les ingÃ©nieurs DevOps :

### 1. **Tracing et Monitoring** (Section 21.3.1)

**ProblÃ©matique :**
> "Mon application est lente, mais je ne sais pas pourquoi."

**Ce qu'eBPF apporte :**
- Tracer **tous les appels systÃ¨me** en temps rÃ©el
- Observer le comportement du kernel
- DÃ©tecter les anomalies comportementales
- Profiler en production sans ralentir

**Cas d'usage :**
- Debugging de performance
- DÃ©tection d'erreurs intermittentes
- Analyse de comportement applicatif
- ObservabilitÃ© complÃ¨te sans agent

**Outils clÃ©s :**
- bpftrace (tracing ad-hoc)
- BCC (outils de monitoring)
- Pixie (observabilitÃ© automatique K8s)

### 2. **Networking** (Section 21.3.2)

**ProblÃ©matique :**
> "Mon cluster Kubernetes avec iptables a des latences inacceptables."

**Ce qu'eBPF apporte :**
- Performances **10-100x supÃ©rieures** Ã  iptables
- Load balancing ultra-rapide (< 1 Âµs)
- Politiques rÃ©seau L7 (HTTP, gRPC)
- ObservabilitÃ© rÃ©seau complÃ¨te

**Cas d'usage :**
- Remplacement d'iptables (Cilium)
- Load balancing haute performance (Katran)
- Service Mesh sans sidecar
- Protection DDoS
- ObservabilitÃ© rÃ©seau temps rÃ©el

**Impact :**
- Latence rÃ©seau rÃ©duite de 90%
- ScalabilitÃ© accrue (milliers de services)
- Ã‰conomies d'infrastructure (CPU, RAM)

### 3. **SÃ©curitÃ©** (Section 21.3.3)

**ProblÃ©matique :**
> "Comment dÃ©tecter une attaque en cours AVANT qu'elle ne cause des dÃ©gÃ¢ts ?"

**Ce qu'eBPF apporte :**
- **Runtime security** : dÃ©tection en temps rÃ©el
- Blocage proactif (avant l'exÃ©cution)
- DÃ©tection comportementale (0-days)
- VisibilitÃ© complÃ¨te dans les conteneurs

**Cas d'usage :**
- DÃ©tection de reverse shells, cryptominers
- PrÃ©vention d'escalade de privilÃ¨ges
- DÃ©tection de mouvement latÃ©ral
- Audit de conformitÃ© (PCI-DSS, SOC 2)
- Protection contre les rootkits

**Outils clÃ©s :**
- Falco (dÃ©tection de menaces)
- Tetragon (enforcement)
- Tracee (forensics)

**Avantages :**
- DÃ©tection < 1 seconde (vs 197 jours traditionnellement)
- Blocage avant impact
- Pas de faux positifs (contexte riche)

### 4. **Performance Analysis** (Section 21.3.4)

**ProblÃ©matique :**
> "Mon API est lente, mais je ne peux pas profiler en production (trop d'overhead)."

**Ce qu'eBPF apporte :**
- Profiling continu en production (< 1% overhead)
- Flamegraphs CPU et Off-CPU
- Analyse de latence I/O
- DÃ©tection de fuites mÃ©moire

**Cas d'usage :**
- Identification de hotspots CPU
- Analyse des temps d'attente (I/O, locks)
- Profiling mÃ©moire (allocations, fuites)
- DÃ©tection de rÃ©gressions de performance
- Optimisation basÃ©e sur des donnÃ©es rÃ©elles

**Impact :**
- MTTR rÃ©duit de 4-5h Ã  5-10 minutes
- Optimisations guidÃ©es par les donnÃ©es
- DÃ©tection proactive de problÃ¨mes

---

## Pourquoi eBPF est essentiel pour DevOps en 2025

### 1. **Cloud-native et Kubernetes**

Kubernetes a adoptÃ© massivement eBPF :

| Cloud Provider | Adoption eBPF |
|----------------|---------------|
| **Google GKE** | Cilium disponible comme CNI |
| **AWS EKS** | Support natif Cilium |
| **Azure AKS** | Cilium en option |
| **DigitalOcean** | Cilium par dÃ©faut |

**Raison :** eBPF rÃ©sout les problÃ¨mes de performance et scalabilitÃ© d'iptables.

### 2. **Shift-left Security**

La sÃ©curitÃ© se dÃ©place "Ã  gauche" (plus tÃ´t dans le cycle) :

```
Avant :
  Dev â†’ Build â†’ Test â†’ Deploy â†’ [SÃ©curitÃ© aprÃ¨s coup]

Maintenant :
  Dev â†’ [SÃ©curitÃ© dÃ¨s le dev] â†’ Build â†’ Test â†’ Deploy
              â†‘
          eBPF permet la sÃ©curitÃ© runtime dÃ¨s le dÃ©but
```

### 3. **FinOps : Optimisation des coÃ»ts cloud**

eBPF permet d'identifier les gaspillages :

**Exemple :**
- DÃ©tection de conteneurs qui font trop d'allocations mÃ©moire
- Identification de pods qui font trop d'I/O disque
- Optimisation des requÃªtes rÃ©seau inutiles

**Impact financier :** Ã‰conomies de 15-30% sur les coÃ»ts cloud.

### 4. **ObservabilitÃ© unifiÃ©e**

eBPF offre une **seule plateforme** pour :
- Metrics (via BPF maps)
- Logs (via tracepoints)
- Traces (via kprobes/uprobes)
- Profiling (via sampling)
- Security (via LSM hooks)

**Avantage :** RÃ©duction du nombre d'outils Ã  maintenir.

---

## Ã‰cosystÃ¨me eBPF pour DevOps

### Outils par catÃ©gorie

**ObservabilitÃ© :**
- **Cilium Hubble** : ObservabilitÃ© rÃ©seau Kubernetes
- **Pixie** : ObservabilitÃ© automatique (HTTP, SQL, DNS)
- **Parca** : Profiling continu
- **Pyroscope** : Continuous profiling platform

**SÃ©curitÃ© :**
- **Falco** : DÃ©tection de menaces runtime
- **Tetragon** : Policy enforcement
- **Tracee** : Security observability
- **KubeArmor** : Container security

**Networking :**
- **Cilium** : CNI Kubernetes moderne
- **Katran** : Load balancer L4
- **bpfilter** : Remplacement d'iptables

**Profiling :**
- **BCC** : Collection d'outils de profiling
- **bpftrace** : Langage de scripting
- **perf + eBPF** : Profiling systÃ¨me

### IntÃ©grations avec l'Ã©cosystÃ¨me existant

eBPF s'intÃ¨gre avec les outils DevOps populaires :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          eBPF Data Collection               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                   â”‚
      â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Prometheusâ”‚      â”‚ OpenTelemetryâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                   â”‚
     â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Grafana  â”‚      â”‚    Jaeger    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Adoption d'eBPF : TÃ©moignages d'entreprises

### Netflix

> "eBPF nous permet de profiler en production des millions de serveurs avec < 1% d'overhead. Nous avons identifiÃ© et corrigÃ© des problÃ¨mes de performance qui nous ont fait Ã©conomiser 30% de nos coÃ»ts cloud."

**Usage :** Profiling continu, dÃ©tection de cryptominers, optimisation rÃ©seau.

### Google

> "Cilium (basÃ© sur eBPF) remplace iptables dans GKE, offrant 10x meilleures performances et une observabilitÃ© native."

**Usage :** Networking Kubernetes, observabilitÃ©, sÃ©curitÃ©.

### Capital One

> "Falco (eBPF) a dÃ©tectÃ© plusieurs tentatives d'intrusion dans nos clusters Kubernetes avant qu'elles ne causent des dÃ©gÃ¢ts."

**Usage :** Runtime security, dÃ©tection d'anomalies.

### Shopify

> "eBPF nous permet de dÃ©tecter des images Docker compromises avant leur dÃ©ploiement en production."

**Usage :** Supply chain security, scanning comportemental.

---

## Par oÃ¹ commencer ?

### Pour les dÃ©butants DevOps

**Ã‰tape 1 : Comprendre les concepts**
- Lire les sections 21.1 et 21.2 (introduction eBPF)
- Comprendre ce qu'eBPF peut faire

**Ã‰tape 2 : Outils haut niveau**
- Installer bpftrace pour du tracing simple
- Utiliser les outils BCC prÃªts Ã  l'emploi (profile, biolatency, tcplife)
- DÃ©ployer Falco dans un cluster K8s test

**Ã‰tape 3 : Cas d'usage spÃ©cifiques**
- Choisir UN domaine (tracing, networking, security, ou performance)
- Approfondir avec les sections 21.3.1 Ã  21.3.4
- Appliquer sur un projet rÃ©el

**Ã‰tape 4 : Production**
- DÃ©ployer Cilium pour le networking Kubernetes
- Activer le profiling continu (Parca/Pyroscope)
- ImplÃ©menter Falco/Tetragon pour la sÃ©curitÃ©

### Pour les experts systÃ¨me

**Approche avancÃ©e :**
- Ã‰crire des programmes eBPF custom en C
- IntÃ©grer eBPF dans vos outils existants
- Contribuer Ã  l'Ã©cosystÃ¨me open-source

---

## Structure des sections suivantes

Dans les quatre sous-sections Ã  venir, nous explorerons en dÃ©tail :

### **21.3.1 Tracing et Monitoring**
- Comment tracer les appels systÃ¨me
- Observer le comportement du kernel
- DÃ©tecter les anomalies comportementales
- Outils : bpftrace, BCC, Pixie

### **21.3.2 Networking**
- Remplacer iptables avec eBPF
- Load balancing haute performance
- Service Mesh sans sidecar
- ObservabilitÃ© rÃ©seau L7
- Outils : Cilium, Katran, Hubble

### **21.3.3 SÃ©curitÃ©**
- Runtime security et dÃ©tection de menaces
- Blocage proactif d'attaques
- DÃ©tection de 0-days
- ConformitÃ© et audit
- Outils : Falco, Tetragon, Tracee

### **21.3.4 Performance Analysis**
- CPU profiling et flamegraphs
- Off-CPU profiling (temps d'attente)
- Memory profiling et fuites
- I/O profiling (disque, rÃ©seau)
- Outils : BCC, bpftrace, Parca, Pyroscope

---

## Conclusion de l'introduction

eBPF n'est pas juste une technologie de plus dans la boÃ®te Ã  outils DevOps : c'est une **transformation fondamentale** de la faÃ§on dont nous observons, sÃ©curisons, et optimisons les systÃ¨mes Linux modernes.

**Les points clÃ©s Ã  retenir :**

- âœ… eBPF offre une **observabilitÃ© complÃ¨te** sans instrumentation
- âœ… **Overhead nÃ©gligeable** (< 1%) permet le monitoring continu en production
- âœ… **Quatre domaines rÃ©volutionnÃ©s** : tracing, networking, sÃ©curitÃ©, performance
- âœ… **Adoption massive** : Google, Netflix, Facebook, et des milliers d'entreprises
- âœ… **Ã‰cosystÃ¨me riche** : outils open-source matures et actifs
- âœ… **Futur de l'infrastructure cloud** : Kubernetes, sÃ©curitÃ©, observabilitÃ©

Dans les sections suivantes, nous allons plonger en profondeur dans chacun de ces quatre domaines, avec des exemples concrets, des cas d'usage rÃ©els, et les outils que vous pouvez utiliser dÃ¨s aujourd'hui.

**PrÃªt Ã  dÃ©couvrir comment eBPF transforme le DevOps ?** CommenÃ§ons par le tracing et monitoring (section 21.3.1).

---

â­ï¸ [Tracing et monitoring](/21-introduction-ebpf/03.1-tracing-monitoring.md)
