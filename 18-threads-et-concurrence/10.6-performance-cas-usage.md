üîù Retour au [Sommaire](/SOMMAIRE.md)

# 18.10.6 Performance et cas d'usage

## Introduction

Maintenant que nous avons explor√© les concepts fondamentaux des op√©rations atomiques, il est temps de voir **comment les utiliser efficacement dans des situations r√©elles**. Cette section se concentre sur :

1. Les **performances** : Mesurer, comprendre, optimiser
2. Les **cas d'usage pratiques** : O√π les atomiques brillent vraiment
3. Les **patterns √©prouv√©s** : Solutions test√©es en production
4. Les **pi√®ges de performance** : Ce qui peut mal tourner

---

## Comprendre les performances des atomiques

### Le co√ªt des op√©rations atomiques

Toutes les op√©rations atomiques n'ont pas le m√™me co√ªt. Voici une hi√©rarchie approximative :

```
OP√âRATION                           CO√õT RELATIF
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Lecture/√©criture non-atomique       1x (baseline)
atomic_load (relaxed)               1-2x
atomic_store (relaxed)              1-2x
atomic_load (acquire)               2-3x
atomic_store (release)              2-3x
atomic_fetch_add (relaxed)          2-4x
atomic_fetch_add (seq_cst)          4-6x
atomic_compare_exchange_weak        5-10x
atomic_compare_exchange_strong      5-10x
Mutex lock/unlock                   50-200x
```

**Note** : Ces chiffres sont approximatifs et varient selon l'architecture (x86, ARM, etc.).

### Facteurs affectant les performances

#### 1. L'architecture du processeur

**x86/x64** :
- Strong memory model (coh√©rence forte)
- Beaucoup d'op√©rations atomiques sont "gratuites"
- `seq_cst` peu co√ªteux compar√© √† ARM

**ARM** :
- Weak memory model (coh√©rence faible)
- N√©cessite plus de barri√®res m√©moire explicites
- Diff√©rence plus marqu√©e entre relaxed et seq_cst

**Exemple de diff√©rence** :

```c
atomic_int counter = 0;

// Sur x86 : ~0.02s
// Sur ARM : ~0.05s
for (int i = 0; i < 1000000; i++) {
    atomic_fetch_add(&counter, 1);
}
```

#### 2. Le memory ordering

```c
atomic_int x = 0;

// Rapide (minimal barriers)
atomic_store_explicit(&x, 42, memory_order_relaxed);

// Moyen (acquire/release barriers)
atomic_store_explicit(&x, 42, memory_order_release);

// Lent (full barriers)
atomic_store_explicit(&x, 42, memory_order_seq_cst);
```

**Impact mesur√©** sur x86-64 (1M op√©rations) :
- `relaxed` : 0.015s
- `release` : 0.020s
- `seq_cst` : 0.025s

#### 3. La contention (cache bouncing)

Quand plusieurs threads modifient la m√™me variable atomique :

```c
// UNE variable atomique partag√©e par 4 threads
atomic_int compteur_partage = 0;

void* worker(void* arg) {
    for (int i = 0; i < 1000000; i++) {
        atomic_fetch_add(&compteur_partage, 1);
        // Cache line bounce entre les c≈ìurs !
    }
    return NULL;
}
```

**Probl√®me** : La cache line contenant `compteur_partage` rebondit constamment entre les c≈ìurs CPU (cache bouncing), d√©gradant les performances.

**Solution** : Thread-local counters

```c
// UN compteur par thread (pas de contention)
_Thread_local atomic_int compteur_local = 0;
atomic_int compteur_global = 0;

void* worker(void* arg) {
    for (int i = 0; i < 1000000; i++) {
        atomic_fetch_add(&compteur_local, 1);  // Rapide, local
    }

    // Ajouter au global √† la fin seulement
    atomic_fetch_add(&compteur_global, atomic_load(&compteur_local));
    return NULL;
}
```

**Gain** : 10-20x plus rapide !

#### 4. Le false sharing

Quand des variables atomiques ind√©pendantes partagent la m√™me cache line :

```c
// ‚ö†Ô∏è PROBL√àME : false sharing
struct {
    atomic_int counter1;  // Octets 0-3
    atomic_int counter2;  // Octets 4-7
    // Les deux sont dans la M√äME cache line (64 bytes)
} stats;

// Thread 1 modifie counter1
// Thread 2 modifie counter2
// ‚Üí Cache line invalidations constantes !
```

**Solution** : Padding pour s√©parer les cache lines

```c
// ‚úÖ BON : s√©paration des cache lines
#define CACHE_LINE_SIZE 64

struct {
    atomic_int counter1;
    char padding1[CACHE_LINE_SIZE - sizeof(atomic_int)];

    atomic_int counter2;
    char padding2[CACHE_LINE_SIZE - sizeof(atomic_int)];
} stats;

// Maintenant counter1 et counter2 sont sur des cache lines diff√©rentes
```

---

## Benchmark : Mesurer les performances

### Outil simple de benchmarking

```c
#include <stdio.h>
#include <stdatomic.h>
#include <pthread.h>
#include <time.h>

#define NB_THREADS 4
#define NB_OPS 1000000

typedef struct {
    double temps_sec;
    long ops_par_sec;
} resultat_bench_t;

resultat_bench_t benchmark(void* (*fonction)(void*), void* arg) {
    pthread_t threads[NB_THREADS];
    struct timespec debut, fin;

    clock_gettime(CLOCK_MONOTONIC, &debut);

    for (int i = 0; i < NB_THREADS; i++) {
        pthread_create(&threads[i], NULL, fonction, arg);
    }

    for (int i = 0; i < NB_THREADS; i++) {
        pthread_join(threads[i], NULL);
    }

    clock_gettime(CLOCK_MONOTONIC, &fin);

    double temps = (fin.tv_sec - debut.tv_sec) +
                   (fin.tv_nsec - debut.tv_nsec) / 1e9;

    long total_ops = NB_THREADS * NB_OPS;

    resultat_bench_t res = {
        .temps_sec = temps,
        .ops_par_sec = (long)(total_ops / temps)
    };

    return res;
}
```

### Comparer diff√©rentes approches

```c
atomic_int counter_relaxed = 0;
atomic_int counter_seq_cst = 0;
pthread_mutex_t mutex_lock = PTHREAD_MUTEX_INITIALIZER;
int counter_mutex = 0;

void* bench_relaxed(void* arg) {
    for (int i = 0; i < NB_OPS; i++) {
        atomic_fetch_add_explicit(&counter_relaxed, 1, memory_order_relaxed);
    }
    return NULL;
}

void* bench_seq_cst(void* arg) {
    for (int i = 0; i < NB_OPS; i++) {
        atomic_fetch_add(&counter_seq_cst, 1);  // seq_cst par d√©faut
    }
    return NULL;
}

void* bench_mutex(void* arg) {
    for (int i = 0; i < NB_OPS; i++) {
        pthread_mutex_lock(&mutex_lock);
        counter_mutex++;
        pthread_mutex_unlock(&mutex_lock);
    }
    return NULL;
}

int main(void) {
    printf("=== Benchmark des m√©thodes de comptage ===\n\n");

    resultat_bench_t r1 = benchmark(bench_relaxed, NULL);
    printf("Atomique relaxed:  %.3f sec  (%ld ops/sec)\n",
           r1.temps_sec, r1.ops_par_sec);

    resultat_bench_t r2 = benchmark(bench_seq_cst, NULL);
    printf("Atomique seq_cst:  %.3f sec  (%ld ops/sec)\n",
           r2.temps_sec, r2.ops_par_sec);

    resultat_bench_t r3 = benchmark(bench_mutex, NULL);
    printf("Mutex:             %.3f sec  (%ld ops/sec)\n",
           r3.temps_sec, r3.ops_par_sec);

    printf("\nSpeedup relaxed/mutex: %.1fx\n",
           (double)r1.ops_par_sec / r3.ops_par_sec);

    return 0;
}
```

**R√©sultats typiques** (x86-64, 4 cores) :

```
=== Benchmark des m√©thodes de comptage ===

Atomique relaxed:  0.025 sec  (160,000,000 ops/sec)
Atomique seq_cst:  0.035 sec  (114,000,000 ops/sec)
Mutex:             0.420 sec  (9,500,000 ops/sec)

Speedup relaxed/mutex: 16.8x
```

---

## Cas d'usage r√©els

### 1. Compteurs de m√©triques

**Contexte** : Application web qui traite des milliers de requ√™tes/seconde et doit tracker des statistiques.

```c
#include <stdatomic.h>
#include <time.h>

typedef struct {
    atomic_ulong total_requetes;
    atomic_ulong requetes_succes;
    atomic_ulong requetes_erreur;
    atomic_ulong bytes_recus;
    atomic_ulong bytes_envoyes;
    _Atomic(time_t) dernier_acces;
} metriques_serveur_t;

metriques_serveur_t metriques = {0};

void traiter_requete(size_t taille_req, size_t taille_resp, bool succes) {
    // Incr√©ment ultra-rapide avec relaxed (pas de synchronisation n√©cessaire)
    atomic_fetch_add_explicit(&metriques.total_requetes, 1,
                              memory_order_relaxed);

    atomic_fetch_add_explicit(&metriques.bytes_recus, taille_req,
                              memory_order_relaxed);

    atomic_fetch_add_explicit(&metriques.bytes_envoyes, taille_resp,
                              memory_order_relaxed);

    if (succes) {
        atomic_fetch_add_explicit(&metriques.requetes_succes, 1,
                                  memory_order_relaxed);
    } else {
        atomic_fetch_add_explicit(&metriques.requetes_erreur, 1,
                                  memory_order_relaxed);
    }

    // Timestamp avec release pour synchroniser
    atomic_store_explicit(&metriques.dernier_acces, time(NULL),
                         memory_order_release);
}

void afficher_stats(void) {
    // Lecture avec acquire
    unsigned long total = atomic_load_explicit(&metriques.total_requetes,
                                               memory_order_acquire);
    unsigned long succes = atomic_load_explicit(&metriques.requetes_succes,
                                                memory_order_acquire);
    unsigned long erreurs = atomic_load_explicit(&metriques.requetes_erreur,
                                                 memory_order_acquire);

    printf("Total: %lu | Succ√®s: %lu (%.1f%%) | Erreurs: %lu (%.1f%%)\n",
           total,
           succes, (double)succes / total * 100,
           erreurs, (double)erreurs / total * 100);
}
```

**Avantages** :
- ‚úÖ Tr√®s rapide (millions d'ops/sec)
- ‚úÖ Pas de contention (relaxed)
- ‚úÖ Thread-safe sans mutex
- ‚úÖ Overhead minimal

---

### 2. Flag d'arr√™t gracieux

**Contexte** : Application avec plusieurs worker threads qui doivent s'arr√™ter proprement.

```c
#include <stdatomic.h>
#include <pthread.h>
#include <signal.h>

atomic_bool should_shutdown = false;

void signal_handler(int sig) {
    printf("Signal %d re√ßu, arr√™t en cours...\n", sig);
    atomic_store(&should_shutdown, true);
}

void* worker_thread(void* arg) {
    int worker_id = *(int*)arg;
    unsigned long operations = 0;

    while (!atomic_load(&should_shutdown)) {
        // Faire du travail
        operations++;

        // Simuler du traitement
        for (volatile int i = 0; i < 1000; i++);
    }

    printf("Worker %d s'arr√™te apr√®s %lu op√©rations\n",
           worker_id, operations);

    return NULL;
}

int main(void) {
    signal(SIGINT, signal_handler);
    signal(SIGTERM, signal_handler);

    pthread_t workers[4];
    int ids[4] = {1, 2, 3, 4};

    for (int i = 0; i < 4; i++) {
        pthread_create(&workers[i], NULL, worker_thread, &ids[i]);
    }

    printf("Workers d√©marr√©s. Appuyez sur Ctrl+C pour arr√™ter.\n");

    for (int i = 0; i < 4; i++) {
        pthread_join(workers[i], NULL);
    }

    printf("Tous les workers se sont arr√™t√©s proprement.\n");
    return 0;
}
```

**Avantages** :
- ‚úÖ Simple et clair
- ‚úÖ Arr√™t rapide et coordonn√©
- ‚úÖ Pas de deadlock possible
- ‚úÖ Pattern standard en production

---

### 3. Cache de configuration hot-reload

**Contexte** : Serveur qui doit pouvoir recharger sa configuration sans red√©marrer.

```c
#include <stdatomic.h>
#include <stdlib.h>
#include <string.h>

typedef struct {
    int max_connections;
    int timeout_sec;
    char log_level[16];
    bool debug_mode;
} configuration_t;

_Atomic(configuration_t*) config_actuelle = NULL;

void initialiser_config(void) {
    configuration_t* cfg = malloc(sizeof(configuration_t));
    cfg->max_connections = 100;
    cfg->timeout_sec = 30;
    strcpy(cfg->log_level, "INFO");
    cfg->debug_mode = false;

    atomic_store(&config_actuelle, cfg);
}

void recharger_config(void) {
    // Charger nouvelle config depuis un fichier
    configuration_t* nouvelle_cfg = malloc(sizeof(configuration_t));
    nouvelle_cfg->max_connections = 200;  // Exemple
    nouvelle_cfg->timeout_sec = 60;
    strcpy(nouvelle_cfg->log_level, "DEBUG");
    nouvelle_cfg->debug_mode = true;

    // Remplacer atomiquement l'ancienne config
    configuration_t* ancienne_cfg = atomic_exchange(&config_actuelle, nouvelle_cfg);

    // Attendre un peu que tous les threads aient vu la nouvelle config
    sleep(1);

    // Lib√©rer l'ancienne config
    free(ancienne_cfg);

    printf("Configuration recharg√©e avec succ√®s\n");
}

void traiter_requete(void) {
    // Lire la config actuelle (atomic)
    configuration_t* cfg = atomic_load(&config_actuelle);

    // Utiliser la config (lecture seule, pas besoin de verrou)
    if (cfg->debug_mode) {
        printf("Debug: traitement avec timeout=%d\n", cfg->timeout_sec);
    }

    // ... traiter avec cfg->max_connections, etc.
}

// Thread de monitoring qui recharge la config p√©riodiquement
void* thread_reload(void* arg) {
    while (1) {
        sleep(60);  // V√©rifier toutes les minutes

        // V√©rifier si le fichier de config a chang√©
        if (config_a_change()) {
            recharger_config();
        }
    }
    return NULL;
}
```

**Avantages** :
- ‚úÖ Hot-reload sans interruption
- ‚úÖ Lectures ultra-rapides (pas de verrou)
- ‚úÖ Coh√©rence garantie (on lit toujours une config compl√®te)

**Note** : En production, utilisez RCU (Read-Copy-Update) ou hazard pointers pour la gestion m√©moire.

---

### 4. Rate limiter (limiteur de d√©bit)

**Contexte** : API qui limite le nombre de requ√™tes par seconde.

```c
#include <stdatomic.h>
#include <time.h>
#include <stdbool.h>

typedef struct {
    atomic_ulong compteur_requetes;
    _Atomic(time_t) derniere_seconde;
    unsigned long limite_par_seconde;
} rate_limiter_t;

void rate_limiter_init(rate_limiter_t* rl, unsigned long limite) {
    atomic_store(&rl->compteur_requetes, 0);
    atomic_store(&rl->derniere_seconde, time(NULL));
    rl->limite_par_seconde = limite;
}

bool rate_limiter_autoriser(rate_limiter_t* rl) {
    time_t maintenant = time(NULL);
    time_t derniere = atomic_load(&rl->derniere_seconde);

    // Nouvelle seconde ? R√©initialiser le compteur
    if (maintenant > derniere) {
        // Essayer de mettre √† jour la seconde avec CAS
        if (atomic_compare_exchange_strong(&rl->derniere_seconde,
                                          &derniere, maintenant)) {
            // Nous avons gagn√© la course, r√©initialiser
            atomic_store(&rl->compteur_requetes, 0);
        }
    }

    // Incr√©menter et v√©rifier la limite
    unsigned long count = atomic_fetch_add(&rl->compteur_requetes, 1);

    if (count < rl->limite_par_seconde) {
        return true;  // Autoris√©
    } else {
        // D√©cr√©menter car on a d√©pass√©
        atomic_fetch_sub(&rl->compteur_requetes, 1);
        return false;  // Rate limit√©
    }
}

// Utilisation
rate_limiter_t limiter;

void initialiser_serveur(void) {
    rate_limiter_init(&limiter, 1000);  // Max 1000 req/sec
}

void traiter_requete_api(void) {
    if (!rate_limiter_autoriser(&limiter)) {
        printf("429 Too Many Requests\n");
        return;
    }

    // Traiter la requ√™te normalement
    printf("200 OK\n");
}
```

**Avantages** :
- ‚úÖ Thread-safe sans mutex
- ‚úÖ Tr√®s rapide (important pour le hot path)
- ‚úÖ Pr√©cision √† la seconde
- ‚úÖ Pattern courant dans les APIs

---

### 5. Pool d'objets (object pool)

**Contexte** : R√©utiliser des objets co√ªteux √† allouer (connexions DB, buffers).

```c
#include <stdatomic.h>
#include <stdlib.h>

#define POOL_SIZE 100

typedef struct {
    void* objets[POOL_SIZE];
    atomic_int disponibles;
    atomic_int index_next;
} pool_objets_t;

void pool_init(pool_objets_t* pool, void* (*create_fn)(void)) {
    for (int i = 0; i < POOL_SIZE; i++) {
        pool->objets[i] = create_fn();
    }
    atomic_store(&pool->disponibles, POOL_SIZE);
    atomic_store(&pool->index_next, 0);
}

void* pool_acquire(pool_objets_t* pool) {
    int dispo = atomic_load(&pool->disponibles);
    if (dispo <= 0) {
        return NULL;  // Pool vide
    }

    // D√©cr√©menter atomiquement
    if (atomic_fetch_sub(&pool->disponibles, 1) <= 0) {
        // Oups, quelqu'un d'autre a pris le dernier
        atomic_fetch_add(&pool->disponibles, 1);
        return NULL;
    }

    // Obtenir un index atomiquement (avec wrap-around)
    int idx = atomic_fetch_add(&pool->index_next, 1) % POOL_SIZE;

    return pool->objets[idx];
}

void pool_release(pool_objets_t* pool, void* obj) {
    // Juste incr√©menter le compteur
    atomic_fetch_add(&pool->disponibles, 1);
    // L'objet reste dans le pool, sera r√©utilis√©
}

// Exemple d'utilisation avec des connexions
typedef struct {
    int socket_fd;
    bool connected;
} connection_t;

void* creer_connection(void) {
    connection_t* conn = malloc(sizeof(connection_t));
    // ... initialiser la connexion ...
    return conn;
}

pool_objets_t pool_connections;

void initialiser_pool(void) {
    pool_init(&pool_connections, creer_connection);
}

void traiter_requete_db(void) {
    connection_t* conn = pool_acquire(&pool_connections);
    if (!conn) {
        printf("Pool satur√©, attendre...\n");
        return;
    }

    // Utiliser la connexion
    // ... requ√™te DB ...

    // Lib√©rer
    pool_release(&pool_connections, conn);
}
```

**Avantages** :
- ‚úÖ √âvite les allocations/deallocations co√ªteuses
- ‚úÖ Lock-free pour acquire/release rapides
- ‚úÖ R√©duit la pression sur le GC/allocateur

---

### 6. Statistiques par thread avec agr√©gation

**Contexte** : √âviter la contention en utilisant des compteurs thread-local.

```c
#include <stdatomic.h>
#include <pthread.h>

#define MAX_THREADS 64

typedef struct {
    atomic_ulong compteurs[MAX_THREADS];
    _Atomic(int) next_thread_id;
} stats_distribuees_t;

static _Thread_local int mon_thread_id = -1;
stats_distribuees_t stats_globales = {0};

void stats_init(void) {
    atomic_store(&stats_globales.next_thread_id, 0);
    for (int i = 0; i < MAX_THREADS; i++) {
        atomic_store(&stats_globales.compteurs[i], 0);
    }
}

void stats_register_thread(void) {
    if (mon_thread_id == -1) {
        mon_thread_id = atomic_fetch_add(&stats_globales.next_thread_id, 1);
    }
}

void stats_incrementer(void) {
    // Incr√©ment local √† ce thread (pas de contention !)
    atomic_fetch_add_explicit(&stats_globales.compteurs[mon_thread_id], 1,
                              memory_order_relaxed);
}

unsigned long stats_total(void) {
    unsigned long total = 0;
    int nb_threads = atomic_load(&stats_globales.next_thread_id);

    for (int i = 0; i < nb_threads; i++) {
        total += atomic_load(&stats_globales.compteurs[i]);
    }

    return total;
}

// Utilisation
void* worker(void* arg) {
    stats_register_thread();

    for (int i = 0; i < 1000000; i++) {
        stats_incrementer();  // Ultra rapide, pas de cache bouncing
    }

    return NULL;
}

int main(void) {
    stats_init();

    pthread_t threads[8];
    for (int i = 0; i < 8; i++) {
        pthread_create(&threads[i], NULL, worker, NULL);
    }

    for (int i = 0; i < 8; i++) {
        pthread_join(threads[i], NULL);
    }

    printf("Total: %lu\n", stats_total());
    return 0;
}
```

**Avantages** :
- ‚úÖ Scalabilit√© lin√©aire (pas de contention)
- ‚úÖ Chaque thread travaille sur sa propre cache line
- ‚úÖ 10-20x plus rapide qu'un compteur global partag√©

**Utilisation r√©elle** : Linux kernel per-CPU statistics, jemalloc

---

## Patterns d'optimisation

### 1. Batching : Grouper les op√©rations

Au lieu de :
```c
// ‚ö†Ô∏è Lent : 1000 op√©rations atomiques
for (int i = 0; i < 1000; i++) {
    atomic_fetch_add(&counter, 1);
}
```

Faire :
```c
// ‚úÖ Rapide : 1 op√©ration atomique
atomic_fetch_add(&counter, 1000);
```

### 2. Read-mostly optimization

Si vous lisez souvent et √©crivez rarement :

```c
// Version na√Øve
atomic_int valeur = 0;

int lire(void) {
    return atomic_load(&valeur);  // Barri√®re m√©moire √† chaque lecture
}

// Version optimis√©e avec cache local
static _Thread_local int valeur_cache = 0;
static _Thread_local int cache_valide = 0;

int lire_optimise(void) {
    if (!cache_valide) {
        valeur_cache = atomic_load(&valeur);
        cache_valide = 1;
    }
    return valeur_cache;
}

void ecrire(int nouvelle_valeur) {
    atomic_store(&valeur, nouvelle_valeur);
    cache_valide = 0;  // Invalider le cache
}
```

### 3. Lazy initialization (double-checked locking)

```c
_Atomic(ressource_t*) ressource = NULL;
pthread_mutex_t init_lock = PTHREAD_MUTEX_INITIALIZER;

ressource_t* obtenir_ressource(void) {
    // First check (atomique, rapide)
    ressource_t* r = atomic_load_explicit(&ressource, memory_order_acquire);
    if (r != NULL) {
        return r;  // D√©j√† initialis√©e
    }

    // Initialisation (avec mutex pour √©viter double-init)
    pthread_mutex_lock(&init_lock);

    // Second check (sous le verrou)
    r = atomic_load(&ressource);
    if (r == NULL) {
        r = creer_ressource();
        atomic_store_explicit(&ressource, r, memory_order_release);
    }

    pthread_mutex_unlock(&init_lock);
    return r;
}
```

**Pattern** : Double-checked locking corrig√© avec atomiques

---

## Pi√®ges de performance

### ‚ùå Pi√®ge 1 : Contention excessive

```c
// ‚ö†Ô∏è PROBL√àME : Tous les threads modifient le m√™me compteur
atomic_int compteur_global = 0;

void* worker(void* arg) {
    for (int i = 0; i < 10000000; i++) {
        atomic_fetch_add(&compteur_global, 1);  // Cache bouncing !
    }
    return NULL;
}

// Avec 8 threads : ~2 secondes
```

**Solution** : Compteurs thread-local (voir exemple pr√©c√©dent)

```c
// ‚úÖ BON : Compteur local √† chaque thread
_Thread_local atomic_int compteur_local = 0;

void* worker(void* arg) {
    for (int i = 0; i < 10000000; i++) {
        atomic_fetch_add(&compteur_local, 1);  // Rapide !
    }
    return NULL;
}

// Avec 8 threads : ~0.2 secondes (10x plus rapide)
```

### ‚ùå Pi√®ge 2 : False sharing

```c
// ‚ö†Ô∏è PROBL√àME : Variables sur la m√™me cache line
struct {
    atomic_int counter1;  // Offset 0
    atomic_int counter2;  // Offset 4
} stats;  // Les deux dans la m√™me cache line (64 bytes)

// Thread 1 modifie counter1
// Thread 2 modifie counter2
// ‚Üí Invalidations de cache constantes
```

**Solution** : Padding

```c
// ‚úÖ BON : S√©paration explicite
struct {
    atomic_int counter1;
    char pad1[64 - sizeof(atomic_int)];

    atomic_int counter2;
    char pad2[64 - sizeof(atomic_int)];
} stats;
```

### ‚ùå Pi√®ge 3 : Sur-utilisation de seq_cst

```c
// ‚ö†Ô∏è LENT : seq_cst inutile pour un compteur ind√©pendant
for (int i = 0; i < 1000000; i++) {
    atomic_fetch_add(&compteur, 1);  // seq_cst par d√©faut
}
```

**Solution** : Utiliser relaxed

```c
// ‚úÖ RAPIDE : relaxed suffisant
for (int i = 0; i < 1000000; i++) {
    atomic_fetch_add_explicit(&compteur, 1, memory_order_relaxed);
}

// Gain : 30-50% plus rapide
```

---

## Profiling et diagnostic

### Utiliser perf pour identifier les hotspots

```bash
# Compiler avec debug info
gcc -g -O2 -pthread mon_programme.c -o mon_programme

# Profiler avec perf
perf record -g ./mon_programme

# Analyser
perf report

# Chercher :
# - cache-misses √©lev√©s ‚Üí false sharing ou cache bouncing
# - cycles √©lev√©s sur atomic_* ‚Üí contention
```

### Utiliser Valgrind Cachegrind

```bash
# Analyser le comportement du cache
valgrind --tool=cachegrind ./mon_programme

# Visualiser
cg_annotate cachegrind.out.<pid>

# Rechercher :
# - D1 miss rate √©lev√© ‚Üí mauvaise localit√©
# - LL (Last Level) miss rate ‚Üí cache bouncing
```

### ThreadSanitizer pour les data races

```bash
# Compiler avec TSan
gcc -fsanitize=thread -g -O1 mon_programme.c -o mon_programme

# Ex√©cuter
./mon_programme

# TSan d√©tecte :
# - Data races
# - Mauvais memory ordering
# - Acc√®s non synchronis√©s
```

---

## Recommandations par type d'application

### Applications web / API servers

**Priorit√©s** : D√©bit √©lev√©, latence faible

**Utilisez atomiques pour** :
- ‚úÖ Compteurs de requ√™tes/statistiques
- ‚úÖ Rate limiting
- ‚úÖ Flags de configuration
- ‚úÖ Pool de connexions

**Exemple** :
```c
atomic_ulong requests_handled = 0;
atomic_ulong active_connections = 0;

void handle_request(void) {
    atomic_fetch_add(&active_connections, 1);
    atomic_fetch_add(&requests_handled, 1);

    // ... traiter ...

    atomic_fetch_sub(&active_connections, 1);
}
```

---

### Syst√®mes embarqu√©s

**Priorit√©s** : Faible consommation, d√©terminisme

**Utilisez atomiques pour** :
- ‚úÖ Flags d'interruption
- ‚úÖ √âtat partag√© entre ISR et main
- ‚úÖ Compteurs mat√©riels

**Attention** : V√©rifier le support lock-free sur votre MCU

```c
#if ATOMIC_INT_LOCK_FREE != 2
    #error "Atomics not lock-free on this platform"
#endif

volatile atomic_bool interrupt_flag = false;

void ISR_handler(void) {
    atomic_store(&interrupt_flag, true);
}

void main_loop(void) {
    while (1) {
        if (atomic_load(&interrupt_flag)) {
            atomic_store(&interrupt_flag, false);
            handle_interrupt();
        }
    }
}
```

---

### Applications temps r√©el

**Priorit√©s** : Latence pr√©visible, pas de blocage

**Utilisez atomiques pour** :
- ‚úÖ Lock-free queues
- ‚úÖ Signalisation sans blocage
- ‚úÖ Coordination threads RT

**√âvitez** : Mutex (impr√©dictibles), allocations dynamiques

---

### Bases de donn√©es / Stockage

**Priorit√©s** : Coh√©rence, durabilit√©

**Utilisez atomiques pour** :
- ‚úÖ Compteurs de transactions
- ‚úÖ Sequence generators (IDs uniques)
- ‚úÖ Cache de m√©tadonn√©es

**Exemple** : G√©n√©rateur d'ID unique

```c
atomic_ulong next_transaction_id = 1;

uint64_t generer_transaction_id(void) {
    return atomic_fetch_add(&next_transaction_id, 1);
}

// Thread-safe, monotone, performant
```

---

## Checklist de performance

Avant de d√©ployer du code avec des atomiques :

### ‚úÖ Validation

- [ ] Compil√© avec `-O2` ou `-O3`
- [ ] Test√© avec ThreadSanitizer (`-fsanitize=thread`)
- [ ] V√©rifi√© le support lock-free (`ATOMIC_*_LOCK_FREE == 2`)
- [ ] Benchmark√© avec contention r√©aliste
- [ ] Profile√© avec `perf` ou `cachegrind`

### ‚úÖ Optimisation

- [ ] Utilis√© `relaxed` o√π appropri√©
- [ ] √âvit√© le false sharing (padding)
- [ ] Minimis√© la contention (thread-local counters)
- [ ] Batching des op√©rations o√π possible
- [ ] Document√© le choix des memory orders

### ‚úÖ Robustesse

- [ ] Gestion d'erreur appropri√©e
- [ ] Tests de stress (charge √©lev√©e)
- [ ] Tests de longue dur√©e (d√©tection de fuites)
- [ ] Logs et m√©triques de monitoring
- [ ] Plan de rollback si probl√®me

---

## R√©sum√©

### Performance : Ce qu'il faut retenir

1. **Les atomiques sont rapides** mais pas gratuits (2-10x co√ªt d'une op√©ration normale)
2. **L'architecture importe** : x86 vs ARM ont des caract√©ristiques diff√©rentes
3. **La contention tue les performances** : Utilisez thread-local counters
4. **False sharing** : S√©parez les variables sur des cache lines distinctes
5. **Memory ordering** : `relaxed` > `acquire/release` > `seq_cst` en performance

### Cas d'usage : Les champions

| Cas d'usage | Atomiques | Justification |
|-------------|:---------:|---------------|
| Compteurs stats | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Ultra-rapide, pas de contention |
| Flags d'arr√™t | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Simple, clair, efficace |
| Config hot-reload | ‚≠ê‚≠ê‚≠ê‚≠ê | Lectures rapides, √©critures rares |
| Rate limiting | ‚≠ê‚≠ê‚≠ê‚≠ê | Performance critique, lock-free |
| Object pools | ‚≠ê‚≠ê‚≠ê‚≠ê | Acquire/release rapides |
| G√©n√©rateur d'ID | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Monotone, thread-safe, performant |

### R√®gles d'or

1. **Mesurez avant d'optimiser** : Pas d'optimisation sans profiling
2. **Commencez simple** : `seq_cst` puis optimisez si n√©cessaire
3. **√âvitez la contention** : Thread-local > global partag√©
4. **Testez exhaustivement** : ThreadSanitizer est votre ami
5. **Documentez** : Expliquez vos choix de memory ordering

---

## Ressources compl√©mentaires

### Outils de performance

- **perf** : Profiler Linux (CPU, cache, instructions)
- **Intel VTune** : Profiler avanc√© (payant)
- **AMD ŒºProf** : Profiler AMD
- **valgrind --tool=cachegrind** : Analyse cache
- **ThreadSanitizer** : D√©tection de races

### Lectures recommand√©es

- **"What Every Programmer Should Know About Memory"** - Ulrich Drepper
- **"Systems Performance"** - Brendan Gregg
- **"The Art of Multiprocessor Programming"** - Herlihy & Shavit

### Code source √† √©tudier

- **Linux Kernel** : per-CPU counters, RCU
- **jemalloc** : Thread-local caches
- **Redis** : Atomic counters pour stats
- **Nginx** : Lock-free algorithms

---

**üí° Conseil final** : La performance des atomiques d√©pend √©norm√©ment du **contexte d'utilisation**. Ce qui est rapide dans un sc√©nario peut √™tre lent dans un autre. Mesurez toujours sur votre charge de travail r√©elle, et n'optimisez que les vrais bottlenecks identifi√©s par le profiling.

**üéØ Priorit√©s** : Correction > Clart√© > Performance. Un code correct et maintenable qui est "assez rapide" vaut mieux qu'un code ultra-optimis√© mais plein de bugs subtils.

**‚ö†Ô∏è Avertissement** : Les optimisations pr√©matur√©es avec des atomiques peuvent introduire des bugs de concurrence tr√®s difficiles √† reproduire et √† d√©boguer. Assurez-vous d'avoir des tests solides et utilisez ThreadSanitizer syst√©matiquement.

‚è≠Ô∏è [Read-write locks](/18-threads-et-concurrence/11-read-write-locks.md)
