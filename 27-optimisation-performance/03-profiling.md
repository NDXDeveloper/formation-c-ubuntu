üîù Retour au [Sommaire](/SOMMAIRE.md)

# 27.3 Profiling

## Introduction

Le **profiling** (ou **profilage** en fran√ßais) est l'analyse des performances d'un programme en cours d'ex√©cution. C'est l'outil indispensable pour comprendre **o√π votre programme passe son temps** et **quelles parties consomment le plus de ressources**.

### Pourquoi le profiling est essentiel ?

Imaginez que votre programme prend 10 secondes √† s'ex√©cuter. O√π passe-t-il son temps ?
- ü§î Dans quelle fonction ?
- ü§î √Ä quelle ligne de code ?
- ü§î Dans les calculs ou dans les acc√®s m√©moire ?

Sans profiling, vous optimisez **√† l'aveugle**. Avec le profiling, vous optimisez **l√† o√π √ßa compte vraiment**.

### La r√®gle des 90/10

> "90% du temps d'ex√©cution est pass√© dans 10% du code"

Cette r√®gle empirique signifie que :
- ‚úÖ Optimiser les **10% critiques** peut am√©liorer drastiquement les performances
- ‚ùå Optimiser les 90% restants est souvent une perte de temps

**Le profiling vous montre ces 10% critiques !**

### Citation c√©l√®bre

> "Premature optimization is the root of all evil" ‚Äî Donald Knuth

Traduction : "L'optimisation pr√©matur√©e est la racine de tous les maux"

**Signification :** N'optimisez jamais sans avoir d'abord **mesur√©** o√π se trouvent les vrais probl√®mes de performance.

---

## Types de profiling

### 1. Profiling CPU (temps d'ex√©cution)

**Question :** Quelles fonctions consomment le plus de temps processeur ?

**Outils :** `gprof`, `perf`, Valgrind Callgrind

**M√©triques :**
- Temps total pass√© dans chaque fonction
- Nombre d'appels de chaque fonction
- Temps par appel

### 2. Profiling m√©moire

**Question :** Comment est utilis√©e la m√©moire ? Y a-t-il des allocations inefficaces ?

**Outils :** Valgrind Massif, `heaptrack`

**M√©triques :**
- M√©moire allou√©e par fonction
- Dur√©e de vie des allocations
- Pics de consommation m√©moire

### 3. Profiling cache

**Question :** Mon programme utilise-t-il efficacement le cache CPU ?

**Outils :** Valgrind Cachegrind, `perf`

**M√©triques :**
- Cache hits vs cache misses
- Pr√©dictions de branchement

### 4. Profiling I/O

**Question :** Combien de temps est pass√© √† lire/√©crire des fichiers ou r√©seau ?

**Outils :** `strace`, `perf`, `iotop`

---

## Workflow de profiling recommand√©

```
1. √âcrire du code fonctionnel
   ‚Üì
2. Identifier un probl√®me de performance
   ‚Üì
3. PROFILER pour trouver le goulot d'√©tranglement
   ‚Üì
4. Optimiser UNIQUEMENT la partie identifi√©e
   ‚Üì
5. Mesurer √† nouveau (a-t-on gagn√© en performance ?)
   ‚Üì
6. R√©p√©ter si n√©cessaire
```

**Important :** Ne sautez jamais l'√©tape 3. Profiler d'abord, optimiser ensuite !

---

## Profiling avec gprof (Profiler classique)

### Introduction √† gprof

`gprof` est le profiler historique de GNU. Il est simple, l√©ger et disponible partout.

**Principe :** `gprof` √©chantillonne p√©riodiquement l'ex√©cution du programme pour d√©terminer dans quelle fonction il se trouve.

### √âtapes d'utilisation

#### √âtape 1 : Compiler avec le flag `-pg`

```bash
gcc -pg -O2 mon_programme.c -o mon_programme
```

Le flag `-pg` (profiling generation) ajoute du code d'instrumentation au binaire.

**‚ö†Ô∏è Note :** Ne combinez **jamais** `-pg` avec des flags d'optimisation trop agressifs comme `-fomit-frame-pointer`, car cela emp√™che le profiling de fonctionner correctement.

#### √âtape 2 : Ex√©cuter le programme normalement

```bash
./mon_programme
```

Le programme s'ex√©cute normalement (avec un l√©ger surco√ªt d√ª √† l'instrumentation). √Ä la fin de l'ex√©cution, un fichier `gmon.out` est g√©n√©r√©.

#### √âtape 3 : G√©n√©rer le rapport avec gprof

```bash
gprof mon_programme gmon.out > rapport_profiling.txt
```

Cette commande analyse `gmon.out` et produit un rapport texte d√©taill√©.

#### √âtape 4 : Analyser le rapport

```bash
less rapport_profiling.txt
```

### Exemple complet

**Code source : `test_perf.c`**

```c
#include <stdio.h>
#include <unistd.h>

void fonction_lente() {
    // Simule un calcul lourd
    for (int i = 0; i < 100000000; i++) {
        // Calcul inutile
    }
}

void fonction_rapide() {
    for (int i = 0; i < 1000; i++) {
        // Peu d'it√©rations
    }
}

void fonction_intermediaire() {
    fonction_lente();
    fonction_rapide();
}

int main() {
    printf("D√©but du programme\n");

    // Appelle plusieurs fois les fonctions
    for (int i = 0; i < 5; i++) {
        fonction_intermediaire();
    }

    fonction_rapide();

    printf("Fin du programme\n");
    return 0;
}
```

**Compilation et profiling :**

```bash
# 1. Compiler avec -pg
gcc -pg -O2 test_perf.c -o test_perf

# 2. Ex√©cuter
./test_perf

# 3. G√©n√©rer le rapport
gprof test_perf gmon.out > rapport.txt

# 4. Afficher les r√©sultats
cat rapport.txt
```

### Interpr√©ter le rapport gprof

Le rapport contient deux sections principales :

#### Section 1 : Flat profile (Profil plat)

```
Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 85.71      0.60     0.60        5   120.00   120.00  fonction_lente
 12.86      0.69     0.09        6     1.50     1.50  fonction_rapide
  1.43      0.70     0.01        5     2.00   122.00  fonction_intermediaire
  0.00      0.70     0.00        1     0.00   700.00  main
```

**Colonnes importantes :**

- **% time** : Pourcentage du temps total pass√© dans cette fonction
  - `fonction_lente` : **85.71%** du temps ‚Üí **C'est le goulot d'√©tranglement !**

- **cumulative seconds** : Temps cumul√© jusqu'√† cette ligne

- **self seconds** : Temps pass√© **dans** cette fonction (sans compter les fonctions qu'elle appelle)

- **calls** : Nombre d'appels

- **self ms/call** : Temps moyen par appel (millisecondes)

**Interpr√©tation :** `fonction_lente` prend 85% du temps total. C'est l√† qu'il faut optimiser !

#### Section 2 : Call graph (Graphe d'appels)

```
index % time    self  children    called     name
                                                 <spontaneous>
[1]    100.0    0.00    0.70                 main [1]
                0.01    0.61       5/5           fonction_intermediaire [2]
                0.09    0.00       6/6           fonction_rapide [4]
-----------------------------------------------
                0.01    0.61       5/5           main [1]
[2]     88.6    0.01    0.61       5         fonction_intermediaire [2]
                0.60    0.00       5/5           fonction_lente [3]
                0.00    0.00       5/6           fonction_rapide [4]
-----------------------------------------------
                0.60    0.00       5/5           fonction_intermediaire [2]
[3]     85.7    0.60    0.00       5         fonction_lente [3]
-----------------------------------------------
                0.09    0.00       6/6           main [1]
                0.00    0.00       5/6           fonction_intermediaire [2]
[4]     12.9    0.09    0.00       6         fonction_rapide [4]
-----------------------------------------------
```

Cette section montre **qui appelle qui** :
- `main` appelle `fonction_intermediaire` 5 fois
- `fonction_intermediaire` appelle `fonction_lente` 5 fois
- etc.

**Utilit√© :** Comprendre le contexte d'appel d'une fonction co√ªteuse.

### Limites de gprof

- ‚ùå **Pr√©cision limit√©e** : √âchantillonnage toutes les ~10ms (peut manquer des fonctions tr√®s rapides)
- ‚ùå **Pas de profiling multi-thread** : Ne fonctionne pas correctement avec `pthread`
- ‚ùå **Overhead** : L'instrumentation ralentit le programme (~10-30%)
- ‚ùå **Pas d'info sur le cache ou la m√©moire**

**Alternative moderne :** `perf` (voir section suivante)

---

## Profiling avec perf (Outil moderne recommand√©)

### Introduction √† perf

`perf` est le profiler moderne de Linux, int√©gr√© au kernel. Il est **beaucoup plus puissant** que `gprof` :

- ‚úÖ Pr√©cision √©lev√©e (√©chantillonnage bas√© sur les interruptions mat√©rielles)
- ‚úÖ Support multi-thread et multi-processus
- ‚úÖ Profiling CPU, cache, branch prediction, I/O, etc.
- ‚úÖ Overhead minimal (~1-5%)
- ‚úÖ Pas besoin de recompiler avec `-pg`

### Installation

```bash
# Sur Ubuntu/Debian
sudo apt-get install linux-tools-common linux-tools-generic linux-tools-$(uname -r)

# V√©rifier l'installation
perf --version
```

### Workflow de base

#### √âtape 1 : Compiler avec symboles de debug

```bash
gcc -O2 -g mon_programme.c -o mon_programme
```

Le flag `-g` ajoute les symboles de d√©bogage pour que `perf` puisse afficher les noms de fonctions.

**Note :** Contrairement √† `gprof`, pas besoin de `-pg` !

#### √âtape 2 : Profiler l'ex√©cution

```bash
perf record ./mon_programme
```

Cela g√©n√®re un fichier `perf.data` contenant les donn√©es de profiling.

**Options utiles :**

```bash
# √âchantillonner plus fr√©quemment (par d√©faut: 1000 Hz)
perf record -F 4000 ./mon_programme

# Profiler un processus existant (par PID)
perf record -p 12345

# Profiler tous les CPUs
perf record -a ./mon_programme

# Profiler pendant 10 secondes puis arr√™ter
perf record -a sleep 10
```

#### √âtape 3 : Analyser les r√©sultats

```bash
perf report
```

Cela ouvre une interface interactive (type `less`) montrant les fonctions les plus co√ªteuses.

**Navigation dans `perf report` :**
- Fl√®ches haut/bas : Naviguer dans la liste
- Entr√©e : Voir les d√©tails d'une fonction (d√©sassemblage)
- `q` : Quitter

### Exemple avec perf

**Code source : `test_perf2.c`**

```c
#include <stdio.h>
#include <stdlib.h>

// Fonction avec beaucoup de calculs
double calcul_intensif(int n) {
    double resultat = 0.0;
    for (int i = 0; i < n; i++) {
        resultat += (double)i * i / (i + 1.0);
    }
    return resultat;
}

// Fonction avec allocations m√©moire
void allocation_intensive(int n) {
    for (int i = 0; i < n; i++) {
        int *tableau = malloc(1000 * sizeof(int));
        for (int j = 0; j < 1000; j++) {
            tableau[j] = j;
        }
        free(tableau);
    }
}

int main() {
    printf("D√©but du profiling\n");

    // 80% du temps ici
    for (int i = 0; i < 1000; i++) {
        calcul_intensif(100000);
    }

    // 20% du temps ici
    allocation_intensive(10000);

    printf("Fin du profiling\n");
    return 0;
}
```

**Profiling :**

```bash
# 1. Compiler avec optimisations et symboles
gcc -O2 -g test_perf2.c -o test_perf2

# 2. Profiler
perf record ./test_perf2

# 3. Voir le rapport
perf report
```

**Exemple de sortie `perf report` :**

```
Samples: 5K of event 'cycles', Event count (approx.): 4521349087
Overhead  Command     Shared Object       Symbol
  78.45%  test_perf2  test_perf2          [.] calcul_intensif
  19.23%  test_perf2  test_perf2          [.] allocation_intensive
   1.89%  test_perf2  libc.so.6           [.] malloc
   0.43%  test_perf2  libc.so.6           [.] free
```

**Interpr√©tation :**
- `calcul_intensif` : **78.45%** du temps ‚Üí Optimiser ici en priorit√© !
- `allocation_intensive` : 19.23%
- Les appels √† `malloc`/`free` prennent aussi du temps (2.32% cumul√©)

### Profiling avanc√© avec perf

#### a) Profiler les cache misses

```bash
# Profiler les d√©fauts de cache L1
perf record -e cache-misses ./mon_programme
perf report
```

**Interpr√©tation :** Si une fonction a beaucoup de cache misses, cela signifie qu'elle acc√®de √† la m√©moire de mani√®re inefficace (acc√®s non s√©quentiels, stride trop grand, etc.).

#### b) Profiler les branch misses (pr√©dictions de branchement)

```bash
perf record -e branch-misses ./mon_programme
perf report
```

**Interpr√©tation :** Beaucoup de branch misses indiquent que le CPU a du mal √† pr√©dire les conditions (`if`, boucles). R√©organiser le code peut aider.

#### c) Profiler les instructions

```bash
perf stat ./mon_programme
```

**Exemple de sortie :**

```
 Performance counter stats for './test_perf2':

          2,147.56 msec task-clock                #    0.998 CPUs utilized
                 3      context-switches          #    1.397 /sec
                 0      cpu-migrations            #    0.000 /sec
               156      page-faults               #   72.628 /sec
     8,521,349,087      cycles                    #    3.968 GHz
    12,456,789,123      instructions              #    1.46  insn per cycle
     2,345,678,901      branches                  # 1092.136 M/sec
        12,456,789      branch-misses             #    0.53% of all branches

       2.151234567 seconds time elapsed

       2.147890000 seconds user
       0.000000000 seconds sys
```

**M√©triques importantes :**

- **cycles** : Nombre de cycles CPU
- **instructions** : Nombre d'instructions ex√©cut√©es
- **IPC (insn per cycle)** : Nombre d'instructions par cycle
  - Valeur id√©ale : ~2-4 (d√©pend du CPU)
  - Valeur faible (<1) : CPU bloqu√© (attente m√©moire, d√©pendances)
- **branch-misses** : Pr√©dictions de branchement rat√©es
  - Bon : <5%
  - Mauvais : >10%

#### d) Flame Graphs (Graphiques en flammes)

Les **Flame Graphs** sont une visualisation tr√®s populaire du profiling.

**Installation :**

```bash
git clone https://github.com/brendangregg/FlameGraph
cd FlameGraph
```

**G√©n√©ration :**

```bash
# Profiler
perf record -F 99 -g ./mon_programme

# G√©n√©rer le stack trace
perf script > out.perf

# Cr√©er le Flame Graph
./stackcollapse-perf.pl out.perf | ./flamegraph.pl > flamegraph.svg

# Ouvrir dans un navigateur
firefox flamegraph.svg
```

**Interpr√©tation :**
- Largeur : Temps pass√© (plus large = plus lent)
- Hauteur : Profondeur de la pile d'appels
- Couleurs : Al√©atoires (pour diff√©rencier)

Les Flame Graphs permettent de voir d'un coup d'≈ìil toute la hi√©rarchie des appels et o√π le temps est d√©pens√©.

---

## Profiling avec Valgrind Callgrind

### Introduction √† Callgrind

**Callgrind** est un outil de Valgrind pour le profiling d√©taill√© des appels de fonctions.

**Avantages :**
- ‚úÖ Tr√®s pr√©cis (compte exact des instructions)
- ‚úÖ Pas besoin de recompiler avec `-pg`
- ‚úÖ Profiling d√©terministe (pas d'√©chantillonnage)

**Inconv√©nients :**
- ‚ùå **Tr√®s lent** (10-50x plus lent que l'ex√©cution normale)
- ‚ùå Ne capture pas les performances r√©elles (simule le CPU)

### Utilisation

```bash
# Profiler avec Callgrind
valgrind --tool=callgrind ./mon_programme

# Cela g√©n√®re un fichier : callgrind.out.<pid>
```

### Analyser avec KCachegrind (interface graphique)

```bash
# Installer KCachegrind
sudo apt-get install kcachegrind

# Ouvrir le fichier de profiling
kcachegrind callgrind.out.12345
```

**KCachegrind** offre une interface graphique superbe avec :
- Graphe d'appels interactif
- Liste des fonctions tri√©es par co√ªt
- Vue du code source annot√©
- Carte de chaleur (heatmap)

### Analyser en ligne de commande

```bash
# Afficher les 10 fonctions les plus co√ªteuses
callgrind_annotate callgrind.out.12345 | head -30
```

**Exemple de sortie :**

```
--------------------------------------------------------------------------------
Profile data file 'callgrind.out.12345' (creator: callgrind-3.15.0)
--------------------------------------------------------------------------------
I1 cache:         32768 B, 64 B, 8-way associative
D1 cache:         32768 B, 64 B, 8-way associative
LL cache:         8388608 B, 64 B, 16-way associative
Command:          ./test_perf2
Data file:        callgrind.out.12345
Events recorded:  Ir
Events shown:     Ir
Event sort order: Ir
Thresholds:       99
Include dirs:
User annotated:
Auto-annotation:  off

--------------------------------------------------------------------------------
      Ir
--------------------------------------------------------------------------------
8,456,789,123  PROGRAM TOTALS

--------------------------------------------------------------------------------
      Ir  file:function
--------------------------------------------------------------------------------
6,745,432,123  test_perf2.c:calcul_intensif [/path/to/test_perf2]
1,234,567,890  test_perf2.c:allocation_intensive [/path/to/test_perf2]
  456,789,100  ???:malloc [/usr/lib/libc.so.6]
```

**Ir** = Instructions Retired (instructions ex√©cut√©es)

**Interpr√©tation :** `calcul_intensif` ex√©cute 6.7 milliards d'instructions, soit ~80% du total.

---

## Profiling m√©moire avec Valgrind Massif

### Introduction √† Massif

**Massif** est un profiler de tas (heap) qui montre :
- Combien de m√©moire est allou√©e
- O√π est-elle allou√©e (quelle fonction)
- L'√©volution dans le temps

### Utilisation

```bash
# Profiler la m√©moire
valgrind --tool=massif ./mon_programme

# G√©n√®re : massif.out.<pid>
```

### Analyser avec ms_print

```bash
ms_print massif.out.12345 > rapport_memoire.txt
less rapport_memoire.txt
```

**Exemple de graphique dans le rapport :**

```
    MB
19.71^                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                      :#
     |                                                                      :#
     |                                                                      :#
     |                                                                      :#
     |                                                                     ::#
     |                                                                     ::#
     |                                                                    :::#
     |                                                                    :::#
     |                                                                   ::::#
     |                                                                   ::::#
     |                                                                  :::::#
     |                                                                 ::::::#
     |                                                               @:::::::#
     |                                                           @@@@:::::::#
     |                                                      @@@@@@@@@:::::::#
     |                                            @@@@@@@@@@@@@@@@@@@@:::::::#
   0 +----------------------------------------------------------------------->Gi
     0                                                                   109.8

Number of snapshots: 52
 Detailed snapshots: [9, 19, 29, 39, 49 (peak)]
```

**Interpr√©tation :**
- Pic de m√©moire √† ~19.71 MB
- Le `@` et `#` montrent l'√©volution de l'allocation
- Les snapshots d√©taill√©s montrent o√π la m√©moire est allou√©e

**D√©tail d'un snapshot (pic) :**

```
--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
 49      8,924,567       19,710,000       19,450,000       260,000            0
99.99% (19,450,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->85.45% (16,834,000B) 0x4005E8: allocation_intensive (test_perf2.c:14)
| ->85.45% (16,834,000B) 0x400623: main (test_perf2.c:26)
|
->14.54% (2,616,000B) 0x4005A3: calcul_intensif (test_perf2.c:7)
  ->14.54% (2,616,000B) 0x400610: main (test_perf2.c:23)
```

**Interpr√©tation :**
- `allocation_intensive` alloue 85.45% de la m√©moire totale
- `calcul_intensif` alloue 14.54%

### Visualiser avec Massif-Visualizer (GUI)

```bash
# Installer
sudo apt-get install massif-visualizer

# Ouvrir
massif-visualizer massif.out.12345
```

Interface graphique √©l√©gante avec graphiques interactifs.

---

## Comparaison des outils de profiling

| Outil | Type | Pr√©cision | Overhead | Multithreading | GUI |
|-------|------|-----------|----------|----------------|-----|
| **gprof** | CPU | Moyenne | 10-30% | ‚ùå | ‚ùå |
| **perf** | CPU, cache, I/O | Haute | 1-5% | ‚úÖ | Via FlameGraph |
| **Callgrind** | CPU | Tr√®s haute | 1000-5000% | ‚úÖ | ‚úÖ (KCachegrind) |
| **Massif** | M√©moire | Haute | 100-200% | ‚úÖ | ‚úÖ (massif-visualizer) |

**Recommandation g√©n√©rale :**
- ü•á **Profiling quotidien** : `perf` (rapide, pr√©cis)
- ü•à **Analyse d√©taill√©e** : Callgrind + KCachegrind
- ü•â **Profiling m√©moire** : Massif
- üìú **Profiling simple** : gprof (si `perf` n'est pas disponible)

---

## Bonnes pratiques de profiling

### 1. Toujours profiler avec les optimisations activ√©es

```bash
# ‚úÖ BON : Profiler le code optimis√©
gcc -O2 -g test.c -o test
perf record ./test

# ‚ùå MAUVAIS : Profiler sans optimisation
gcc -O0 -g test.c -o test
perf record ./test
```

**Pourquoi ?** Le code non optimis√© ne repr√©sente pas les performances r√©elles.

### 2. Profiler avec des donn√©es r√©alistes

```bash
# ‚ùå MAUVAIS : Petit dataset
./mon_programme petit_fichier.txt

# ‚úÖ BON : Dataset repr√©sentatif de la production
./mon_programme gros_fichier_production.txt
```

### 3. Profiler plusieurs fois et faire la moyenne

Les performances peuvent varier √† cause :
- Du cache CPU
- De l'√©tat du syst√®me
- D'autres processus

```bash
# Profiler 5 fois et comparer
for i in {1..5}; do
    perf stat ./mon_programme
done
```

### 4. Isoler les parties co√ªteuses

Si votre programme fait beaucoup de choses, profilez une partie √† la fois :

```c
int main() {
    // Phase 1 : Chargement des donn√©es
    charger_donnees();

    // Phase 2 : Traitement (√Ä PROFILER)
    traiter_donnees();

    // Phase 3 : Sauvegarde
    sauvegarder_resultats();
}
```

Ajoutez des flags ou commentez les parties non pertinentes.

### 5. V√©rifier que l'optimisation a fonctionn√©

```bash
# Avant optimisation
perf stat ./mon_programme_v1

# Apr√®s optimisation
perf stat ./mon_programme_v2

# Comparer les m√©triques (cycles, time elapsed, etc.)
```

### 6. Documenter les r√©sultats

Gardez une trace de vos mesures :

```bash
# Cr√©er un fichier de benchmark
echo "Version 1.0 - $(date)" > benchmark.txt
perf stat ./mon_programme 2>> benchmark.txt

# Apr√®s modification
echo "Version 1.1 - $(date)" >> benchmark.txt
perf stat ./mon_programme 2>> benchmark.txt
```

---

## Exemple de workflow complet

### Probl√®me : Programme trop lent

**Programme : Tri de grand tableau**

```c
// sort_benchmark.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define TAILLE 100000

void bubble_sort(int *tab, int n) {
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            if (tab[j] > tab[j + 1]) {
                int temp = tab[j];
                tab[j] = tab[j + 1];
                tab[j + 1] = temp;
            }
        }
    }
}

int main() {
    int *tableau = malloc(TAILLE * sizeof(int));

    // Remplir avec valeurs al√©atoires
    srand(time(NULL));
    for (int i = 0; i < TAILLE; i++) {
        tableau[i] = rand();
    }

    printf("D√©but du tri...\n");
    bubble_sort(tableau, TAILLE);
    printf("Tri termin√©\n");

    free(tableau);
    return 0;
}
```

### √âtape 1 : Mesurer les performances initiales

```bash
gcc -O2 -g sort_benchmark.c -o sort_benchmark

time ./sort_benchmark
# R√©sultat : 8.5 secondes ‚Üê Trop lent !
```

### √âtape 2 : Profiler avec perf

```bash
perf record ./sort_benchmark
perf report
```

**R√©sultat :**
```
Overhead  Symbol
  99.8%   bubble_sort
   0.2%   main
```

**Conclusion :** 99.8% du temps est dans `bubble_sort`. C'est le goulot !

### √âtape 3 : Analyser l'algorithme

Le bubble sort est O(n¬≤), c'est un algorithme inefficace pour les grands tableaux.

**Solution :** Utiliser quicksort (O(n log n))

### √âtape 4 : Optimiser

```c
// Utiliser qsort de la stdlib
int compare(const void *a, const void *b) {
    return (*(int*)a - *(int*)b);
}

int main() {
    int *tableau = malloc(TAILLE * sizeof(int));

    srand(time(NULL));
    for (int i = 0; i < TAILLE; i++) {
        tableau[i] = rand();
    }

    printf("D√©but du tri...\n");
    qsort(tableau, TAILLE, sizeof(int), compare);  // ‚Üê Optimis√© !
    printf("Tri termin√©\n");

    free(tableau);
    return 0;
}
```

### √âtape 5 : Re-mesurer

```bash
gcc -O2 -g sort_benchmark_v2.c -o sort_benchmark_v2

time ./sort_benchmark_v2
# R√©sultat : 0.015 secondes ‚Üê 500x plus rapide !
```

### √âtape 6 : Profiler √† nouveau

```bash
perf record ./sort_benchmark_v2
perf report
```

**R√©sultat :**
```
Overhead  Symbol
  78.2%   qsort
  21.8%   main
```

Le programme est maintenant si rapide que `perf` passe plus de temps dans l'initialisation (`main`) que dans le tri lui-m√™me.

**Mission accomplie ! üéâ**

---

## Profiling de programmes multi-thread√©s

### Particularit√©s

Les programmes multi-thread√©s posent des d√©fis :
- Les threads peuvent s'ex√©cuter en parall√®le
- Le profiling doit capturer tous les threads
- Attention aux conditions de course (race conditions)

### Profiling avec perf

```bash
# Profiler tous les threads
perf record -g ./mon_programme_multithread

# Voir les r√©sultats par thread
perf report --sort comm,dso
```

### Identifier les contentions (lock contention)

Si les threads passent beaucoup de temps √† attendre des mutex :

```bash
perf record -e syscalls:sys_enter_futex ./mon_programme_multithread
perf report
```

**Interpr√©tation :** Beaucoup d'appels √† `futex` (Fast Userspace Mutex) indiquent que les threads se bloquent mutuellement.

**Solution potentielle :**
- R√©duire la taille des sections critiques
- Utiliser des locks plus fins (fine-grained locking)
- Utiliser des structures lock-free (atomics)

---

## Outils compl√©mentaires

### 1. time (mesure simple)

```bash
# Temps r√©el vs temps CPU
time ./mon_programme

# R√©sultat :
# real    0m2.547s  ‚Üê Temps √©coul√© (horloge murale)
# user    0m2.123s  ‚Üê Temps CPU en mode utilisateur
# sys     0m0.421s  ‚Üê Temps CPU en mode kernel
```

**Interpr√©tation :**
- `real > user + sys` : Programme bloqu√© (I/O, sleep, attente r√©seau)
- `user + sys > real` : Programme multi-thread√© (utilise plusieurs CPUs)

### 2. strace (profiling des appels syst√®me)

```bash
# Tracer tous les appels syst√®me
strace -c ./mon_programme

# R√©sultat :
# % time     seconds  usecs/call     calls    errors syscall
# ------ ----------- ----------- --------- --------- ----------------
#  45.23    0.012345        1234        10           read
#  32.45    0.008876         443        20           write
#  12.34    0.003377         169        20           open
```

**Utilit√© :** Identifier les I/O lentes ou les appels syst√®me excessifs.

### 3. htop / top (monitoring en temps r√©el)

```bash
htop
```

Montre l'utilisation CPU/m√©moire en temps r√©el. Utile pour identifier les processus qui consomment trop de ressources.

---

## Checklist : Profiling efficace

Avant de profiler :
- ‚úÖ Mon programme a-t-il un vrai probl√®me de performance ?
- ‚úÖ Ai-je compil√© avec `-O2` et `-g` ?
- ‚úÖ Ai-je des donn√©es de test repr√©sentatives ?

Pendant le profiling :
- ‚úÖ Ai-je utilis√© le bon outil (`perf` pour CPU, Massif pour m√©moire) ?
- ‚úÖ Ai-je ex√©cut√© plusieurs fois pour obtenir des r√©sultats stables ?
- ‚úÖ Ai-je identifi√© les fonctions qui prennent >10% du temps ?

Apr√®s le profiling :
- ‚úÖ Ai-je optimis√© SEULEMENT les parties identifi√©es comme lentes ?
- ‚úÖ Ai-je re-mesur√© pour v√©rifier que l'optimisation a fonctionn√© ?
- ‚úÖ Ai-je document√© mes r√©sultats ?

---

## Erreurs courantes √† √©viter

### ‚ùå Optimiser sans profiler

**Probl√®me :** Vous passez du temps √† optimiser une fonction qui ne repr√©sente que 1% du temps total.

**Solution :** Profilez d'abord, optimisez ensuite.

### ‚ùå Profiler du code non optimis√©

**Probl√®me :** Le code avec `-O0` a des patterns de performance compl√®tement diff√©rents de `-O2`.

**Solution :** Toujours profiler avec les flags d'optimisation que vous utiliserez en production.

### ‚ùå Profiler avec de petites donn√©es

**Probl√®me :** Un algorithme O(n¬≤) peut sembler rapide avec n=10 mais exploser avec n=10000.

**Solution :** Utilisez des datasets r√©alistes.

### ‚ùå Ne pas re-mesurer apr√®s optimisation

**Probl√®me :** Vous optimisez mais ne v√©rifiez pas si √ßa a vraiment am√©lior√© les performances.

**Solution :** Toujours mesurer avant et apr√®s.

### ‚ùå Croire les microbenchmarks

**Probl√®me :** Les microbenchmarks peuvent √™tre trompeurs (overhead du framework de test, cache chaud, etc.).

**Solution :** Profilez le programme complet dans des conditions r√©elles.

---

## R√©sum√©

| Objectif | Outil recommand√© | Commande |
|----------|------------------|----------|
| Profiling CPU rapide | `perf` | `perf record ./prog && perf report` |
| Profiling CPU d√©taill√© | Callgrind | `valgrind --tool=callgrind ./prog` + KCachegrind |
| Profiling m√©moire | Massif | `valgrind --tool=massif ./prog` + ms_print |
| Mesure simple | `time` | `time ./prog` |
| Appels syst√®me | `strace` | `strace -c ./prog` |
| Flame Graph | `perf` | `perf record -g` + FlameGraph scripts |

---

## Pour aller plus loin

### Documentation

```bash
# Manuel de perf
man perf
man perf-record
man perf-report
man perf-stat

# Valgrind
man valgrind
man callgrind
man massif
```

### Ressources en ligne

- **Brendan Gregg's Blog** : http://www.brendangregg.com/perf.html (expert en profiling)
- **perf Tutorial** : https://perf.wiki.kernel.org/index.php/Tutorial
- **FlameGraph** : https://github.com/brendangregg/FlameGraph
- **Linux Performance** : http://www.brendangregg.com/linuxperf.html

### Livres recommand√©s

- **"Systems Performance"** par Brendan Gregg (bible du profiling)
- **"The Art of Computer Programming"** par Donald Knuth (algorithmes et performance)

---

## Conclusion

Le profiling est un outil **indispensable** pour optimiser efficacement :

1. ‚úÖ **Mesurez avant d'optimiser** : Ne pr√©sumez jamais o√π sont les goulots
2. ‚úÖ **Utilisez le bon outil** : `perf` pour le CPU, Massif pour la m√©moire
3. ‚úÖ **Profilez du code optimis√©** : `-O2` minimum
4. ‚úÖ **Optimisez les 10% critiques** : R√®gle des 90/10
5. ‚úÖ **Re-mesurez toujours** : V√©rifiez que l'optimisation a fonctionn√©

**Citation finale :**

> "In God we trust, all others bring data" ‚Äî W. Edwards Deming

Traduction : "En Dieu nous croyons, tous les autres doivent apporter des donn√©es"

**Ne devinez pas, mesurez !**

---

*Prochaine section : 27.4 Cache awareness*

‚è≠Ô∏è [Cache awareness](/27-optimisation-performance/04-cache-awareness.md)
