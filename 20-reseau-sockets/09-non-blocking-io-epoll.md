üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.9 Non-blocking I/O et epoll

## Introduction

Dans la section pr√©c√©dente, nous avons vu comment utiliser `epoll()` pour g√©rer plusieurs clients simultan√©ment. Mais nous avons utilis√© des sockets en mode **bloquant**, ce qui n'exploite pas pleinement la puissance d'`epoll()`.

Dans cette section, nous allons d√©couvrir le **I/O non-bloquant** : un mode o√π les op√©rations r√©seau retournent imm√©diatement au lieu d'attendre. C'est la base des serveurs haute performance comme Nginx, Redis, et Node.js.

**Objectif :** Comprendre le I/O non-bloquant et cr√©er un serveur √©v√©nementiel performant avec `epoll()`.

---

## I/O Bloquant vs Non-Bloquant

### Mode Bloquant (D√©faut)

En mode **bloquant**, les op√©rations r√©seau **attendent** jusqu'√† ce qu'elles puissent se compl√©ter.

```c
// Mode bloquant (d√©faut)
char buffer[1024];  
ssize_t n = recv(sockfd, buffer, sizeof(buffer), 0);  
// ‚è≥ Le programme s'arr√™te ici jusqu'√† ce que des donn√©es arrivent
```

**Comportement :**
- `recv()` attend qu'il y ait des donn√©es √† lire
- `send()` attend qu'il y ait de la place dans le buffer d'envoi
- `accept()` attend qu'un client se connecte
- `connect()` attend que la connexion soit √©tablie

**Probl√®me :** Si vous g√©rez plusieurs clients, vous ne pouvez pas attendre sur un socket sans ignorer les autres.

---

### Mode Non-Bloquant

En mode **non-bloquant**, les op√©rations retournent **imm√©diatement**, m√™me si elles ne peuvent pas se compl√©ter.

```c
// Mode non-bloquant
char buffer[1024];  
ssize_t n = recv(sockfd, buffer, sizeof(buffer), 0);  
// ‚ö° Retourne imm√©diatement

if (n < 0) {
    if (errno == EAGAIN || errno == EWOULDBLOCK) {
        // Pas de donn√©es disponibles maintenant, r√©essayer plus tard
    } else {
        // Vraie erreur
        perror("recv");
    }
}
```

**Comportement :**
- Si l'op√©ration ne peut pas se compl√©ter ‚Üí retourne `-1` avec `errno = EAGAIN`
- Si l'op√©ration r√©ussit partiellement ‚Üí retourne le nombre d'octets trait√©s
- Si l'op√©ration r√©ussit compl√®tement ‚Üí retourne le r√©sultat normal

---

## Rendre un Socket Non-Bloquant

### M√©thode 1 : `fcntl()` (Recommand√©e)

```c
#include <fcntl.h>

int set_nonblocking(int sockfd) {
    int flags = fcntl(sockfd, F_GETFL, 0);
    if (flags == -1) {
        perror("fcntl F_GETFL");
        return -1;
    }

    if (fcntl(sockfd, F_SETFL, flags | O_NONBLOCK) == -1) {
        perror("fcntl F_SETFL");
        return -1;
    }

    return 0;
}
```

**Utilisation :**
```c
int sockfd = socket(AF_INET, SOCK_STREAM, 0);  
set_nonblocking(sockfd);  

// Maintenant recv(), send(), etc. sont non-bloquants
```

---

### M√©thode 2 : Flag √† la cr√©ation (Linux)

```c
// Cr√©er directement un socket non-bloquant
int sockfd = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0);
```

**Avantage :** Atomique, pas de race condition.

---

### M√©thode 3 : `ioctl()` (Ancienne m√©thode)

```c
#include <sys/ioctl.h>

int nonblock = 1;  
ioctl(sockfd, FIONBIO, &nonblock);  
```

**Note :** Moins portable que `fcntl()`.

---

## G√©rer EAGAIN et EWOULDBLOCK

### Le Concept

Quand une op√©ration ne peut pas se compl√©ter imm√©diatement, elle retourne `-1` avec :
- `errno = EAGAIN` (Try again)
- `errno = EWOULDBLOCK` (Would block)

Sur Linux, `EAGAIN == EWOULDBLOCK`, mais sur d'autres syst√®mes ils peuvent √™tre diff√©rents.

**Bonne pratique :** Toujours tester les deux.

```c
if (errno == EAGAIN || errno == EWOULDBLOCK) {
    // C'est normal, l'op√©ration n'est pas pr√™te
    // R√©essayer plus tard
}
```

---

### Exemple : Lecture Non-Bloquante

```c
ssize_t read_nonblocking(int sockfd, char *buffer, size_t len) {
    ssize_t n = recv(sockfd, buffer, len, 0);

    if (n < 0) {
        if (errno == EAGAIN || errno == EWOULDBLOCK) {
            // Pas de donn√©es disponibles maintenant
            return 0;  // Signaler "pas de donn√©es"
        } else {
            // Vraie erreur
            perror("recv");
            return -1;
        }
    } else if (n == 0) {
        // Connexion ferm√©e
        return -1;
    }

    // n > 0 : donn√©es lues avec succ√®s
    return n;
}
```

---

### Exemple : √âcriture Non-Bloquante

L'√©criture non-bloquante est plus complexe car `send()` peut envoyer **moins** que demand√©.

```c
ssize_t write_nonblocking(int sockfd, const char *buffer, size_t len) {
    ssize_t n = send(sockfd, buffer, len, 0);

    if (n < 0) {
        if (errno == EAGAIN || errno == EWOULDBLOCK) {
            // Le buffer d'envoi est plein
            return 0;  // Rien envoy√©, r√©essayer plus tard
        } else {
            perror("send");
            return -1;
        }
    }

    // n >= 0 : octets envoy√©s (peut √™tre < len)
    return n;
}
```

**Important :** Si `send()` retourne `n < len`, il faut **sauvegarder** les octets non envoy√©s et les envoyer plus tard.

---

## epoll : Edge-Triggered vs Level-Triggered

### Deux Modes de Notification

`epoll()` peut notifier les √©v√©nements de deux mani√®res :

1. **Level-Triggered (LT)** : Mode par d√©faut
2. **Edge-Triggered (ET)** : Mode avanc√©

---

### Level-Triggered (LT) - Mode par D√©faut

**Principe :** Notification tant que la condition est vraie.

```
Donn√©es disponibles ‚Üí epoll_wait() notifie
    ‚Üì
Vous ne lisez pas tout
    ‚Üì
epoll_wait() notifie √† nouveau
    ‚Üì
Vous ne lisez toujours pas
    ‚Üì
epoll_wait() notifie encore...
```

**Comportement :**
- `epoll_wait()` notifie **√† chaque fois** qu'il y a des donn√©es non lues
- Similaire √† `select()` et `poll()`
- Plus tol√©rant aux erreurs de programmation

**Exemple :**
```c
struct epoll_event event;  
event.events = EPOLLIN;  // Level-Triggered par d√©faut  
event.data.fd = sockfd;  
epoll_ctl(epfd, EPOLL_CTL_ADD, sockfd, &event);  
```

**Quand utiliser LT :**
- ‚úÖ Vous d√©butez avec `epoll()`
- ‚úÖ Simplicit√© du code
- ‚úÖ Sockets bloquants ou non-bloquants

---

### Edge-Triggered (ET) - Mode Avanc√©

**Principe :** Notification uniquement sur les **changements** d'√©tat.

```
Donn√©es arrivent ‚Üí epoll_wait() notifie UNE FOIS
    ‚Üì
Vous devez TOUT lire maintenant
    ‚Üì
Si vous ne lisez pas tout, epoll_wait() ne notifie plus !
```

**Comportement :**
- Notification seulement quand l'√©tat **change** (0 ‚Üí donn√©es, pas de donn√©es ‚Üí donn√©es)
- **Obligation** de tout lire/√©crire jusqu'√† `EAGAIN`
- N√©cessite des sockets **non-bloquants**
- Plus efficace (moins d'appels syst√®me)

**Exemple :**
```c
struct epoll_event event;  
event.events = EPOLLIN | EPOLLET;  // Edge-Triggered  
event.data.fd = sockfd;  
epoll_ctl(epfd, EPOLL_CTL_ADD, sockfd, &event);  
```

**Quand utiliser ET :**
- ‚úÖ Performance maximale
- ‚úÖ Vous ma√Ætrisez le I/O non-bloquant
- ‚úÖ Serveur haute charge (1000+ clients)

---

### Comparaison LT vs ET

| Aspect | Level-Triggered | Edge-Triggered |
|--------|-----------------|----------------|
| **Notification** | R√©p√©t√©e tant que donn√©es disponibles | Une seule fois par changement |
| **Lecture** | Partielle OK | **TOUT lire** jusqu'√† EAGAIN |
| **Socket** | Bloquant ou non-bloquant | **Obligatoirement** non-bloquant |
| **Performance** | Bonne | Excellente |
| **Complexit√©** | Simple | Complexe |
| **Risque** | Faible | Famine si mal cod√© |

---

### Exemple de Famine en ET

```c
// ‚ùå MAUVAIS CODE en Edge-Triggered
while (1) {
    int n = epoll_wait(epfd, events, MAX_EVENTS, -1);

    for (int i = 0; i < n; i++) {
        int fd = events[i].data.fd;

        char buffer[100];
        // ‚ùå Ne lit que 100 octets !
        recv(fd, buffer, 100, 0);

        // S'il y a 10 000 octets, les 9 900 restants ne seront JAMAIS lus
        // Car epoll_wait() ne notifiera plus ce fd
    }
}
```

**R√©sultat :** Le client attend ind√©finiment, le serveur ne r√©pond plus ‚Üí **deadlock**.

---

## Architecture Event-Driven avec epoll ET

### Gestion d'√âtat par Connexion

En mode Edge-Triggered, chaque connexion doit avoir un **√©tat** :

```c
typedef enum {
    STATE_READING,   // En train de lire
    STATE_WRITING,   // En train d'√©crire
    STATE_CLOSING    // √Ä fermer
} connection_state_t;

typedef struct {
    int fd;
    connection_state_t state;

    // Buffers de lecture
    char read_buffer[4096];
    size_t read_pos;

    // Buffers d'√©criture (donn√©es √† envoyer)
    char write_buffer[4096];
    size_t write_pos;
    size_t write_len;
} connection_t;
```

---

### Pattern de Lecture Compl√®te

En Edge-Triggered, il faut tout lire jusqu'√† `EAGAIN`.

```c
void handle_read_et(connection_t *conn) {
    while (1) {
        ssize_t n = recv(conn->fd,
                        conn->read_buffer + conn->read_pos,
                        sizeof(conn->read_buffer) - conn->read_pos,
                        0);

        if (n < 0) {
            if (errno == EAGAIN || errno == EWOULDBLOCK) {
                // Tout a √©t√© lu, c'est normal
                break;
            } else {
                // Erreur r√©elle
                perror("recv");
                conn->state = STATE_CLOSING;
                return;
            }
        } else if (n == 0) {
            // Connexion ferm√©e
            conn->state = STATE_CLOSING;
            return;
        }

        // n > 0 : donn√©es re√ßues
        conn->read_pos += n;

        // V√©rifier si le buffer est plein
        if (conn->read_pos >= sizeof(conn->read_buffer)) {
            fprintf(stderr, "Buffer plein !\n");
            break;
        }
    }

    // Traiter les donn√©es lues
    process_data(conn);
}
```

**Points cl√©s :**
1. Boucle `while(1)` pour tout lire
2. Sortir sur `EAGAIN` (c'est normal)
3. G√©rer le buffer plein

---

### Pattern d'√âcriture Compl√®te

L'√©criture est plus complexe car `send()` peut ne pas tout envoyer.

```c
void handle_write_et(connection_t *conn) {
    while (conn->write_pos < conn->write_len) {
        ssize_t n = send(conn->fd,
                        conn->write_buffer + conn->write_pos,
                        conn->write_len - conn->write_pos,
                        0);

        if (n < 0) {
            if (errno == EAGAIN || errno == EWOULDBLOCK) {
                // Buffer d'envoi plein, r√©essayer plus tard
                // Activer la notification EPOLLOUT
                struct epoll_event event;
                event.events = EPOLLIN | EPOLLOUT | EPOLLET;
                event.data.ptr = conn;
                epoll_ctl(epfd, EPOLL_CTL_MOD, conn->fd, &event);
                return;
            } else {
                perror("send");
                conn->state = STATE_CLOSING;
                return;
            }
        }

        // n >= 0 : octets envoy√©s
        conn->write_pos += n;
    }

    // Tout envoy√© !
    conn->write_pos = 0;
    conn->write_len = 0;

    // D√©sactiver EPOLLOUT pour √©viter les notifications inutiles
    struct epoll_event event;
    event.events = EPOLLIN | EPOLLET;
    event.data.ptr = conn;
    epoll_ctl(epfd, EPOLL_CTL_MOD, conn->fd, &event);
}
```

**Points cl√©s :**
1. Boucle tant qu'il reste des donn√©es √† envoyer
2. Sur `EAGAIN`, activer `EPOLLOUT` pour √™tre notifi√© quand on peut r√©envoyer
3. Quand tout est envoy√©, d√©sactiver `EPOLLOUT`

---

## Exemple Complet : Serveur √âcho avec epoll ET

Voici un serveur √©cho complet en mode Edge-Triggered.

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <fcntl.h>
#include <errno.h>
#include <arpa/inet.h>
#include <sys/socket.h>
#include <sys/epoll.h>

#define PORT 8080
#define MAX_EVENTS 64
#define BUFFER_SIZE 4096

typedef enum {
    STATE_READING,
    STATE_WRITING,
    STATE_CLOSING
} state_t;

typedef struct {
    int fd;
    state_t state;
    char read_buf[BUFFER_SIZE];
    size_t read_pos;
    char write_buf[BUFFER_SIZE];
    size_t write_pos;
    size_t write_len;
} connection_t;

// Rendre un socket non-bloquant
int set_nonblocking(int fd) {
    int flags = fcntl(fd, F_GETFL, 0);
    if (flags == -1) return -1;
    return fcntl(fd, F_SETFL, flags | O_NONBLOCK);
}

// G√©rer la lecture (Edge-Triggered)
void handle_read(int epfd, connection_t *conn) {
    while (1) {
        ssize_t n = recv(conn->fd,
                        conn->read_buf + conn->read_pos,
                        BUFFER_SIZE - conn->read_pos - 1,
                        0);

        if (n < 0) {
            if (errno == EAGAIN || errno == EWOULDBLOCK) {
                break;  // Tout lu
            } else {
                perror("recv");
                conn->state = STATE_CLOSING;
                return;
            }
        } else if (n == 0) {
            printf("[FD %d] Client d√©connect√©\n", conn->fd);
            conn->state = STATE_CLOSING;
            return;
        }

        conn->read_pos += n;

        if (conn->read_pos >= BUFFER_SIZE - 1) {
            fprintf(stderr, "[FD %d] Buffer plein\n", conn->fd);
            break;
        }
    }

    // Pr√©parer l'√©cho : copier read_buf ‚Üí write_buf
    if (conn->read_pos > 0) {
        memcpy(conn->write_buf, conn->read_buf, conn->read_pos);
        conn->write_len = conn->read_pos;
        conn->write_pos = 0;
        conn->read_pos = 0;

        // Passer en mode √©criture
        conn->state = STATE_WRITING;

        // Activer EPOLLOUT
        struct epoll_event event;
        event.events = EPOLLIN | EPOLLOUT | EPOLLET;
        event.data.ptr = conn;
        epoll_ctl(epfd, EPOLL_CTL_MOD, conn->fd, &event);
    }
}

// G√©rer l'√©criture (Edge-Triggered)
void handle_write(int epfd, connection_t *conn) {
    while (conn->write_pos < conn->write_len) {
        ssize_t n = send(conn->fd,
                        conn->write_buf + conn->write_pos,
                        conn->write_len - conn->write_pos,
                        0);

        if (n < 0) {
            if (errno == EAGAIN || errno == EWOULDBLOCK) {
                // Buffer plein, on r√©essaiera plus tard
                return;
            } else {
                perror("send");
                conn->state = STATE_CLOSING;
                return;
            }
        }

        conn->write_pos += n;
    }

    // Tout envoy√©, repasser en mode lecture
    conn->write_pos = 0;
    conn->write_len = 0;
    conn->state = STATE_READING;

    // D√©sactiver EPOLLOUT
    struct epoll_event event;
    event.events = EPOLLIN | EPOLLET;
    event.data.ptr = conn;
    epoll_ctl(epfd, EPOLL_CTL_MOD, conn->fd, &event);
}

int main() {
    int server_fd, epfd;
    struct sockaddr_in addr;
    struct epoll_event event, events[MAX_EVENTS];

    // Cr√©er socket serveur
    server_fd = socket(AF_INET, SOCK_STREAM, 0);
    if (server_fd < 0) {
        perror("socket");
        exit(EXIT_FAILURE);
    }

    int opt = 1;
    setsockopt(server_fd, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));

    // Rendre non-bloquant
    if (set_nonblocking(server_fd) < 0) {
        perror("set_nonblocking");
        exit(EXIT_FAILURE);
    }

    // Bind
    memset(&addr, 0, sizeof(addr));
    addr.sin_family = AF_INET;
    addr.sin_addr.s_addr = INADDR_ANY;
    addr.sin_port = htons(PORT);

    if (bind(server_fd, (struct sockaddr*)&addr, sizeof(addr)) < 0) {
        perror("bind");
        exit(EXIT_FAILURE);
    }

    if (listen(server_fd, SOMAXCONN) < 0) {
        perror("listen");
        exit(EXIT_FAILURE);
    }

    // Cr√©er epoll
    epfd = epoll_create1(0);
    if (epfd < 0) {
        perror("epoll_create1");
        exit(EXIT_FAILURE);
    }

    // Ajouter serveur en Edge-Triggered
    event.events = EPOLLIN | EPOLLET;
    event.data.fd = server_fd;
    if (epoll_ctl(epfd, EPOLL_CTL_ADD, server_fd, &event) < 0) {
        perror("epoll_ctl");
        exit(EXIT_FAILURE);
    }

    printf("Serveur epoll ET sur port %d\n", PORT);

    // Boucle √©v√©nementielle
    while (1) {
        int n = epoll_wait(epfd, events, MAX_EVENTS, -1);

        for (int i = 0; i < n; i++) {
            if (events[i].data.fd == server_fd) {
                // Nouvelles connexions (Edge-Triggered)
                while (1) {
                    struct sockaddr_in client_addr;
                    socklen_t len = sizeof(client_addr);
                    int client_fd = accept(server_fd,
                                          (struct sockaddr*)&client_addr,
                                          &len);

                    if (client_fd < 0) {
                        if (errno == EAGAIN || errno == EWOULDBLOCK) {
                            break;  // Plus de connexions en attente
                        } else {
                            perror("accept");
                            break;
                        }
                    }

                    char ip[INET_ADDRSTRLEN];
                    inet_ntop(AF_INET, &client_addr.sin_addr, ip, sizeof(ip));
                    printf("[FD %d] Connexion de %s:%d\n",
                           client_fd, ip, ntohs(client_addr.sin_port));

                    // Rendre non-bloquant
                    set_nonblocking(client_fd);

                    // Cr√©er la connexion
                    connection_t *conn = malloc(sizeof(connection_t));
                    memset(conn, 0, sizeof(connection_t));
                    conn->fd = client_fd;
                    conn->state = STATE_READING;

                    // Ajouter √† epoll en Edge-Triggered
                    event.events = EPOLLIN | EPOLLET;
                    event.data.ptr = conn;
                    if (epoll_ctl(epfd, EPOLL_CTL_ADD, client_fd, &event) < 0) {
                        perror("epoll_ctl");
                        free(conn);
                        close(client_fd);
                    }
                }
            } else {
                // √âv√©nement client
                connection_t *conn = events[i].data.ptr;

                if (events[i].events & EPOLLIN) {
                    handle_read(epfd, conn);
                }

                if (events[i].events & EPOLLOUT) {
                    if (conn->state == STATE_WRITING) {
                        handle_write(epfd, conn);
                    }
                }

                // Fermer si n√©cessaire
                if (conn->state == STATE_CLOSING) {
                    epoll_ctl(epfd, EPOLL_CTL_DEL, conn->fd, NULL);
                    close(conn->fd);
                    free(conn);
                }
            }
        }
    }

    close(server_fd);
    close(epfd);
    return 0;
}
```

**Compilation :**
```bash
gcc -o server_epoll_et server_epoll_et.c -Wall -Wextra
./server_epoll_et
```

**Test :**
```bash
# Terminal 1
./server_epoll_et

# Terminal 2
telnet localhost 8080  
Hello  
# Le serveur renvoie : Hello
```

---

## Patterns Avanc√©s

### 1. Buffers Dynamiques

Pour g√©rer de grandes donn√©es, utilisez des buffers dynamiques redimensionnables.

```c
typedef struct {
    char *data;
    size_t capacity;
    size_t length;
} dynamic_buffer_t;

void buffer_append(dynamic_buffer_t *buf, const char *data, size_t len) {
    if (buf->length + len > buf->capacity) {
        // Redimensionner
        size_t new_capacity = (buf->capacity + len) * 2;
        char *new_data = realloc(buf->data, new_capacity);
        if (!new_data) {
            fprintf(stderr, "Erreur realloc\n");
            return;
        }
        buf->data = new_data;
        buf->capacity = new_capacity;
    }

    memcpy(buf->data + buf->length, data, len);
    buf->length += len;
}
```

---

### 2. Zero-Copy avec `sendfile()`

Pour envoyer des fichiers, utilisez `sendfile()` pour √©viter de copier en m√©moire.

```c
#include <sys/sendfile.h>

// Envoyer un fichier directement
int file_fd = open("file.txt", O_RDONLY);  
off_t offset = 0;  
size_t file_size = 1024;  

ssize_t sent = sendfile(socket_fd, file_fd, &offset, file_size);
```

**Avantages :**
- Pas de copie kernel ‚Üí userspace ‚Üí kernel
- Performance optimale
- Moins d'utilisation CPU

---

### 3. EPOLLONESHOT

Pour √©viter les race conditions dans les architectures multi-thread√©es.

```c
event.events = EPOLLIN | EPOLLONESHOT;  
event.data.ptr = conn;  
epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &event);  

// Apr√®s traitement, r√©-armer manuellement
event.events = EPOLLIN | EPOLLONESHOT;  
epoll_ctl(epfd, EPOLL_CTL_MOD, fd, &event);  
```

**Effet :** Le descripteur est automatiquement d√©sactiv√© apr√®s une notification.

---

### 4. EPOLLEXCLUSIVE (Linux 4.5+)

Pour r√©partir les connexions entre plusieurs threads/processus.

```c
event.events = EPOLLIN | EPOLLEXCLUSIVE;
```

**Effet :** Un seul thread/processus est r√©veill√© par √©v√©nement (√©vite le "thundering herd").

---

## Debugging et Profiling

### 1. V√©rifier les Sockets Non-Bloquants

```bash
# Voir les flags d'un socket
ls -l /proc/<PID>/fd/<FD>

# Avec lsof
lsof -p <PID>
```

---

### 2. Surveiller les √âv√©nements epoll

```c
// Logger les √©v√©nements
if (events[i].events & EPOLLIN)  printf("EPOLLIN\n");  
if (events[i].events & EPOLLOUT) printf("EPOLLOUT\n");  
if (events[i].events & EPOLLERR) printf("EPOLLERR\n");  
if (events[i].events & EPOLLHUP) printf("EPOLLHUP\n");  
```

---

### 3. Statistiques de Performance

```c
struct stats {
    uint64_t total_connections;
    uint64_t active_connections;
    uint64_t bytes_read;
    uint64_t bytes_written;
    time_t start_time;
};

void print_stats(struct stats *s) {
    time_t uptime = time(NULL) - s->start_time;
    printf("Uptime: %ld s\n", uptime);
    printf("Connexions totales: %lu\n", s->total_connections);
    printf("Connexions actives: %lu\n", s->active_connections);
    printf("D√©bit entrant: %.2f MB/s\n",
           s->bytes_read / (double)uptime / 1024 / 1024);
    printf("D√©bit sortant: %.2f MB/s\n",
           s->bytes_written / (double)uptime / 1024 / 1024);
}
```

---

## Erreurs Courantes et Solutions

### 1. Oublier de Tout Lire en ET

**Sympt√¥me :** Le serveur se bloque, ne r√©pond plus √† certains clients.

**Cause :** Pas de boucle `while` pour lire jusqu'√† `EAGAIN`.

**Solution :**
```c
// ‚úÖ Bon
while (1) {
    ssize_t n = recv(...);
    if (n < 0 && (errno == EAGAIN || errno == EWOULDBLOCK)) {
        break;  // Tout lu
    }
    // Traiter...
}
```

---

### 2. Ne Pas D√©sactiver EPOLLOUT

**Sympt√¥me :** `epoll_wait()` retourne continuellement, CPU √† 100%.

**Cause :** `EPOLLOUT` est toujours actif, m√™me quand il n'y a rien √† √©crire.

**Solution :** Activer `EPOLLOUT` seulement quand n√©cessaire, le d√©sactiver apr√®s.

```c
// Activer quand on a des donn√©es √† envoyer
event.events = EPOLLIN | EPOLLOUT | EPOLLET;  
epoll_ctl(epfd, EPOLL_CTL_MOD, fd, &event);  

// D√©sactiver quand tout est envoy√©
event.events = EPOLLIN | EPOLLET;  
epoll_ctl(epfd, EPOLL_CTL_MOD, fd, &event);  
```

---

### 3. Fuites M√©moire avec les Connexions

**Sympt√¥me :** M√©moire croissante sans limite.

**Cause :** Oublier de `free()` les structures de connexion.

**Solution :** Toujours lib√©rer lors de la fermeture.

```c
if (conn->state == STATE_CLOSING) {
    epoll_ctl(epfd, EPOLL_CTL_DEL, conn->fd, NULL);
    close(conn->fd);
    free(conn);  // ‚úÖ Important !
}
```

---

### 4. Socket Bloquant en Mode ET

**Sympt√¥me :** Le serveur se bloque compl√®tement.

**Cause :** Socket rest√© en mode bloquant avec epoll ET.

**Solution :** Toujours `set_nonblocking()` avant d'ajouter √† epoll ET.

```c
int client_fd = accept(...);  
set_nonblocking(client_fd);  // ‚úÖ Obligatoire en ET  
epoll_ctl(epfd, EPOLL_CTL_ADD, client_fd, &event);  
```

---

## Performances : Level-Triggered vs Edge-Triggered

### Benchmarks Typiques

**Configuration :** 10 000 connexions simultan√©es, 1000 requ√™tes/s

| M√©trique | Level-Triggered | Edge-Triggered |
|----------|-----------------|----------------|
| **CPU** | 35% | 22% |
| **Appels syst√®me** | ~20 000/s | ~12 000/s |
| **Latence (p99)** | 5 ms | 3 ms |
| **D√©bit max** | 50k req/s | 80k req/s |

**Gain ET :** ~30-40% de performance en haute charge.

---

## Architecture Recommand√©e : Multi-Processus + epoll

Pour exploiter tous les c≈ìurs CPU :

```
Processus 1 (Core 1) : epoll ET ‚Üí 25k connexions  
Processus 2 (Core 2) : epoll ET ‚Üí 25k connexions  
Processus 3 (Core 3) : epoll ET ‚Üí 25k connexions  
Processus 4 (Core 4) : epoll ET ‚Üí 25k connexions  

Total : 100k connexions, 4 c≈ìurs utilis√©s
```

**Impl√©mentation :**

```c
int main() {
    int num_workers = sysconf(_SC_NPROCESSORS_ONLN);  // Nombre de CPU

    for (int i = 0; i < num_workers; i++) {
        pid_t pid = fork();

        if (pid == 0) {
            // Processus fils
            worker_main();  // Boucle epoll
            exit(0);
        }
    }

    // Processus parent surveille les fils
    while (1) {
        wait(NULL);
    }
}
```

**Avec `SO_REUSEPORT` :**

```c
int opt = 1;  
setsockopt(server_fd, SOL_SOCKET, SO_REUSEPORT, &opt, sizeof(opt));  
```

Le kernel distribue automatiquement les connexions entre les processus.

---

## Comparaison Finale : Bloquant vs Non-Bloquant

| Aspect | Bloquant | Non-Bloquant |
|--------|----------|--------------|
| **Simplicit√©** | ‚úÖ Simple | ‚ùå Complexe |
| **Performance** | Moyenne | ‚úÖ Excellente |
| **Scalabilit√©** | Limit√©e | ‚úÖ > 100k clients |
| **CPU** | Plus √©lev√© | ‚úÖ Optimis√© |
| **Latence** | Moyenne | ‚úÖ Faible |
| **Debugging** | Facile | Difficile |
| **Code** | Court | Long |

---

## En R√©sum√©

Le **I/O non-bloquant** avec **epoll Edge-Triggered** est la base des serveurs haute performance modernes.

**Points cl√©s √† retenir :**

‚úÖ **Non-bloquant** : Les op√©rations retournent imm√©diatement

‚úÖ **EAGAIN** est normal : Signifie "r√©essayez plus tard"

‚úÖ **Edge-Triggered** : Notification seulement sur changements d'√©tat

‚úÖ **Tout lire** : En ET, boucler jusqu'√† `EAGAIN`

‚úÖ **G√©rer EPOLLOUT** : Activer/d√©sactiver selon les besoins

‚úÖ **√âtat par connexion** : Tracker lecture/√©criture/fermeture

‚úÖ **Buffers** : G√©rer les lectures/√©critures partielles

**Workflow typique :**

1. Cr√©er socket et le rendre **non-bloquant**
2. Ajouter √† `epoll()` avec `EPOLLET`
3. Sur `EPOLLIN` : Boucler `recv()` jusqu'√† `EAGAIN`
4. Traiter les donn√©es
5. Sur `EPOLLOUT` : Boucler `send()` jusqu'√† `EAGAIN` ou tout envoy√©
6. D√©sactiver `EPOLLOUT` quand plus rien √† envoyer

**Quand utiliser :**
- Serveurs haute performance (> 1000 clients)
- Applications sensibles √† la latence
- Besoins de scalabilit√© extr√™me

**Exemples de serveurs utilisant epoll ET :**
- Nginx
- Redis
- Memcached
- HAProxy

Dans la prochaine section, nous verrons comment cr√©er un mini-serveur HTTP complet utilisant toutes ces techniques.

---

**‚Üí Prochaine section : 20.10 Cr√©ation d'un Mini-Serveur HTTP**

‚è≠Ô∏è [Cr√©ation d'un mini-serveur HTTP](/20-reseau-sockets/10-mini-serveur-http.md)
