üîù Retour au [Sommaire](/SOMMAIRE.md)

# 27.2 Comprendre l'optimiseur

## Introduction

L'**optimiseur** est le composant du compilateur GCC qui transforme votre code source en un code machine plus efficace. Contrairement √† ce que l'on pourrait penser, le compilateur ne traduit pas litt√©ralement votre code C en assembleur : il l'analyse, le comprend, puis g√©n√®re un code √©quivalent mais plus performant.

Cette section vous explique comment fonctionne l'optimiseur, quelles transformations il effectue, et surtout comment vous pouvez **visualiser et comprendre ses d√©cisions**.

### Pourquoi comprendre l'optimiseur ?

- üîç **D√©boguer des comportements surprenants** : Certains bugs n'apparaissent qu'avec les optimisations
- üìà **√âcrire du code "optimiseur-friendly"** : Aider le compilateur √† mieux optimiser
- üß† **Am√©liorer votre compr√©hension** : Savoir ce qui se passe "sous le capot"
- ‚ö° **Identifier les goulots d'√©tranglement** : Comprendre pourquoi une partie du code est lente

---

## Le pipeline de compilation et d'optimisation

Lorsque vous compilez un fichier C, voici les grandes √©tapes travers√©es par votre code :

```
Code Source C
     ‚Üì
 [Pr√©processeur]
     ‚Üì
Code C √©tendu (apr√®s macros, includes)
     ‚Üì
 [Parseur / Analyseur]
     ‚Üì
AST (Arbre de Syntaxe Abstraite)
     ‚Üì
 [Front-end : optimisations ind√©pendantes du langage]
     ‚Üì
Repr√©sentation Interm√©diaire (GIMPLE en GCC)
     ‚Üì
 [Middle-end : OPTIMISEUR PRINCIPAL] ‚Üê C'EST ICI !
     ‚Üì
RTL (Register Transfer Language)
     ‚Üì
 [Back-end : optimisations sp√©cifiques au CPU]
     ‚Üì
Code Assembleur
     ‚Üì
 [Assembleur]
     ‚Üì
Code Machine (binaire)
```

L'**optimiseur principal** travaille sur une repr√©sentation interm√©diaire (GIMPLE dans GCC), qui est plus simple √† manipuler que le code assembleur final. Il applique des centaines de transformations diff√©rentes avant de passer le code au g√©n√©rateur de code machine.

---

## Principes fondamentaux de l'optimisation

### 1. Pr√©server la s√©mantique

**R√®gle d'or** : L'optimiseur **ne doit jamais changer le comportement observable** du programme.

```c
// Code original
int a = 5;
int b = 3;
int c = a + b;
printf("%d\n", c);

// L'optimiseur peut remplacer par
printf("%d\n", 8);

// Mais SEULEMENT si personne ne peut observer que 'a', 'b' et 'c' n'existent plus
```

Si votre programme produit le r√©sultat `8`, l'optimiseur peut remplacer tous les calculs par la constante `8` directement. C'est une transformation **s√©mantiquement √©quivalente**.

### 2. Analyse du flux de donn√©es

L'optimiseur analyse comment les donn√©es circulent dans votre programme :

```c
int x = 10;      // x vaut 10
int y = x + 5;   // y vaut 15, x est lu
x = 20;          // x vaut maintenant 20
// Si x n'est plus utilis√© apr√®s, cette ligne peut √™tre supprim√©e !
```

L'optimiseur construit un graphe montrant :
- **O√π chaque variable est d√©finie** (affect√©e)
- **O√π elle est utilis√©e** (lue)
- **Quelle valeur elle peut avoir** √† chaque point du programme

### 3. Analyse du flux de contr√¥le

L'optimiseur comprend la structure de votre programme (if, boucles, fonctions) :

```c
if (1) {  // Condition toujours vraie
    printf("Hello\n");
} else {
    printf("World\n");  // Code mort, jamais ex√©cut√©
}

// L'optimiseur transforme en :
printf("Hello\n");
```

---

## Les grandes familles d'optimisations

### 1. Optimisations locales (au niveau d'un bloc de base)

Un **bloc de base** est une s√©quence d'instructions sans branchement (pas de `if`, `for`, etc.). Ce sont les optimisations les plus simples.

#### a) √âlimination des sous-expressions communes (CSE)

**Avant :**
```c
int a = b + c;
int d = b + c;  // On recalcule la m√™me chose !
```

**Apr√®s :**
```c
int a = b + c;
int d = a;      // R√©utilisation du r√©sultat
```

L'optimiseur d√©tecte que `b + c` est calcul√© deux fois avec les m√™mes valeurs.

#### b) Propagation de constantes

**Avant :**
```c
int x = 5;
int y = x + 3;
int z = y * 2;
```

**Apr√®s :**
```c
int z = 16;  // (5 + 3) * 2 = 16
```

Si toutes les valeurs sont connues √† la compilation, l'optimiseur effectue les calculs directement.

#### c) Alg√®bre de simplification

**Avant :**
```c
int x = a * 1;        // Multiplication par 1
int y = b + 0;        // Addition de 0
int z = c - c;        // Soustraction identique
int w = d / 1;        // Division par 1
```

**Apr√®s :**
```c
int x = a;
int y = b;
int z = 0;
int w = d;
```

L'optimiseur conna√Æt les propri√©t√©s math√©matiques de base.

#### d) Repliement de constantes (Constant Folding)

**Avant :**
```c
int surface = 10 * 20;
```

**Apr√®s :**
```c
int surface = 200;
```

Les calculs entre constantes sont effectu√©s √† la compilation.

---

### 2. Optimisations globales (au niveau d'une fonction)

Ces optimisations analysent plusieurs blocs de base et les chemins d'ex√©cution possibles.

#### a) √âlimination de code mort (Dead Code Elimination)

**Avant :**
```c
void fonction() {
    int x = 10;  // Variable jamais utilis√©e
    int y = 20;
    printf("%d\n", y);
}
```

**Apr√®s :**
```c
void fonction() {
    int y = 20;
    printf("%d\n", y);
}
```

Si une variable n'est jamais lue, son calcul et son stockage sont inutiles.

#### b) Inlining de fonctions

**Avant :**
```c
int carre(int x) {
    return x * x;
}

int main() {
    int resultat = carre(5);
}
```

**Apr√®s :**
```c
int main() {
    int resultat = 5 * 5;  // La fonction est "int√©gr√©e"
}
```

**Avantages :**
- ‚úÖ √âlimine l'overhead de l'appel de fonction (push/pop de la pile)
- ‚úÖ Permet d'autres optimisations (propagation de constantes)

**Inconv√©nients :**
- ‚ùå Augmente la taille du code
- ‚ùå Peut saturer le cache d'instructions

**Crit√®res de d√©cision :**
- Taille de la fonction (petites fonctions sont des candidates id√©ales)
- Fr√©quence d'appel (fonctions appel√©es souvent sont prioritaires)
- Niveau d'optimisation (`-O2` est conservateur, `-O3` est agressif)

#### c) Optimisation de boucles : D√©placement de code invariant

**Avant :**
```c
for (int i = 0; i < 1000; i++) {
    int limite = calcul_complexe();  // M√™me r√©sultat √† chaque it√©ration
    tableau[i] = i * limite;
}
```

**Apr√®s :**
```c
int limite = calcul_complexe();  // Sorti de la boucle !
for (int i = 0; i < 1000; i++) {
    tableau[i] = i * limite;
}
```

Si un calcul dans une boucle produit toujours le m√™me r√©sultat, l'optimiseur le d√©place √† l'ext√©rieur.

#### d) D√©roulage de boucles (Loop Unrolling)

**Avant :**
```c
for (int i = 0; i < 4; i++) {
    tableau[i] = i;
}
```

**Apr√®s :**
```c
tableau[0] = 0;
tableau[1] = 1;
tableau[2] = 2;
tableau[3] = 3;
```

**Avantages :**
- ‚úÖ √âlimine les sauts conditionnels (instructions de branchement)
- ‚úÖ Permet la parall√©lisation par le CPU (instruction-level parallelism)
- ‚úÖ R√©duit les it√©rations de boucle

**Inconv√©nients :**
- ‚ùå Augmente fortement la taille du code
- ‚ùå Peut d√©grader les performances si le code d√©passe le cache

**GCC d√©roule automatiquement :**
- Petites boucles avec un nombre d'it√©rations connu
- Avec `-O3` ou `-funroll-loops`

---

### 3. Optimisations inter-proc√©durales (IPO)

Ces optimisations analysent **plusieurs fonctions** ensemble, parfois m√™me plusieurs fichiers avec `-flto`.

#### a) Propagation de constantes entre fonctions

**Avant :**
```c
int calcul(int x) {
    return x * 2 + 10;
}

int main() {
    int resultat = calcul(5);
}
```

**Apr√®s :**
```c
int main() {
    int resultat = 20;  // (5 * 2 + 10) calcul√© √† la compilation
}
```

Si l'optimiseur voit que `calcul()` est toujours appel√©e avec `5`, il peut calculer le r√©sultat directement.

#### b) √âlimination de fonctions non utilis√©es

Avec `-flto`, GCC peut d√©tecter qu'une fonction n'est appel√©e nulle part dans le programme entier et la supprimer compl√®tement.

---

## Repr√©sentation interm√©diaire : GIMPLE

### Qu'est-ce que GIMPLE ?

**GIMPLE** est une repr√©sentation simplifi√©e de votre code C, plus facile √† analyser et transformer. Chaque instruction GIMPLE est tr√®s simple (3 adresses maximum).

**Exemple de transformation :**

**Code C :**
```c
int resultat = (a + b) * (c + d);
```

**Repr√©sentation GIMPLE (simplifi√©e) :**
```
t1 = a + b
t2 = c + d
resultat = t1 * t2
```

Chaque op√©ration complexe est d√©compos√©e en op√©rations √©l√©mentaires sur des **variables temporaires** (t1, t2...).

### Visualiser le GIMPLE

```bash
# G√©n√©rer la repr√©sentation GIMPLE
gcc -fdump-tree-gimple -O2 mon_programme.c

# Cela cr√©e un fichier : mon_programme.c.004t.gimple
cat mon_programme.c.004t.gimple
```

**Exemple complet :**

```c
// fichier: exemple.c
int somme(int a, int b) {
    return a + b;
}

int main() {
    int x = 5;
    int y = 10;
    int z = somme(x, y);
    return 0;
}
```

**Commande :**
```bash
gcc -fdump-tree-all -O2 exemple.c
```

Cela g√©n√®re de nombreux fichiers `.t` montrant chaque passe d'optimisation :
- `exemple.c.004t.gimple` : GIMPLE initial
- `exemple.c.010t.cfg` : Control Flow Graph
- `exemple.c.030t.inline` : Apr√®s inlining
- `exemple.c.235t.optimized` : GIMPLE final optimis√©
- etc.

---

## Visualiser les optimisations en action

### M√©thode 1 : Comparer l'assembleur

**Exemple de code :**
```c
// fichier: test.c
int somme_tableau(int *tab, int taille) {
    int resultat = 0;
    for (int i = 0; i < taille; i++) {
        resultat += tab[i];
    }
    return resultat;
}
```

**Sans optimisation :**
```bash
gcc -O0 -S test.c -o test_O0.s
```

**Avec optimisation :**
```bash
gcc -O2 -S test.c -o test_O2.s
```

**Comparaison :**
```bash
# Compter les lignes d'assembleur
wc -l test_O0.s test_O2.s

# Exemple de r√©sultat :
# 45 test_O0.s
# 28 test_O2.s  ‚Üê Moins de lignes = plus optimis√©
```

Vous pouvez ouvrir les deux fichiers et voir concr√®tement les diff√©rences.

### M√©thode 2 : Utiliser Compiler Explorer (Godbolt)

**Outil en ligne** : https://godbolt.org/

Cet outil g√©nial vous permet de :
1. √âcrire du code C dans le navigateur
2. Voir l'assembleur g√©n√©r√© **en temps r√©el**
3. Comparer diff√©rents niveaux d'optimisation c√¥te √† c√¥te
4. Colorer les correspondances entre code C et assembleur

**Exemple d'utilisation :**
```c
int carre(int x) {
    return x * x;
}

int main() {
    return carre(5);
}
```

Sur Godbolt, vous verrez qu'avec `-O2`, tout le code se r√©duit √† :
```asm
main:
    mov eax, 25    ; R√©sultat directement !
    ret
```

### M√©thode 3 : Dumps d'optimisation de GCC

GCC peut g√©n√©rer des rapports d√©taill√©s de ses optimisations :

```bash
# Afficher toutes les optimisations appliqu√©es
gcc -O2 -fopt-info-all test.c -o test

# Optimisations de boucles uniquement
gcc -O2 -fopt-info-loop test.c -o test

# Inlining
gcc -O2 -fopt-info-inline test.c -o test

# Vectorisation
gcc -O2 -fopt-info-vec test.c -o test
```

**Exemple de sortie :**
```
test.c:5:5: optimized: loop vectorized using 16 byte vectors
test.c:12:9: optimized: Inlining calcul into main
```

---

## Limites de l'optimiseur

### 1. L'optimiseur n'est pas omniscient

L'optimiseur ne peut optimiser que ce qu'il **peut prouver**.

**Exemple : Aliasing de pointeurs**

```c
void increment(int *a, int *b) {
    *a = *a + 1;
    *b = *b + 1;
}
```

L'optimiseur **ne sait pas** si `a` et `b` pointent vers la m√™me adresse ou non. Il doit donc g√©n√©rer du code qui fonctionne dans les deux cas, ce qui limite les optimisations possibles.

**Solution : Le mot-cl√© `restrict`**
```c
void increment(int *restrict a, int *restrict b) {
    *a = *a + 1;
    *b = *b + 1;
}
```

`restrict` est une promesse au compilateur que `a` et `b` ne pointent **jamais** vers la m√™me zone m√©moire. Cela permet de meilleures optimisations.

### 2. Comportement ind√©fini (Undefined Behavior)

L'optimiseur **suppose que votre code ne contient pas de comportement ind√©fini**.

**Exemple de pi√®ge :**
```c
int main() {
    int x = 10;
    x = x + 1;  // OK

    int y;
    y = y + 1;  // UNDEFINED BEHAVIOR : y non initialis√©

    return y;
}
```

Avec `-O0`, `y` pourrait contenir 0 (ou une valeur al√©atoire). Avec `-O2`, l'optimiseur pourrait **supprimer compl√®tement** la variable `y` car son comportement est ind√©fini.

**R√®gle d'or :** Toujours initialiser vos variables !

### 3. L'optimiseur peut √™tre "tromp√©"

Certains patterns de code emp√™chent l'optimiseur de faire son travail.

**Exemple : Appels de fonction opaques**

```c
int calcul_complexe(int x);  // D√©finie ailleurs

void traitement(int *tab, int taille) {
    for (int i = 0; i < taille; i++) {
        tab[i] = calcul_complexe(i);  // Appel de fonction
    }
}
```

Si `calcul_complexe()` est dans un autre fichier (compilation s√©par√©e sans LTO), l'optimiseur ne peut pas l'analyser et donc ne peut pas :
- La rendre inline
- Optimiser la boucle en fonction de son contenu
- Propager des constantes √† travers elle

**Solution :** Utiliser `-flto` (Link-Time Optimization) pour l'optimisation inter-fichiers.

---

## Aider l'optimiseur : Bonnes pratiques

### 1. Marquer les fonctions `inline`

Pour les petites fonctions appel√©es fr√©quemment :

```c
inline int min(int a, int b) {
    return (a < b) ? a : b;
}
```

Le mot-cl√© `inline` est un **hint** (suggestion) au compilateur, pas une obligation. Avec `-O2`, GCC ignore souvent votre `inline` et prend ses propres d√©cisions.

### 2. Utiliser `const` pour les param√®tres

```c
int somme_tableau(const int *tab, int taille) {
    // L'optimiseur sait que 'tab' ne sera pas modifi√©
}
```

`const` aide l'optimiseur √† comprendre les intentions du code.

### 3. Utiliser `restrict` pour les pointeurs

```c
void copie(int *restrict dest, const int *restrict src, int n) {
    for (int i = 0; i < n; i++) {
        dest[i] = src[i];
    }
}
```

### 4. D√©clarer les fonctions `static` quand possible

```c
static int fonction_interne(int x) {
    return x * 2;
}
```

Une fonction `static` n'est pas visible hors du fichier. L'optimiseur peut donc l'optimiser plus agressivement (inlining, suppression si non utilis√©e, etc.).

### 5. √âviter les variables globales

```c
// Mauvais : difficile √† optimiser
int compteur_global = 0;

void increment() {
    compteur_global++;
}

// Meilleur : optimisation locale possible
void traitement() {
    int compteur = 0;
    compteur++;
}
```

Les variables globales peuvent √™tre modifi√©es par n'importe quelle fonction, ce qui complique l'analyse de l'optimiseur.

### 6. √âcrire du code simple et clair

**L'optimiseur pr√©f√®re le code simple !**

```c
// Code "malin" mais difficile √† optimiser
int valeur = (x & 1) ? ((x >> 1) + 1) : (x >> 1);

// Code clair et facile √† optimiser
int valeur = x / 2;
if (x % 2 == 1) {
    valeur++;
}
```

Paradoxalement, le code le plus simple est souvent le plus rapide apr√®s optimisation.

---

## Cas d'√©tude : Optimisation d'une boucle

### Code initial (na√Øf)

```c
int somme_carres(int n) {
    int resultat = 0;
    for (int i = 1; i <= n; i++) {
        resultat = resultat + (i * i);
    }
    return resultat;
}
```

### √âtapes d'optimisation par GCC (avec `-O2`)

**√âtape 1 : Simplification des expressions**
```c
int somme_carres(int n) {
    int resultat = 0;
    for (int i = 1; i <= n; i++) {
        resultat += i * i;  // Op√©rateur compos√©
    }
    return resultat;
}
```

**√âtape 2 : D√©roulage partiel de boucle (si activ√©)**
```c
int somme_carres(int n) {
    int resultat = 0;
    int i = 1;

    // Traiter 4 √©l√©ments √† la fois
    for (; i <= n - 3; i += 4) {
        resultat += i * i;
        resultat += (i+1) * (i+1);
        resultat += (i+2) * (i+2);
        resultat += (i+3) * (i+3);
    }

    // Reste de la boucle
    for (; i <= n; i++) {
        resultat += i * i;
    }
    return resultat;
}
```

**√âtape 3 : Vectorisation (si CPU supporte SIMD)**

Le compilateur peut utiliser des instructions vectorielles (SSE, AVX) pour calculer plusieurs carr√©s en parall√®le.

### R√©sultat final en assembleur

Avec `-O2 -march=native`, le code peut √™tre r√©duit √† quelques instructions vectorielles ultra-efficaces.

**V√©rification :**
```bash
gcc -O2 -march=native -S somme_carres.c
cat somme_carres.s
```

---

## Optimisations sp√©cifiques selon l'architecture

### Optimisations pour x86-64

- **Utilisation des registres** : x86-64 a 16 registres g√©n√©raux (vs 8 en 32-bit)
- **Instructions SIMD** : SSE, AVX, AVX2, AVX-512 pour le calcul parall√®le
- **Pr√©diction de branchement** : R√©organisation du code pour aider le CPU

### Optimisations pour ARM

- **Load/Store architecture** : Plus de load/store, moins d'instructions complexes
- **Conditional execution** : Instructions conditionnelles natives
- **NEON** : Instructions SIMD pour ARM

### Voir les optimisations appliqu√©es

```bash
# Verbose : affiche les optimisations activ√©es
gcc -O2 -fopt-info-vec-optimized -march=native test.c
```

---

## Outils pour analyser l'optimisation

### 1. `objdump` : D√©sassembler un binaire

```bash
# Compiler
gcc -O2 test.c -o test

# D√©sassembler
objdump -d test > test.asm
```

Utile pour voir le code machine final.

### 2. `perf` : Profiler les performances

```bash
# Compiler avec symboles de debug
gcc -O2 -g test.c -o test

# Profiler
perf record ./test
perf report
```

`perf` montre quelles parties du code consomment le plus de temps CPU.

### 3. `gprof` : Profiler classique

```bash
# Compiler avec profiling
gcc -O2 -pg test.c -o test

# Ex√©cuter
./test

# G√©n√©rer le rapport
gprof test gmon.out > rapport.txt
```

### 4. `valgrind --tool=cachegrind` : Analyser le cache

```bash
valgrind --tool=cachegrind ./test
cg_annotate cachegrind.out.<pid>
```

Montre les miss de cache (acc√®s m√©moire lents).

---

## Erreurs d'optimisation courantes

### 1. L'optimiseur "casse" mon code !

**Sympt√¥me :** Le code fonctionne avec `-O0` mais plante avec `-O2`.

**Causes possibles :**
- **Comportement ind√©fini** : Variables non initialis√©es, d√©passement de buffer, etc.
- **Violation de l'aliasing** : Cast de pointeurs incompatibles
- **Code d√©pendant de l'ordre d'√©valuation**

**Solution :** Utilisez les sanitizers pour d√©tecter les bugs :
```bash
gcc -O2 -fsanitize=address,undefined test.c -o test
./test
```

### 2. L'optimisation rend le d√©bogage impossible

**Sympt√¥me :** Avec GDB, les variables affichent des valeurs bizarres, le code "saute".

**Cause :** Les optimisations modifient l'ordre du code et suppriment des variables.

**Solution :** Compiler avec `-Og` (optimisations compatibles avec le d√©bogage) :
```bash
gcc -Og -g test.c -o test
gdb ./test
```

### 3. Le code optimis√© est plus lent !

**Sympt√¥me :** `-O3` est plus lent que `-O2`.

**Cause :** Le code d√©roul√©/inlin√© est trop gros et sature le cache d'instructions.

**Solution :** Mesurer les performances r√©elles et rester sur `-O2` si c'est plus rapide.

---

## R√©sum√© des concepts cl√©s

| Concept | Description | Impact |
|---------|-------------|--------|
| **CSE** | √âlimination des calculs redondants | ‚¨ÜÔ∏è Vitesse |
| **Propagation de constantes** | Calculs √† la compilation | ‚¨ÜÔ∏è Vitesse, ‚¨áÔ∏è Taille |
| **Dead code elimination** | Suppression du code inutile | ‚¨áÔ∏è Taille |
| **Inlining** | Int√©gration de fonctions | ‚¨ÜÔ∏è Vitesse, ‚¨ÜÔ∏è Taille |
| **Loop unrolling** | D√©roulage de boucles | ‚¨ÜÔ∏è Vitesse, ‚¨ÜÔ∏è‚¨ÜÔ∏è Taille |
| **Vectorisation** | Utilisation SIMD | ‚¨ÜÔ∏è‚¨ÜÔ∏è Vitesse |
| **IPO/LTO** | Optimisation inter-fichiers | ‚¨ÜÔ∏è Vitesse, ‚¨áÔ∏è Taille |

---

## Checklist : √âcrire du code optimisable

- ‚úÖ Initialiser toutes les variables
- ‚úÖ Utiliser `const` pour les param√®tres en lecture seule
- ‚úÖ Utiliser `restrict` pour les pointeurs non-alias√©s
- ‚úÖ Marquer les fonctions internes comme `static`
- ‚úÖ Pr√©f√©rer les variables locales aux globales
- ‚úÖ √âcrire du code simple et lisible
- ‚úÖ √âviter les casts de pointeurs dangereux
- ‚úÖ Compiler avec `-Wall -Wextra` pour d√©tecter les probl√®mes
- ‚úÖ Tester avec les sanitizers (`-fsanitize=address,undefined`)
- ‚úÖ Mesurer les performances avant d'optimiser manuellement

---

## Pour aller plus loin

### Visualiser l'optimiseur en action

1. **Compiler Explorer (Godbolt)** : https://godbolt.org/
   - Voir l'assembleur en temps r√©el
   - Comparer diff√©rents compilateurs et niveaux d'optimisation

2. **GCC Dump Files** :
   ```bash
   gcc -fdump-tree-all -O2 test.c
   ls -l test.c.*t.*  # Tous les dumps interm√©diaires
   ```

3. **Rapport d'optimisation** :
   ```bash
   gcc -O2 -fopt-info-all test.c
   ```

### Documentation officielle

```bash
# Documentation GCC sur les optimisations
info gcc "Optimize Options"

# Liste des passes d'optimisation
gcc --help=optimizers
```

### Lectures recommand√©es

- **"Engineering a Compiler"** par Cooper & Torczon (livre de r√©f√©rence)
- **GCC Internals Manual** : https://gcc.gnu.org/onlinedocs/gccint/
- **Blog de Matt Godbolt** : cr√©ateur de Compiler Explorer

---

## Conclusion

Comprendre l'optimiseur vous permet de :

1. **√âcrire du meilleur code** : Code "optimiseur-friendly"
2. **D√©boguer efficacement** : Comprendre pourquoi le code optimis√© se comporte diff√©remment
3. **Faire des choix √©clair√©s** : Savoir quand utiliser `-O2`, `-O3`, ou `-Os`
4. **√âviter les pi√®ges** : D√©tecter le comportement ind√©fini avant qu'il ne cause des bugs

**R√®gle d'or :** L'optimiseur est votre alli√©, mais il ne peut optimiser que du code correct. √âcrivez d'abord du code propre, sans bugs, puis laissez le compilateur faire le reste !

---

*Prochaine section : 27.3 Profiling*

‚è≠Ô∏è [Profiling](/27-optimisation-performance/03-profiling.md)
