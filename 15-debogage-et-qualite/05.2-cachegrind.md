ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 15.5.2 Cachegrind - Analyse des Performances du Cache

## Introduction

Cachegrind est un outil de profiling de Valgrind qui **simule** le comportement du cache CPU de votre machine pour analyser comment votre programme l'utilise. Il vous aide Ã  comprendre pourquoi votre programme est lent et comment l'optimiser.

### Pourquoi le cache est-il important ?

Pour comprendre l'utilitÃ© de Cachegrind, il faut d'abord comprendre le problÃ¨me qu'il rÃ©sout : la **hiÃ©rarchie mÃ©moire**.

**Le problÃ¨me fondamental :**
- Le CPU (processeur) est **extrÃªmement rapide** (~3 GHz = 3 milliards d'opÃ©rations/seconde)
- La RAM est **relativement lente** (~100-200 cycles pour accÃ©der Ã  une donnÃ©e)
- â¡ï¸ Le CPU passe son temps Ã  **attendre** que les donnÃ©es arrivent de la RAM !

**La solution : Le cache CPU**

Le cache est une mÃ©moire **trÃ¨s rapide** mais **petite** situÃ©e directement dans le processeur. Elle stocke les donnÃ©es frÃ©quemment utilisÃ©es pour Ã©viter d'aller chercher dans la RAM lente.

---

## Comprendre la HiÃ©rarchie du Cache

Les processeurs modernes ont gÃ©nÃ©ralement **3 niveaux de cache** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CPU (Processeur)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Registres (le plus rapide, ~0.5 cycles)               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                        â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ L1 Cache â”‚ (~32 KB, 3-4 cycles)       â”‚ L1 Cache â”‚
   â”‚  Data    â”‚                            â”‚   Instr  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚                                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   L2 Cache     â”‚ (~256 KB, 10-12 cycles)
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   L3 Cache     â”‚ (~8-32 MB, 40-75 cycles)
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   RAM (DDR4)   â”‚ (~4-32 GB, 100-200 cycles)
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Les diffÃ©rents niveaux

| Niveau | Taille | Vitesse | PartagÃ© |
|--------|--------|---------|---------|
| **L1** | ~32-64 KB | 3-4 cycles | Par cÅ“ur CPU |
| **L2** | ~256-512 KB | 10-12 cycles | Par cÅ“ur CPU |
| **L3** | 8-64 MB | 40-75 cycles | Entre tous les cÅ“urs |
| **RAM** | 4-128 GB | 100-200 cycles | - |

**Point clÃ© :** Un accÃ¨s Ã  la RAM est **25 Ã  50 fois plus lent** qu'un accÃ¨s au cache L1 !

---

## Cache Hit vs Cache Miss

### Cache Hit âœ…

Quand le CPU demande une donnÃ©e et qu'elle est **dÃ©jÃ  dans le cache** :

```c
int tableau[100];  
for (int i = 0; i < 100; i++) {  
    tableau[i] = i;  // Les Ã©lÃ©ments proches sont dans le cache
}
```

â¡ï¸ **Rapide** : Les donnÃ©es sont chargÃ©es par blocs (lignes de cache de 64 octets)

### Cache Miss âŒ

Quand le CPU demande une donnÃ©e et qu'elle **n'est pas dans le cache** :

```c
int tableau[1000000];  
for (int i = 0; i < 1000000; i += 1000) {  
    tableau[i] = i;  // AccÃ¨s espacÃ©s = beaucoup de misses
}
```

â¡ï¸ **Lent** : Le CPU doit aller chercher dans la RAM

---

## Types de Cache Misses

Cachegrind distingue **3 types de cache misses** :

### 1. Compulsory Miss (Cold Miss)

Premier accÃ¨s Ã  une donnÃ©e jamais vue auparavant.

```c
int x = 10;  // PremiÃ¨re fois qu'on accÃ¨de Ã  x
              // â¡ï¸ Compulsory miss (inÃ©vitable)
```

**InÃ©vitable** : La premiÃ¨re fois, la donnÃ©e n'est pas dans le cache.

### 2. Capacity Miss

Le cache est **trop petit** pour contenir toutes les donnÃ©es nÃ©cessaires.

```c
int tableau[10000000];  // 40 MB de donnÃ©es  
for (int i = 0; i < 10000000; i++) {  
    tableau[i] = i;  // Ne rentre pas dans le cache L3 (8-32 MB)
}
```

**Solution** : Travailler sur des blocs de donnÃ©es plus petits (blocking/tiling).

### 3. Conflict Miss (ou Associativity Miss)

Deux donnÃ©es diffÃ©rentes veulent utiliser le **mÃªme emplacement** dans le cache.

```c
// Exemple simplifiÃ© (le vrai comportement est plus complexe)
int a[1024];  
int b[1024];  
// Si a et b sont mappÃ©s aux mÃªmes lignes de cache,
// ils vont se "chasser" mutuellement (cache thrashing)
```

**Solution** : RÃ©organiser les donnÃ©es ou l'ordre d'accÃ¨s.

---

## Installation et Utilisation de Cachegrind

### Installation

Cachegrind est inclus dans Valgrind :

```bash
# VÃ©rifier l'installation
valgrind --tool=cachegrind --version
```

### Compilation

Compilez votre programme normalement, idÃ©alement avec les symboles de dÃ©bogage :

```bash
gcc -g -O2 mon_programme.c -o mon_programme
```

**Note :** Contrairement Ã  Memcheck ou Helgrind, vous **pouvez** compiler avec optimisations (`-O2` ou `-O3`) car vous voulez profiler le code rÃ©el.

### ExÃ©cution de base

```bash
valgrind --tool=cachegrind ./mon_programme
```

**Exemple complet :**

```bash
$ valgrind --tool=cachegrind ./test_cache
==23456== Cachegrind, a cache and branch-prediction profiler
==23456== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.
==23456== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==23456== Command: ./test_cache
==23456==
--23456-- warning: L3 cache found, using its data for the LL simulation.
Programme terminÃ©
==23456==
==23456== I   refs:      1,234,567
==23456== I1  misses:        1,234
==23456== LLi misses:          567
==23456== I1  miss rate:      0.10%
==23456== LLi miss rate:      0.05%
==23456==
==23456== D   refs:        987,654  (765,432 rd   + 222,222 wr)
==23456== D1  misses:       12,345  ( 10,000 rd   +   2,345 wr)
==23456== LLd misses:        5,678  (  4,000 rd   +   1,678 wr)
==23456== D1  miss rate:       1.2% (    1.3%     +     1.1%  )
==23456== LLd miss rate:       0.6% (    0.5%     +     0.8%  )
==23456==
==23456== LL refs:          13,579  ( 11,234 rd   +   2,345 wr)
==23456== LL misses:         6,245  (  4,567 rd   +   1,678 wr)
==23456== LL miss rate:        0.3% (    0.2%     +     0.7%  )
```

---

## Comprendre les Statistiques de Cachegrind

### Explication des termes

**Instructions (I) :**
- **I refs** : Nombre total d'instructions exÃ©cutÃ©es
- **I1 misses** : Cache misses au niveau L1 pour les instructions
- **LLi misses** : Cache misses au dernier niveau (Last Level, gÃ©nÃ©ralement L3)

**DonnÃ©es (D) :**
- **D refs** : Nombre total d'accÃ¨s aux donnÃ©es
- **rd** : Lectures (reads)
- **wr** : Ã‰critures (writes)
- **D1 misses** : Cache misses au niveau L1 pour les donnÃ©es
- **LLd misses** : Cache misses au dernier niveau pour les donnÃ©es

**Global (LL = Last Level) :**
- **LL refs** : Total des accÃ¨s au dernier niveau de cache
- **LL misses** : Total des cache misses au dernier niveau
- **LL miss rate** : Pourcentage de misses (plus c'est bas, mieux c'est)

### Que rechercher ?

**âœ… Bon :**
- D1 miss rate < 1%
- LL miss rate < 0.5%

**âš ï¸ Moyen :**
- D1 miss rate : 1-5%
- LL miss rate : 0.5-2%

**âŒ ProblÃ©matique :**
- D1 miss rate > 5%
- LL miss rate > 2%

---

## Analyse DÃ©taillÃ©e avec Annotate

Le vrai pouvoir de Cachegrind est l'annotation ligne par ligne de votre code source.

### GÃ©nÃ©rer le fichier d'annotation

Cachegrind gÃ©nÃ¨re automatiquement un fichier `cachegrind.out.<pid>` :

```bash
$ ls cachegrind.out.*
cachegrind.out.23456
```

Pour **analyser ce fichier** et voir les dÃ©tails ligne par ligne :

```bash
cg_annotate cachegrind.out.23456
```

### Exemple de sortie annotÃ©e

```
--------------------------------------------------------------------------------
Ir          I1mr  ILmr  Dr          D1mr   DLmr   Dw         D1mw   DLmw  file:function
--------------------------------------------------------------------------------
1,234,567    567    89  987,654    12,345  5,678  222,222    2,345  1,678  PROGRAM TOTALS

--------------------------------------------------------------------------------
    Ir    I1mr  ILmr      Dr    D1mr  DLmr      Dw    D1mw  DLmw  file:function
--------------------------------------------------------------------------------
500,000     100    20  400,000  10,000 4,000  100,000   2,000 1,500  test.c:process_array
300,000      50    10  200,000   1,500   800   50,000     300   150  test.c:calculate
200,000      30     5  150,000     800   500   30,000      40    25  test.c:main
...
```

**Colonnes importantes :**
- **Ir** : Instructions exÃ©cutÃ©es
- **Dr** : Lectures de donnÃ©es
- **Dw** : Ã‰critures de donnÃ©es
- **D1mr** : Cache misses L1 en lecture
- **DLmr** : Cache misses dernier niveau en lecture

### Annotation du code source

Pour voir les misses **ligne par ligne** dans votre code :

```bash
cg_annotate --auto=yes cachegrind.out.23456 test.c
```

**Exemple de sortie :**

```c
-- line 45 ----------------------------------------
          Ir    Dr    Dw    D1mr  D1mw  ILmr  DLmr  DLmw
           .     .     .      .     .     .     .     . void process_array(int *data, int size) {
      10,000 5,000     .    500     .    10    20     .     for (int i = 0; i < size; i++) {
     500,000 400,000 100,000 10,000 2,000  20 4,000 1,500         data[i] = data[i] * 2;
           .     .     .      .     .     .     .     .     }
           .     .     .      .     .     .     .     . }
```

**InterprÃ©tation :**
- La ligne `data[i] = data[i] * 2;` gÃ©nÃ¨re **10,000 cache misses L1** en lecture
- C'est cette ligne qui pose problÃ¨me !

---

## Visualisation Graphique avec KCachegrind

### Installation

```bash
sudo apt install kcachegrind  # Ubuntu/Debian
```

### Utilisation

```bash
# 1. ExÃ©cuter Cachegrind
valgrind --tool=cachegrind --cachegrind-out-file=cachegrind.out ./mon_programme

# 2. Ouvrir avec KCachegrind
kcachegrind cachegrind.out
```

### Interface de KCachegrind

KCachegrind offre une **interface graphique** avec :

**ğŸ“Š Graphiques :**
- Diagrammes circulaires des fonctions les plus coÃ»teuses
- Graphes d'appels (call graphs)
- Flamegraphs

**ğŸ” Analyses :**
- Tri des fonctions par nombre de cache misses
- Vue du code source annotÃ© avec code couleur
- Comparaison entre diffÃ©rents profils

**ğŸ’¡ Avantage :** Beaucoup plus intuitif que la ligne de commande pour identifier les goulots d'Ã©tranglement.

---

## Options AvancÃ©es de Cachegrind

### Simuler une architecture spÃ©cifique

Par dÃ©faut, Cachegrind utilise les caractÃ©ristiques du cache de votre CPU. Vous pouvez simuler une autre configuration :

```bash
valgrind --tool=cachegrind \
  --I1=32768,8,64 \      # L1 instruction: 32KB, 8-way, ligne 64B
  --D1=32768,8,64 \      # L1 data: 32KB, 8-way, ligne 64B
  --LL=8388608,16,64 \   # Last level: 8MB, 16-way, ligne 64B
  ./mon_programme
```

**Format :** `taille,associativitÃ©,taille_ligne`

### Collecter les statistiques de branchement

```bash
valgrind --tool=cachegrind --branch-sim=yes ./mon_programme
```

Cela ajoute les statistiques de **branch prediction** (prÃ©diction de branchement) :
- **Bc** : Branches conditionnelles exÃ©cutÃ©es
- **Bcm** : Branches conditionnelles mal prÃ©dites

---

## Exemples Pratiques d'Optimisation

### ProblÃ¨me 1 : AccÃ¨s non sÃ©quentiels

**Code inefficace (mauvaise localitÃ© spatiale) :**

```c
#define N 1000
int matrix[N][N];

// âŒ AccÃ¨de aux colonnes (sauts de N Ã©lÃ©ments Ã  chaque itÃ©ration)
void bad_access() {
    for (int col = 0; col < N; col++) {
        for (int row = 0; row < N; row++) {
            matrix[row][col] = 0;  // Cache miss frÃ©quents !
        }
    }
}
```

**RÃ©sultat Cachegrind :**
```
D1 miss rate: 25% âŒ
```

**Code optimisÃ© (bonne localitÃ© spatiale) :**

```c
// âœ… AccÃ¨de aux lignes (Ã©lÃ©ments contigus en mÃ©moire)
void good_access() {
    for (int row = 0; row < N; row++) {
        for (int col = 0; col < N; col++) {
            matrix[row][col] = 0;  // AccÃ¨s sÃ©quentiel !
        }
    }
}
```

**RÃ©sultat Cachegrind :**
```
D1 miss rate: 0.8% âœ…
```

**Gain de performance :** ~30x plus rapide sur les grandes matrices !

### ProblÃ¨me 2 : Structures trop grosses

**Code inefficace :**

```c
typedef struct {
    int id;              // 4 octets
    char padding[60];    // 60 octets (inutilisÃ©s)
    int value;           // 4 octets
} BigStruct;             // Total: 68 octets

BigStruct data[10000];

void process() {
    for (int i = 0; i < 10000; i++) {
        data[i].value += 1;  // Beaucoup de donnÃ©es inutiles dans le cache
    }
}
```

**RÃ©sultat :** Gaspillage de bande passante du cache (pollution).

**Code optimisÃ© (Structure of Arrays) :**

```c
typedef struct {
    int ids[10000];      // DonnÃ©es compactes
    int values[10000];   // DonnÃ©es compactes
} OptimizedData;

OptimizedData data;

void process() {
    for (int i = 0; i < 10000; i++) {
        data.values[i] += 1;  // Cache friendly !
    }
}
```

**RÃ©sultat :** Meilleure utilisation du cache, performance amÃ©liorÃ©e.

### ProblÃ¨me 3 : AccÃ¨s alÃ©atoires Ã  de grandes structures

**Code inefficace :**

```c
#define SIZE 10000000
int huge_array[SIZE];

void random_access() {
    srand(42);
    for (int i = 0; i < 1000000; i++) {
        int index = rand() % SIZE;
        huge_array[index] += 1;  // âŒ AccÃ¨s totalement alÃ©atoire
    }
}
```

**RÃ©sultat Cachegrind :**
```
LL miss rate: 15% âŒ (Ã©norme !)
```

**StratÃ©gie d'amÃ©lioration :**

Si vous ne pouvez pas Ã©viter les accÃ¨s alÃ©atoires :
1. **RÃ©duire la taille des donnÃ©es** (compression, filtrage)
2. **PrÃ©fetching** : Charger les donnÃ©es Ã  l'avance
3. **RÃ©organiser les donnÃ©es** : Index, hash tables
4. **Blocking** : Traiter les donnÃ©es par blocs qui rentrent dans le cache

---

## StratÃ©gies GÃ©nÃ©rales d'Optimisation du Cache

### 1. Principe de LocalitÃ© Spatiale

**DÃ©finition :** AccÃ©der aux donnÃ©es **contigÃ¼es en mÃ©moire**.

```c
// âœ… BON : AccÃ¨s sÃ©quentiel
for (int i = 0; i < size; i++) {
    array[i] = process(array[i]);
}

// âŒ MAUVAIS : AccÃ¨s avec grands sauts
for (int i = 0; i < size; i += 1000) {
    array[i] = process(array[i]);
}
```

### 2. Principe de LocalitÃ© Temporelle

**DÃ©finition :** RÃ©utiliser les donnÃ©es **rÃ©cemment accÃ©dÃ©es**.

```c
// âœ… BON : RÃ©utilisation immÃ©diate
int sum = 0;  
for (int i = 0; i < size; i++) {  
    sum += array[i];  // array[i] rÃ©utilisÃ© tout de suite
}

// âŒ MOINS BON : AccÃ¨s espacÃ© dans le temps
for (int i = 0; i < size; i++) {
    temp[i] = array[i];
}
// ... beaucoup d'autres opÃ©rations ...
for (int i = 0; i < size; i++) {
    result[i] = temp[i];  // temp[i] peut avoir Ã©tÃ© Ã©vincÃ© du cache
}
```

### 3. Blocking / Tiling

Diviser les donnÃ©es en **blocs** qui rentrent dans le cache.

**Exemple : Multiplication de matrices**

```c
// âŒ NaÃ¯f (mauvaises performances cache)
for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
        for (int k = 0; k < N; k++) {
            C[i][j] += A[i][k] * B[k][j];
        }
    }
}

// âœ… Blocked (meilleur cache)
#define BLOCK_SIZE 32
for (int ii = 0; ii < N; ii += BLOCK_SIZE) {
    for (int jj = 0; jj < N; jj += BLOCK_SIZE) {
        for (int kk = 0; kk < N; kk += BLOCK_SIZE) {
            // Traiter un bloc de BLOCK_SIZE x BLOCK_SIZE
            for (int i = ii; i < ii + BLOCK_SIZE && i < N; i++) {
                for (int j = jj; j < jj + BLOCK_SIZE && j < N; j++) {
                    for (int k = kk; k < kk + BLOCK_SIZE && k < N; k++) {
                        C[i][j] += A[i][k] * B[k][j];
                    }
                }
            }
        }
    }
}
```

**Gain :** 2-3x sur les grandes matrices !

### 4. Data Alignment et Padding

Aligner les structures sur les limites de ligne de cache (64 octets).

```c
// Structure alignÃ©e
typedef struct {
    int data[16];  // 64 octets exactement (1 ligne de cache)
} __attribute__((aligned(64))) CacheAlignedStruct;
```

**Avantage :** Ã‰vite le "false sharing" en multithreading.

---

## Limitations de Cachegrind

### 1. Simulation, pas mesure rÃ©elle

Cachegrind **simule** le cache. Il ne mesure pas le vrai comportement sur votre CPU.

**DiffÃ©rences possibles :**
- PrÃ©fetching matÃ©riel non simulÃ©
- Out-of-order execution non pris en compte
- Comportement NUMA (Non-Uniform Memory Access) ignorÃ©

**Solution :** Utiliser `perf` pour des mesures rÃ©elles (voir section 27.3).

### 2. Ralentissement significatif

Cachegrind peut ralentir votre programme de **10x Ã  100x**.

**Conseil :** Profiler sur des jeux de donnÃ©es rÃ©duits ou des tests unitaires.

### 3. Ne profile pas le kernel

Cachegrind ne voit que votre code utilisateur, pas les appels systÃ¨me.

---

## Workflow RecommandÃ©

```
1. Compilation optimisÃ©e : gcc -O2 -g
                          â†“
2. Profiling initial     : valgrind --tool=cachegrind ./prog
                          â†“
3. Identifier hotspots   : cg_annotate cachegrind.out.XXX
                          â†“
4. Visualisation         : kcachegrind cachegrind.out.XXX
                          â†“
5. Optimisation ciblÃ©e   : Modifier les fonctions problÃ©matiques
                          â†“
6. Re-profiling          : Valgrind + cg_annotate
                          â†“
7. Validation            : Comparer avec profil initial
```

---

## Comparaison avec d'autres Outils

| Outil | Type | Overhead | PrÃ©cision | Use case |
|-------|------|----------|-----------|----------|
| **Cachegrind** | Simulation | 10-100x | Bonne | Analyse dÃ©taillÃ©e offline |
| **perf** | Hardware counters | 1-5% | Excellente | Profiling production |
| **gprof** | Instrumentation | 5-20x | Moyenne | Profiling rapide |
| **Intel VTune** | Hardware | 1-10% | Excellente | Intel CPUs, GUI |

**Recommandation :**
1. DÃ©veloppement : **Cachegrind** (dÃ©taillÃ©, pÃ©dagogique)
2. Production : **perf** (lÃ©ger, prÃ©cis)
3. Intel : **VTune** (le plus complet)

---

## Commandes Essentielles - RÃ©sumÃ©

```bash
# Profiling basique
valgrind --tool=cachegrind ./programme

# Annotation dÃ©taillÃ©e
cg_annotate cachegrind.out.XXXXX

# Annotation du code source
cg_annotate --auto=yes cachegrind.out.XXXXX fichier.c

# Visualisation graphique
kcachegrind cachegrind.out.XXXXX

# Simuler un cache spÃ©cifique
valgrind --tool=cachegrind --I1=32768,8,64 --D1=32768,8,64 ./programme

# Avec statistiques de branchement
valgrind --tool=cachegrind --branch-sim=yes ./programme

# Comparer deux profils
cg_diff cachegrind.out.avant cachegrind.out.apres
```

---

## Exemple d'Analyse ComplÃ¨te

### Code initial

```c
// matrix_multiply.c
#include <stdio.h>
#include <stdlib.h>

#define N 500

double A[N][N], B[N][N], C[N][N];

void multiply() {
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            C[i][j] = 0;
            for (int k = 0; k < N; k++) {
                C[i][j] += A[i][k] * B[k][j];  // âŒ B[k][j] = mauvaise localitÃ©
            }
        }
    }
}

int main() {
    // Initialisation
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            A[i][j] = i + j;
            B[i][j] = i - j;
        }
    }

    multiply();

    printf("C[0][0] = %f\n", C[0][0]);
    return 0;
}
```

### Profiling

```bash
$ gcc -O2 -g matrix_multiply.c -o matrix_multiply
$ valgrind --tool=cachegrind ./matrix_multiply
```

**RÃ©sultats :**
```
D1  miss rate: 12.5%  âŒ  
LL  miss rate:  3.2%  âŒ  
```

### Analyse

```bash
$ cg_annotate --auto=yes cachegrind.out.XXXXX matrix_multiply.c
```

**Ligne problÃ©matique :**
```c
C[i][j] += A[i][k] * B[k][j];  // 500,000 cache misses !
```

**Cause :** AccÃ¨s Ã  `B[k][j]` n'est pas sÃ©quentiel (sauts de N Ã©lÃ©ments).

### Optimisation : Transposer B

```c
double B_transposed[N][N];

void multiply_optimized() {
    // Transposer B une fois
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            B_transposed[j][i] = B[i][j];
        }
    }

    // Multiplication avec B transposÃ©e
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            C[i][j] = 0;
            for (int k = 0; k < N; k++) {
                C[i][j] += A[i][k] * B_transposed[j][k];  // âœ… AccÃ¨s sÃ©quentiel !
            }
        }
    }
}
```

### RÃ©sultats aprÃ¨s optimisation

```
D1  miss rate: 1.2%   âœ… (10x mieux !)  
LL  miss rate: 0.4%   âœ…  
Temps d'exÃ©cution: 3x plus rapide  
```

---

## RÃ©sumÃ©

### âœ… Ce que Cachegrind fait bien
- Simulation dÃ©taillÃ©e du comportement du cache
- Annotation ligne par ligne du code source
- Identification des hotspots de cache misses
- Comparaison avant/aprÃ¨s optimisation
- Ã‰ducatif : comprendre comment fonctionne le cache

### âš ï¸ Limites Ã  connaÃ®tre
- Ralentissement trÃ¨s important (10-100x)
- Simulation, pas mesure rÃ©elle
- Ne profile pas le code kernel
- RÃ©sultats peuvent diffÃ©rer du hardware rÃ©el

### ğŸ¯ Quand utiliser Cachegrind ?
- Phase d'optimisation de performances
- Comprendre pourquoi un code est lent
- Apprendre les principes de localitÃ© du cache
- Valider l'impact d'une optimisation
- ComplÃ©ter l'analyse de `perf`

### ğŸ’¡ Conseils pratiques
1. Toujours compiler avec `-O2` ou `-O3`
2. Commencer par identifier les fonctions lentes (cg_annotate)
3. Utiliser KCachegrind pour une vue graphique
4. Optimiser en prioritÃ© les boucles avec beaucoup de misses
5. Valider avec `perf` pour des mesures rÃ©elles

### ğŸ“š Pour aller plus loin
- Documentation officielle : `man cachegrind`
- Guide Valgrind : https://valgrind.org/docs/manual/cg-manual.html
- Section 27.3 : Profiling (perf, gprof)
- Section 27.4 : Cache awareness
- Section 27.6 : Optimisations algorithmiques

---

**ğŸ’¡ Citation :**
> "There are only two hard problems in computer science: cache invalidation, naming things, and off-by-one errors."
> â€” Phil Karlton

**ğŸ“ Le cache est la clÃ© de la performance moderne. Cachegrind vous aide Ã  le maÃ®triser !**

â­ï¸ [Callgrind](/15-debogage-et-qualite/05.3-callgrind.md)
