ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 15.5.3 Callgrind - Profiling et Analyse des Appels de Fonctions

## Introduction

Callgrind est un outil de **profiling** de Valgrind qui enregistre l'historique complet des appels de fonctions dans votre programme. Il vous dit **oÃ¹ votre programme passe son temps**, quelles fonctions sont les plus coÃ»teuses, et comment elles s'appellent entre elles.

### Qu'est-ce que le Profiling ?

Le profiling consiste Ã  **mesurer** les performances d'un programme pour identifier les parties qui consomment le plus de temps CPU. C'est essentiel pour optimiser efficacement votre code.

**L'analogie du budget :**
Imaginez que le temps d'exÃ©cution de votre programme soit un budget de 100â‚¬ :
- La fonction `calculate()` dÃ©pense 60â‚¬ (60% du temps)
- La fonction `display()` dÃ©pense 30â‚¬ (30% du temps)
- La fonction `main()` dÃ©pense 10â‚¬ (10% du temps)

â¡ï¸ Pour accÃ©lÃ©rer votre programme, concentrez-vous sur `calculate()` !

**RÃ¨gle d'or de l'optimisation :**
> "Mesurez avant d'optimiser. L'intuition est souvent trompeuse."

Sans profiling, vous risquez de perdre du temps Ã  optimiser une fonction qui ne reprÃ©sente que 2% du temps total !

---

## Callgrind vs Cachegrind

Bien que Callgrind et Cachegrind soient tous deux des outils Valgrind, ils ont des objectifs diffÃ©rents :

| CaractÃ©ristique | Cachegrind | Callgrind |
|-----------------|------------|-----------|
| **Objectif principal** | Analyser l'utilisation du cache | Profiler les appels de fonctions |
| **Mesure** | Cache hits/misses | CoÃ»t en instructions par fonction |
| **Graphe d'appels** | Non | Oui (qui appelle qui) |
| **Call graph** | Non | Oui |
| **Visualisation** | KCachegrind | KCachegrind (identique) |
| **Overhead** | 10-100x | 10-50x |

**En rÃ©sumÃ© :**
- **Cachegrind** : "Pourquoi mes accÃ¨s mÃ©moire sont lents ?"
- **Callgrind** : "Quelle fonction consomme le plus de temps ?"

**ğŸ’¡ Conseil :** Utilisez Callgrind d'abord pour trouver les fonctions lentes, puis Cachegrind pour comprendre pourquoi elles sont lentes.

---

## Qu'est-ce que Callgrind Mesure ?

### 1. CoÃ»t des Instructions (Ir)

Callgrind compte le nombre d'**instructions CPU** exÃ©cutÃ©es par chaque fonction.

```c
void simple() {
    int x = 5;      // 2-3 instructions
    int y = 10;     // 2-3 instructions
    int z = x + y;  // 3-4 instructions
}
// Total: ~8-10 instructions
```

**Plus une fonction exÃ©cute d'instructions, plus elle est coÃ»teuse.**

### 2. Graphe d'Appels (Call Graph)

Callgrind enregistre **qui appelle qui** et **combien de fois**.

```c
void A() {
    B();    // A appelle B
    C();    // A appelle C
}

void B() {
    D();    // B appelle D
}

void C() {
    D();    // C appelle D aussi
}
```

**Graphe gÃ©nÃ©rÃ© :**
```
main
 â””â”€â”€ A (appelÃ©e 1 fois)
      â”œâ”€â”€ B (appelÃ©e 1 fois)
      â”‚    â””â”€â”€ D (appelÃ©e 1 fois depuis B)
      â””â”€â”€ C (appelÃ©e 1 fois)
           â””â”€â”€ D (appelÃ©e 1 fois depuis C)
```

â¡ï¸ Callgrind peut vous dire que `D()` est appelÃ©e 2 fois au total, et depuis quelles fonctions.

### 3. CoÃ»t Inclusif vs Exclusif

**CoÃ»t exclusif (Self) :**
Le temps passÃ© **dans la fonction elle-mÃªme**, sans les fonctions qu'elle appelle.

**CoÃ»t inclusif (Incl) :**
Le temps passÃ© dans la fonction **plus toutes les fonctions qu'elle appelle**.

**Exemple :**

```c
void process_data() {           // Incl: 100ms, Self: 10ms
    int x = prepare();          // 5ms
    int y = calculate(x);       // 80ms (fonction lente !)
    int z = finalize(y);        // 5ms
}
```

- **CoÃ»t inclusif** de `process_data()` : 100ms (tout)
- **CoÃ»t exclusif** de `process_data()` : 10ms (juste son code, pas les appels)
- **CoÃ»t de** `calculate()` : 80ms

â¡ï¸ **Optimiser** `calculate()` aura beaucoup plus d'impact qu'optimiser `process_data()` !

---

## Installation et Utilisation de Base

### Installation

Callgrind est inclus dans Valgrind :

```bash
# VÃ©rifier l'installation
valgrind --tool=callgrind --version
```

### Compilation

Compilez avec les symboles de dÃ©bogage pour obtenir les noms de fonctions :

```bash
gcc -g mon_programme.c -o mon_programme
```

**Options recommandÃ©es :**
- `-g` : Symboles de dÃ©bogage (essentiel)
- `-O0` ou `-O1` : DÃ©sactiver les optimisations agressives pour un profiling plus prÃ©cis
- Ou `-O2` / `-O3` : Si vous voulez profiler le code optimisÃ© (production)

### ExÃ©cution Basique

```bash
valgrind --tool=callgrind ./mon_programme
```

**Exemple complet :**

```bash
$ valgrind --tool=callgrind ./test_prof
==34567== Callgrind, a call-graph generating cache profiler
==34567== Copyright (C) 2002-2017, and GNU GPL'd, by Josef Weidendorfer et al.
==34567== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==34567== Command: ./test_prof
==34567==
==34567== For interactive control, run 'callgrind_control -h'.
Programme terminÃ©
==34567==
==34567== Events    : Ir
==34567== Collected : 2567890
==34567==
==34567== I   refs:      2,567,890
```

Callgrind gÃ©nÃ¨re un fichier `callgrind.out.<pid>` :

```bash
$ ls callgrind.out.*
callgrind.out.34567
```

---

## Analyser les RÃ©sultats avec callgrind_annotate

### Vue d'Ensemble

Pour voir un rÃ©sumÃ© textuel des rÃ©sultats :

```bash
callgrind_annotate callgrind.out.34567
```

**Exemple de sortie :**

```
--------------------------------------------------------------------------------
Profile data file 'callgrind.out.34567' (creator: callgrind-3.15.0)
--------------------------------------------------------------------------------
I1 cache: 32768 B, 64 B, 8-way associative
D1 cache: 32768 B, 64 B, 8-way associative
LL cache: 8388608 B, 64 B, 16-way associative
Timerange: Basic block 0 - 125678
Trigger: Program termination
Profiled target:  ./test_prof (PID 34567, part 1)
--------------------------------------------------------------------------------

        Ir  file:function
--------------------------------------------------------------------------------
 2,567,890  PROGRAM TOTALS

--------------------------------------------------------------------------------
        Ir  file:function
--------------------------------------------------------------------------------
 1,500,000  test_prof.c:calculate_heavy  (60%)
   500,000  test_prof.c:process_array    (20%)
   300,000  test_prof.c:main             (12%)
   200,000  /lib/x86_64-linux-gnu/libc-2.31.so:__printf
    50,000  test_prof.c:helper           (2%)
    17,890  ???:0x00000000               (reste)
```

### InterprÃ©tation

**Colonnes importantes :**
- **Ir** : Nombre d'instructions exÃ©cutÃ©es (Instructions Read)
- **file:function** : Nom de la fonction et fichier source
- **Pourcentage** : Part du temps total

**Dans cet exemple :**
- `calculate_heavy()` consomme **60% du temps** â¡ï¸ Cible prioritaire d'optimisation !
- `process_array()` : 20%
- `main()` : 12%
- Le reste est nÃ©gligeable

**RÃ¨gle des 80/20 (Principe de Pareto) :**
Souvent, 80% du temps est passÃ© dans 20% du code. Concentrez-vous sur ces 20% !

### Annotation du Code Source

Pour voir le coÃ»t **ligne par ligne** :

```bash
callgrind_annotate --auto=yes callgrind.out.34567 test_prof.c
```

**Exemple de sortie :**

```c
-- line 45 ----------------------------------------
        Ir
         .  void calculate_heavy(int n) {
   100,000      int sum = 0;
 1,400,000      for (int i = 0; i < n; i++) {
         .          sum += i * i;  // â† Ligne la plus coÃ»teuse !
         .      }
         .      return sum;
         .  }
```

â¡ï¸ La boucle `for` consomme **1,4 million d'instructions** sur 1,5M total !

---

## Visualisation Graphique avec KCachegrind

### Lancement

```bash
kcachegrind callgrind.out.34567
```

### Interface de KCachegrind

KCachegrind offre une **interface graphique puissante** avec plusieurs vues :

#### 1. **Vue Liste des Fonctions (Flat Profile)**

Affiche toutes les fonctions triÃ©es par coÃ»t dÃ©croissant :

```
Function              Incl.    Self    Called
calculate_heavy       60.0%    58.0%   1x
process_array         20.0%    15.0%   10x
main                  100.0%   12.0%   1x
helper                 2.0%     2.0%   100x
```

**Colonnes :**
- **Incl.** : CoÃ»t inclusif (fonction + sous-fonctions)
- **Self** : CoÃ»t exclusif (fonction seule)
- **Called** : Nombre d'appels

**ğŸ’¡ Astuce :** Triez par "Self" pour trouver les fonctions qui font rÃ©ellement le travail.

#### 2. **Graphe d'Appels (Call Graph)**

Visualisation des relations entre fonctions avec des flÃ¨ches :

```
         main (100%)
           â”‚
           â”œâ”€â”€> calculate_heavy (60%)
           â”‚
           â””â”€â”€> process_array (20%)
                   â”‚
                   â””â”€â”€> helper (2%) Ã—100 calls
```

**ReprÃ©sentation visuelle :**
- Taille des boÃ®tes âˆ coÃ»t de la fonction
- Ã‰paisseur des flÃ¨ches âˆ nombre d'appels
- Code couleur : rouge = coÃ»teux, vert = rapide

#### 3. **Callers / Callees**

**Callers** : Qui appelle cette fonction ?
**Callees** : Quelles fonctions cette fonction appelle-t-elle ?

**Exemple pour `process_array()` :**
```
Callers:
  main â†’ process_array (10 calls, 20% du temps)

Callees:
  process_array â†’ helper (100 calls, 2% du temps)
  process_array â†’ calculate_heavy (1 call, 60% du temps)
```

â¡ï¸ Vous voyez immÃ©diatement que `calculate_heavy()` est le goulot d'Ã©tranglement !

#### 4. **Code Source AnnotÃ©**

KCachegrind affiche votre code source avec une **coloration** indiquant les lignes coÃ»teuses :

- ğŸŸ¢ **Vert** : Peu coÃ»teux
- ğŸŸ¡ **Jaune** : CoÃ»t moyen
- ğŸ”´ **Rouge** : TrÃ¨s coÃ»teux (OPTIMISER ICI !)

#### 5. **Flamegraph**

ReprÃ©sentation graphique en "flammes" montrant la pile d'appels :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              main (100%)                   â”‚  â† Base
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  calculate_heavy     â”‚   process_array     â”‚  â† Niveau 1
â”‚      (60%)           â”‚      (20%)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ helper (2%)    â† Niveau 2
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Lecture :** Plus une barre est large, plus elle est coÃ»teuse.

---

## Options AvancÃ©es de Callgrind

### 1. ContrÃ´le de l'Instrumentation

Par dÃ©faut, Callgrind profile **tout** le programme. Pour ne profiler que certaines parties :

**DÃ©sactiver le profiling au dÃ©marrage :**

```bash
valgrind --tool=callgrind --instr-atstart=no ./programme
```

**ContrÃ´ler depuis le code source :**

```c
#include <valgrind/callgrind.h>

void fonction_a_profiler() {
    CALLGRIND_START_INSTRUMENTATION;
    // Code Ã  analyser
    for (int i = 0; i < 1000000; i++) {
        // ... calculs ...
    }
    CALLGRIND_STOP_INSTRUMENTATION;
}
```

**Compiler avec :**
```bash
gcc -g mon_programme.c -o mon_programme
# Les macros sont des no-op si Valgrind n'est pas utilisÃ©
```

### 2. ContrÃ´le Externe avec callgrind_control

Pendant l'exÃ©cution, vous pouvez contrÃ´ler Callgrind depuis un autre terminal :

```bash
# Lister les processus Callgrind en cours
callgrind_control --status

# Activer/dÃ©sactiver l'instrumentation
callgrind_control -i on   # Activer
callgrind_control -i off  # DÃ©sactiver

# Forcer un dump (snapshot)
callgrind_control -d
```

**Use case :** Profiler uniquement une partie spÃ©cifique d'un long processus.

### 3. Simulation du Cache

Callgrind peut aussi simuler le cache (comme Cachegrind) :

```bash
valgrind --tool=callgrind --cache-sim=yes ./programme
```

**Avantage :** Combine le profiling de fonctions ET l'analyse du cache dans un seul run.

### 4. DiffÃ©rence entre Deux Profils

Pour comparer deux versions de votre code :

```bash
# Version 1
valgrind --tool=callgrind --callgrind-out-file=avant.out ./prog_v1

# Version 2
valgrind --tool=callgrind --callgrind-out-file=apres.out ./prog_v2

# Comparaison
callgrind_annotate --diff=avant.out apres.out
```

**RÃ©sultat :**
```
Function         v1        v2      Diff     %
calculate_heavy  1,500,000 500,000 -1,000,000 -66%  âœ… Excellent !
helper           50,000    55,000  +5,000     +10%  âš ï¸ LÃ©gÃ¨re rÃ©gression
```

---

## Exemples Pratiques d'Optimisation

### ProblÃ¨me 1 : Fonction AppelÃ©e Trop Souvent

**Code initial :**

```c
int is_prime(int n) {
    if (n < 2) return 0;
    for (int i = 2; i < n; i++) {
        if (n % i == 0) return 0;
    }
    return 1;
}

void process() {
    int count = 0;
    for (int i = 0; i < 100000; i++) {
        if (is_prime(i)) {  // âŒ AppelÃ©e 100,000 fois !
            count++;
        }
    }
    printf("Primes: %d\n", count);
}
```

**Profiling Callgrind :**
```
Function     Incl.    Self    Called
is_prime     95%      95%     100,000x  âŒ Ã‰norme coÃ»t !
process      100%     5%      1x
```

**ProblÃ¨me :** `is_prime()` est trÃ¨s coÃ»teuse et appelÃ©e 100,000 fois.

**Solution 1 : Optimiser is_prime (âˆšn au lieu de n)**

```c
int is_prime(int n) {
    if (n < 2) return 0;
    if (n == 2) return 1;
    if (n % 2 == 0) return 0;

    // Tester jusqu'Ã  âˆšn seulement
    int sqrt_n = (int)sqrt(n);
    for (int i = 3; i <= sqrt_n; i += 2) {
        if (n % i == 0) return 0;
    }
    return 1;
}
```

**RÃ©sultat :** **10-100x plus rapide** selon la taille de `n`.

**Solution 2 : MÃ©moÃ¯sation (Cache des rÃ©sultats)**

```c
int prime_cache[100000] = {0};

int is_prime_cached(int n) {
    if (n >= 100000) return is_prime(n);

    // DÃ©jÃ  calculÃ© ?
    if (prime_cache[n] != 0) {
        return prime_cache[n];
    }

    // Calculer et mettre en cache
    prime_cache[n] = is_prime(n);
    return prime_cache[n];
}
```

**RÃ©sultat :** Chaque nombre n'est testÃ© qu'**une seule fois**.

### ProblÃ¨me 2 : Fonction RÃ©cursive Inefficace

**Code initial (Fibonacci naÃ¯f) :**

```c
int fibonacci(int n) {
    if (n <= 1) return n;
    return fibonacci(n - 1) + fibonacci(n - 2);  // âŒ Exponentiel !
}

int main() {
    printf("Fib(40) = %d\n", fibonacci(40));
}
```

**Profiling Callgrind :**
```
Function    Called
fibonacci   331,160,281 fois !  âŒ Explosion d'appels !
```

**Graphe d'appels :**
```
fibonacci(40)
â”œâ”€â”€ fibonacci(39)
â”‚   â”œâ”€â”€ fibonacci(38)
â”‚   â”‚   â”œâ”€â”€ fibonacci(37)
â”‚   â”‚   â”‚   â””â”€â”€ ... (rÃ©cursion profonde)
â”‚   â”‚   â””â”€â”€ fibonacci(36)
â”‚   â””â”€â”€ fibonacci(37)  â† RecalculÃ© inutilement !
â””â”€â”€ fibonacci(38)      â† RecalculÃ© aussi !
```

â¡ï¸ Beaucoup de **calculs redondants** !

**Solution : Programmation Dynamique**

```c
int fibonacci_dp(int n) {
    if (n <= 1) return n;

    int fib[n + 1];
    fib[0] = 0;
    fib[1] = 1;

    for (int i = 2; i <= n; i++) {
        fib[i] = fib[i - 1] + fib[i - 2];
    }

    return fib[n];
}
```

**RÃ©sultat :**
```
Function      Called
fibonacci_dp  1 fois
```

**Gain de performance : De plusieurs secondes Ã  quelques microsecondes !**

### ProblÃ¨me 3 : Appels de Fonctions Inutiles dans une Boucle

**Code initial :**

```c
void process_data(int *data, int size) {
    for (int i = 0; i < size; i++) {
        int factor = get_scaling_factor();  // âŒ AppelÃ©e Ã  chaque itÃ©ration
        data[i] = data[i] * factor;
    }
}

int get_scaling_factor() {
    // Calcul complexe qui retourne toujours la mÃªme valeur
    return 42;
}
```

**Profiling Callgrind :**
```
Function            Called
get_scaling_factor  1,000,000x  âŒ Inutile !
process_data        1x
```

**Solution : Sortir l'appel de la boucle**

```c
void process_data(int *data, int size) {
    int factor = get_scaling_factor();  // âœ… Une seule fois
    for (int i = 0; i < size; i++) {
        data[i] = data[i] * factor;
    }
}
```

**RÃ©sultat :** `get_scaling_factor()` appelÃ©e **1 seule fois** au lieu de 1 million !

---

## Patterns d'Optimisation Courants

### 1. Loop Hoisting (Invariant Code Motion)

**Principe :** Sortir de la boucle tout ce qui ne change pas Ã  chaque itÃ©ration.

```c
// âŒ AVANT
for (int i = 0; i < n; i++) {
    int limit = compute_limit();  // Ne change jamais
    process(data[i], limit);
}

// âœ… APRÃˆS
int limit = compute_limit();  // Une seule fois
for (int i = 0; i < n; i++) {
    process(data[i], limit);
}
```

### 2. Function Inlining

**Principe :** Ã‰liminer l'overhead d'appel de fonction pour les petites fonctions.

```c
// âŒ AVANT : Fonction appelÃ©e des millions de fois
int square(int x) {
    return x * x;
}

for (int i = 0; i < 1000000; i++) {
    result[i] = square(i);
}

// âœ… APRÃˆS : Inline manuel ou avec __attribute__((always_inline))
inline int square(int x) {
    return x * x;
}

// Ou directement :
for (int i = 0; i < 1000000; i++) {
    result[i] = i * i;  // Pas d'appel de fonction
}
```

**Note :** Avec `-O2` ou `-O3`, GCC inline automatiquement les petites fonctions.

### 3. Lazy Evaluation

**Principe :** Ne calculer que ce qui est nÃ©cessaire.

```c
// âŒ AVANT : Calcul inutile si condition fausse
int expensive_check() {
    // Calcul trÃ¨s coÃ»teux
    return /* rÃ©sultat */;
}

if (quick_check() && expensive_check()) {
    // ...
}

// âœ… APRÃˆS : Court-circuit
// Si quick_check() est faux, expensive_check() n'est PAS appelÃ©
```

### 4. Batch Processing

**Principe :** Traiter les donnÃ©es par blocs pour rÃ©duire les appels.

```c
// âŒ AVANT : Appel pour chaque Ã©lÃ©ment
for (int i = 0; i < n; i++) {
    send_to_server(data[i]);  // n appels rÃ©seau !
}

// âœ… APRÃˆS : Batch de 100 Ã©lÃ©ments
for (int i = 0; i < n; i += 100) {
    int batch_size = (i + 100 < n) ? 100 : (n - i);
    send_batch_to_server(&data[i], batch_size);  // n/100 appels
}
```

---

## Workflow d'Optimisation RecommandÃ©

```
1. Identifier le problÃ¨me
   "Mon programme est lent !" â† SymptÃ´me
                â†“
2. Profiler avec Callgrind
   valgrind --tool=callgrind ./programme
                â†“
3. Analyser avec KCachegrind
   Identifier les fonctions "Self" Ã©levÃ©
                â†“
4. Comprendre POURQUOI c'est lent
   - Trop d'appels ?
   - Algorithme inefficace ?
   - Redondance ?
                â†“
5. Optimiser de maniÃ¨re ciblÃ©e
   Modifier SEULEMENT les hotspots
                â†“
6. Re-profiler
   Comparer avant/aprÃ¨s
                â†“
7. Valider
   - Performance âœ…
   - Correction âœ… (tests unitaires)
   - LisibilitÃ© âœ… (pas de code obscur)
```

**âš ï¸ RÃ¨gle importante :** Ne jamais sacrifier la **lisibilitÃ©** ou la **maintenabilitÃ©** pour un gain de 5% !

---

## Limitations de Callgrind

### 1. Ralentissement Important

Callgrind ralentit votre programme de **10x Ã  50x**.

**Solutions :**
- Profiler sur des jeux de donnÃ©es rÃ©duits
- Utiliser `--instr-atstart=no` et profiler uniquement les parties critiques
- Pour la production, utiliser `perf` (overhead < 5%)

### 2. Ne Mesure Pas le Temps RÃ©el

Callgrind compte les **instructions**, pas le **temps rÃ©el** (wall-clock time).

**ConsÃ©quence :** Ne dÃ©tecte pas :
- Les attentes I/O (lecture fichier, rÃ©seau)
- Les sleep/wait
- La contention de locks en multithreading

**Solution :** Utiliser `perf record` pour le temps rÃ©el.

### 3. Impact de l'Optimisation Compilateur

Avec `-O3`, le compilateur peut inline, unroll, ou rÃ©organiser le code.

**ConsÃ©quence :** Le profil peut Ãªtre diffÃ©rent de ce Ã  quoi vous vous attendez.

**Conseil :** Profiler le code tel qu'il sera dÃ©ployÃ© (mÃªme niveau d'optimisation).

---

## Comparaison avec Autres Outils de Profiling

| Outil | Type | Overhead | PrÃ©cision | Call Graph | Use Case |
|-------|------|----------|-----------|------------|----------|
| **Callgrind** | Instrumentation | 10-50x | Excellente | Oui | DÃ©veloppement, analyse dÃ©taillÃ©e |
| **gprof** | Instrumentation | 5-15x | Bonne | Oui | Profiling rapide |
| **perf** | Sampling | 1-5% | TrÃ¨s bonne | Oui | Production, benchmarking |
| **Valgrind/Memcheck** | Instrumentation | 10-50x | - | Non | DÃ©tection de bugs mÃ©moire |
| **VTune** | Hardware counters | 1-10% | Excellente | Oui | Intel CPUs, GUI avancÃ© |

**Recommandations :**
1. **DÃ©veloppement** : Callgrind (dÃ©taillÃ©)
2. **CI/CD** : perf (lÃ©ger)
3. **Production** : perf (minimal overhead)
4. **Intel CPUs** : VTune (le plus complet)

---

## IntÃ©gration dans le Workflow de DÃ©veloppement

### 1. Profiling RÃ©gulier

Ajoutez un profiling dans vos tests de performance :

```bash
#!/bin/bash
# scripts/profile.sh

echo "Profiling de test_performance..."
valgrind --tool=callgrind \
    --callgrind-out-file=callgrind.out.latest \
    ./test_performance

echo "GÃ©nÃ©rer le rapport..."
callgrind_annotate callgrind.out.latest > profile_report.txt

echo "Rapport disponible dans profile_report.txt"
```

### 2. Benchmarking Avant/AprÃ¨s

Comparer les performances entre commits :

```bash
# Profiler la version actuelle
git checkout main
make clean && make
valgrind --tool=callgrind --callgrind-out-file=main.out ./programme

# Profiler la nouvelle version
git checkout feature-optimization
make clean && make
valgrind --tool=callgrind --callgrind-out-file=feature.out ./programme

# Comparer
callgrind_annotate --diff=main.out feature.out
```

### 3. CI/CD : DÃ©tection de RÃ©gressions

Ajouter une Ã©tape de profiling dans votre pipeline :

```yaml
# .github/workflows/profile.yml
name: Performance Profile

on: [pull_request]

jobs:
  profile:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Install Valgrind
        run: sudo apt-get install -y valgrind

      - name: Build
        run: make

      - name: Profile
        run: |
          valgrind --tool=callgrind \
            --callgrind-out-file=profile.out \
            ./test_benchmark

          callgrind_annotate profile.out > profile_report.txt

      - name: Upload Report
        uses: actions/upload-artifact@v2
        with:
          name: profile-report
          path: profile_report.txt
```

---

## Conseils et Bonnes Pratiques

### âœ… Ã€ Faire

1. **Profiler avant d'optimiser** : Mesurez, ne devinez pas
2. **Se concentrer sur les hotspots** : 20% du code = 80% du temps
3. **Valider avec des tests** : L'optimisation ne doit pas casser le code
4. **Comparer avant/aprÃ¨s** : Quantifiez vos amÃ©liorations
5. **Profiler le code optimisÃ©** : Avec `-O2` si c'est ce qui sera dÃ©ployÃ©

### âŒ Ã€ Ã‰viter

1. **Optimiser prÃ©maturÃ©ment** : N'optimisez que ce qui est prouvÃ© lent
2. **Ignorer la complexitÃ© algorithmique** : O(nÂ²) â†’ O(n log n) > micro-optimisations
3. **Sacrifier la lisibilitÃ©** : Code obscur = dette technique
4. **Optimiser sans mesurer** : Vous pourriez ralentir le code !
5. **Profiler en debug** : Les rÃ©sultats ne seront pas reprÃ©sentatifs

---

## Exemple Complet : De l'Analyse Ã  l'Optimisation

### Code Initial

```c
// sort_benchmark.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

void bubble_sort(int *arr, int n) {
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                int temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
            }
        }
    }
}

int main() {
    int n = 10000;
    int *arr = malloc(n * sizeof(int));

    // Initialisation alÃ©atoire
    srand(42);
    for (int i = 0; i < n; i++) {
        arr[i] = rand() % 10000;
    }

    bubble_sort(arr, n);

    printf("Premier Ã©lÃ©ment triÃ©: %d\n", arr[0]);
    free(arr);
    return 0;
}
```

### Ã‰tape 1 : Profiling

```bash
$ gcc -g -O0 sort_benchmark.c -o sort_benchmark
$ valgrind --tool=callgrind ./sort_benchmark
$ kcachegrind callgrind.out.XXXXX
```

### Ã‰tape 2 : Analyse

**RÃ©sultat KCachegrind :**
```
Function      Incl.    Self    Called
bubble_sort   99.8%    99.8%   1x       âŒ Goulot d'Ã©tranglement !
main          100%     0.2%    1x
```

â¡ï¸ `bubble_sort()` consomme **99.8% du temps** !

**Code annotÃ© :**
```c
        Ir
         .  void bubble_sort(int *arr, int n) {
 50,000,000      for (int i = 0; i < n - 1; i++) {           // Boucle externe
499,950,000          for (int j = 0; j < n - i - 1; j++) {   // Boucle interne âŒ
 99,900,000              if (arr[j] > arr[j + 1]) {
 49,950,000                  // swap
         .              }
         .          }
         .      }
         .  }
```

â¡ï¸ La boucle interne est **extrÃªmement coÃ»teuse** (complexitÃ© O(nÂ²)).

### Ã‰tape 3 : Optimisation

**Solution : Utiliser quicksort (O(n log n))**

```c
// Utiliser qsort de la libc
#include <stdlib.h>

int compare(const void *a, const void *b) {
    return (*(int*)a - *(int*)b);
}

int main() {
    // ... initialisation ...

    qsort(arr, n, sizeof(int), compare);  // âœ… O(n log n)

    // ... suite ...
}
```

### Ã‰tape 4 : Validation

```bash
$ gcc -g -O2 sort_benchmark_optimized.c -o sort_benchmark_optimized
$ valgrind --tool=callgrind ./sort_benchmark_optimized
```

**RÃ©sultat :**
```
AVANT :   650,000,000 instructions (bubble_sort)
APRÃˆS :     1,500,000 instructions (qsort)
Gain  :     ~430x plus rapide !  ğŸ‰
```

---

## RÃ©sumÃ©

### âœ… Ce que Callgrind fait bien
- Identification prÃ©cise des fonctions coÃ»teuses
- Graphe d'appels complet (qui appelle qui)
- Annotation ligne par ligne du code source
- Visualisation graphique avec KCachegrind
- Comparaison avant/aprÃ¨s optimisation
- Ã‰ducatif pour comprendre le comportement du programme

### âš ï¸ Limites Ã  connaÃ®tre
- Ralentissement important (10-50x)
- Compte les instructions, pas le temps rÃ©el
- Ne dÃ©tecte pas les attentes I/O ou locks
- NÃ©cessite une compilation avec symboles de dÃ©bogage

### ğŸ¯ Quand utiliser Callgrind ?
- **Toujours** avant d'optimiser : "Mesure, ne devine pas"
- Quand un programme est anormalement lent
- Pour valider l'impact d'une optimisation
- Pour comprendre les appels entre fonctions
- En dÃ©veloppement (pas en production)

### ğŸ’¡ Conseils finaux
1. **Profiler rÃ©guliÃ¨rement** pendant le dÃ©veloppement
2. **Se concentrer sur les 20%** de code qui consomment 80% du temps
3. **Optimiser l'algorithme d'abord**, les dÃ©tails ensuite
4. **Toujours valider** avec des tests aprÃ¨s optimisation
5. **Utiliser KCachegrind** pour une exploration visuelle

### ğŸ“š Pour aller plus loin
- Documentation officielle : `man callgrind`
- Guide Valgrind : https://valgrind.org/docs/manual/cl-manual.html
- Section 27.3 : Profiling avec perf et gprof
- Section 27.6 : Optimisations algorithmiques
- Section 27.10 : Benchmarking rigoureux

---

**ğŸ¯ Citation :**
> "Premature optimization is the root of all evil." â€” Donald Knuth

**Mais :**
> "Profiling is the root of all optimization." â€” Anonyme

**ğŸ’¡ Callgrind vous aide Ã  optimiser intelligemment, lÃ  oÃ¹ Ã§a compte vraiment !**

â­ï¸ [Massif](/15-debogage-et-qualite/05.4-massif.md)
