üîù Retour au [Sommaire](/SOMMAIRE.md)

# 21.6.2 Pixie

## Introduction

**Pixie** est une plateforme d'observabilit√© r√©volutionnaire pour Kubernetes qui utilise eBPF pour capturer automatiquement des donn√©es de t√©l√©m√©trie de vos applications **sans aucune modification de code** et **sans instrumentation manuelle**.

Si Cilium (section 21.6.1) r√©volutionne le networking avec eBPF, Pixie r√©volutionne l'**observabilit√©** : imaginez pouvoir voir en temps r√©el toutes les requ√™tes HTTP, SQL, Redis, gRPC de votre cluster Kubernetes sans avoir touch√© une seule ligne de code de vos applications !

Dans cette section, nous allons d√©couvrir :
- Ce qu'est Pixie et le probl√®me qu'il r√©sout
- Comment il utilise eBPF pour l'auto-instrumentation
- Ses fonctionnalit√©s uniques (live debugging, query language)
- Pourquoi c'est un outil essentiel pour les DevOps/SRE modernes

**Note importante** : Pixie a √©t√© d√©velopp√© par une startup du m√™me nom, puis acquis par **New Relic** en 2020. Le projet reste open-source et fait partie de la CNCF.

## Qu'est-ce que Pixie ?

### D√©finition simple

**Pixie** est une plateforme qui vous donne une **visibilit√© instantan√©e** sur votre cluster Kubernetes en capturant automatiquement :

- üìä **M√©triques** : CPU, m√©moire, latence, throughput
- üîç **Traces** : Requ√™tes HTTP/gRPC compl√®tes avec headers et body
- üìù **Logs** : Logs applicatifs structur√©s
- üåê **Network flows** : Topologie r√©seau et d√©pendances entre services
- üîê **Donn√©es de s√©curit√©** : Connexions suspectes, acc√®s non autoris√©s

Le tout **sans modifier vos applications** et **sans sidecars** !

### La promesse de Pixie

```
‚ùå Avant Pixie :
- Ajouter des biblioth√®ques d'instrumentation dans chaque service
- Configurer des exporters (Prometheus, Jaeger, etc.)
- G√©rer des agents de collecte
- Modifier le code pour chaque nouveau metric
- Red√©ployer les applications

‚úÖ Avec Pixie :
- kubectl apply -f pixie.yaml
- Attendre 2 minutes
- Vous avez TOUTE l'observabilit√©, automatiquement !
```

### Origine et histoire

- **2018** : Cr√©ation de Pixie Labs (startup)
- **2019** : Premi√®re version utilisant eBPF
- **2020** : Acquisition par New Relic pour 30+ millions $
- **2021** : Open-source complet et donation √† la CNCF
- **2023** : Projet CNCF Sandbox (en croissance rapide)
- **2024-2025** : Adoption croissante, int√©gration dans de nombreux outils

## Le probl√®me : L'observabilit√© traditionnelle est complexe

### L'approche classique (et douloureuse)

Pour avoir de l'observabilit√© dans un cluster Kubernetes traditionnel, vous devez :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Votre Application                ‚îÇ
‚îÇ                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Code applicatif                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  import prometheus_client  ‚Üê Instrumentation‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  import opentelemetry      ‚Üê Tracing        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  import logging           ‚Üê Logs            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  // Ajouter des m√©triques custom            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  counter.inc()                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  histogram.observe(latency)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  tracer.start_span("db_query")              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Sidecar/Agent                        ‚îÇ
‚îÇ  ‚Ä¢ Prometheus exporter                            ‚îÇ
‚îÇ  ‚Ä¢ OpenTelemetry collector                        ‚îÇ
‚îÇ  ‚Ä¢ Log forwarder (Fluentd)                        ‚îÇ
‚îÇ  ‚ö†Ô∏è  Overhead m√©moire : 50-100 MB/pod             ‚îÇ
‚îÇ  ‚ö†Ô∏è  Overhead CPU : 100-200 millicores/pod        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Stack d'observabilit√©                   ‚îÇ
‚îÇ  ‚Ä¢ Prometheus (m√©triques)                         ‚îÇ
‚îÇ  ‚Ä¢ Jaeger (traces)                                ‚îÇ
‚îÇ  ‚Ä¢ Elasticsearch (logs)                           ‚îÇ
‚îÇ  ‚Ä¢ Grafana (visualisation)                        ‚îÇ
‚îÇ  ‚ö†Ô∏è  Complexit√© : 4+ composants √† g√©rer           ‚îÇ
‚îÇ  ‚ö†Ô∏è  Co√ªt : Storage + compute √©lev√©               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Probl√®mes de cette approche :**

- ‚ùå **Modification du code** : Chaque service doit √™tre instrument√©
- ‚ùå **Polyglotte difficile** : Diff√©rentes biblioth√®ques pour Python, Go, Java, etc.
- ‚ùå **Overhead** : Sidecars consomment des ressources
- ‚ùå **D√©lai** : Des semaines/mois pour instrumenter une application
- ‚ùå **Co√ªt** : Infrastructure d'observabilit√© co√ªteuse
- ‚ùå **Blind spots** : Services legacy non instrument√©s = invisibles
- ‚ùå **Lag** : Attendre le prochain d√©ploiement pour ajouter une m√©trique

### Exemple concret du cauchemar

Imaginez ce sc√©nario :

```
üî• Incident en production : Latence √©lev√©e !

DevOps : "Quelle est la latence du service Backend ?"
Dev : "Euh... on n'a pas instrument√© cette m√©trique encore"

DevOps : "Quelles sont les requ√™tes SQL lentes ?"
Dev : "Il faudrait ajouter du tracing, red√©ployer, attendre..."

DevOps : "Quels services appellent Backend ?"
Dev : "On n'a pas de service mesh, donc... aucune id√©e"

‚è∞ 2 heures plus tard : Toujours en train de d√©boguer
```

## La solution Pixie : Auto-telemetry avec eBPF

Pixie r√©sout tous ces probl√®mes avec une approche r√©volutionnaire : **l'auto-instrumentation via eBPF**.

### Architecture Pixie

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Votre Application (NON MODIFI√âE)         ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  Code applicatif                         ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ                                          ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  // Aucune instrumentation !             ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  // Code normal, rien de sp√©cial         ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ                                          ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  def handle_request():                   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ      response = db.query(...)            ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ      return response                     ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚îÇ (Pixie observe TOUT automatiquement)
                     ‚îÇ
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              KERNEL LINUX                             ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  Programmes eBPF Pixie                   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ                                          ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Kprobes : Appels syst√®me              ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Uprobes : Fonctions SSL (OpenSSL)     ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Tracepoints : Network, scheduler      ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Socket filters : Paquets r√©seau       ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ                                          ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚úì Capture HTTP, SQL, Redis, gRPC        ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚úì Parse les protocols en temps r√©el     ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚úì Reconstruit les requ√™tes compl√®tes    ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  BPF Maps (donn√©es collect√©es)           ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ HTTP requests/responses               ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ SQL queries                           ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Network connections                   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Process metrics                       ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Pixie Vizier (Agent)                      ‚îÇ
‚îÇ  ‚Ä¢ Collecte les donn√©es des BPF maps                   ‚îÇ
‚îÇ  ‚Ä¢ Agr√®ge et enrichit                                  ‚îÇ
‚îÇ  ‚Ä¢ Execute les queries PxL                             ‚îÇ
‚îÇ  ‚Ä¢ Expose l'API                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Pixie UI / CLI / API                      ‚îÇ
‚îÇ  ‚Ä¢ Visualisation en temps r√©el                         ‚îÇ
‚îÇ  ‚Ä¢ Requ√™tes avec PxL (Pixie Language)                  ‚îÇ
‚îÇ  ‚Ä¢ Dashboards interactifs                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Comment Pixie utilise eBPF

Pixie d√©ploie de **nombreux programmes eBPF** qui capturent diff√©rents aspects du syst√®me :

#### 1. Capture du trafic r√©seau (Socket filters)

```c
// Programme eBPF conceptuel de Pixie pour HTTP
SEC("socket")
int pixie_http_capture(struct __sk_buff *skb)
{
    // Parser les en-t√™tes Ethernet, IP, TCP
    parse_network_headers(skb);

    // Extraire le payload HTTP
    char http_data[4096];
    bpf_skb_load_bytes(skb, offset, http_data, sizeof(http_data));

    // Parser HTTP : "GET /api/users HTTP/1.1"
    struct http_request req = {};
    if (parse_http_request(http_data, &req)) {
        // Stocker dans une BPF map
        __u64 conn_id = get_connection_id(skb);
        bpf_map_update_elem(&http_requests, &conn_id, &req, BPF_ANY);
    }

    return 0;
}
```

**R√©sultat** : Pixie voit **toutes** les requ√™tes HTTP, avec m√©thode, path, headers, body !

#### 2. D√©cryptage SSL/TLS (Uprobes sur OpenSSL)

Les communications HTTPS sont chiffr√©es, mais Pixie a un trick g√©nial :

```c
// Uprobe sur la fonction SSL_write d'OpenSSL
SEC("uprobe/SSL_write")
int pixie_ssl_write(struct pt_regs *ctx)
{
    // SSL_write(ssl, buf, len) est appel√© AVANT chiffrement
    // On peut lire 'buf' qui contient les donn√©es en clair !

    void *ssl = (void *)PT_REGS_PARM1(ctx);
    char *buf = (char *)PT_REGS_PARM2(ctx);
    size_t len = PT_REGS_PARM3(ctx);

    // Copier les donn√©es d√©chiffr√©es
    char plaintext[4096];
    bpf_probe_read_user(plaintext, sizeof(plaintext), buf);

    // Parser HTTP depuis les donn√©es en clair
    parse_http_and_store(plaintext, len);

    return 0;
}
```

**Magie !** Pixie peut voir le contenu des requ√™tes HTTPS **sans avoir les certificats SSL** et **sans modifier les applications**.

**Comment c'est possible ?** Parce que l'application appelle `SSL_write()` avec les donn√©es en clair, et OpenSSL les chiffre ensuite. Pixie intercepte l'appel juste avant le chiffrement !

#### 3. Capture SQL, Redis, etc.

Pixie reconnait automatiquement de nombreux protocoles :

```c
// D√©tection automatique de protocole
if (starts_with(data, "SELECT") || starts_with(data, "INSERT")) {
    parse_sql_query(data);
} else if (starts_with(data, "GET") || starts_with(data, "SET")) {
    parse_redis_command(data);
} else if (is_http(data)) {
    parse_http(data);
} else if (is_grpc(data)) {
    parse_grpc(data);
}
```

**Protocoles support√©s** :
- ‚úÖ HTTP/1.x, HTTP/2
- ‚úÖ HTTPS (via uprobe OpenSSL/BoringSSL)
- ‚úÖ gRPC
- ‚úÖ MySQL
- ‚úÖ PostgreSQL
- ‚úÖ Redis
- ‚úÖ Kafka
- ‚úÖ DNS
- ‚úÖ Cassandra
- ‚úÖ NATS
- ‚úÖ RabbitMQ/AMQP
- ‚úÖ Et bien d'autres...

#### 4. M√©triques syst√®me

Pixie collecte aussi des m√©triques syst√®me via tracepoints et kprobes :

- **CPU** : Temps CPU par processus/pod
- **M√©moire** : RSS, virtual memory, page faults
- **I/O** : Reads/writes par processus
- **Network** : Bytes sent/received, connections
- **Contexte Kubernetes** : Pod name, namespace, labels

## Fonctionnalit√©s principales de Pixie

### 1. Live Debugging : D√©bogage en temps r√©el

L'interface Pixie vous permet de voir **en direct** ce qui se passe dans votre cluster.

**Exemple de vue** :

```
Service: backend-api (3 pods)

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HTTP Requests (last 60s)                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ GET  /api/users     200  15ms  [frontend]           ‚îÇ
‚îÇ POST /api/orders    201  45ms  [mobile-app]         ‚îÇ
‚îÇ GET  /api/products  500  2.3s  [web-app] ‚ö†Ô∏è         ‚îÇ
‚îÇ GET  /api/users     200  12ms  [frontend]           ‚îÇ
‚îÇ ...                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SQL Queries (slowest)                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ SELECT * FROM orders WHERE user_id = 123            ‚îÇ
‚îÇ Duration: 2.1s ‚ö†Ô∏è                                   ‚îÇ
‚îÇ Called from: /api/products handler                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Network Connections                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ backend-api ‚Üí postgres:5432    (15 connections)     ‚îÇ
‚îÇ backend-api ‚Üí redis:6379       (8 connections)      ‚îÇ
‚îÇ backend-api ‚Üê frontend         (120 req/s)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Tout cela est mis √† jour en temps r√©el !**

### 2. PxL : Pixie Language

Pixie propose un **langage de query** inspir√© de Python pour interroger les donn√©es.

**Exemple simple** : Toutes les requ√™tes HTTP avec code d'erreur 5xx

```python
import px

# R√©cup√©rer les requ√™tes HTTP
df = px.DataFrame(table='http_events', start_time='-5m')

# Filtrer les erreurs 5xx
df = df[df.resp_status >= 500]

# Afficher les colonnes pertinentes
df = df[['time_', 'req_method', 'req_path', 'resp_status', 'latency']]

# Grouper par path pour voir les endpoints probl√©matiques
df = df.groupby('req_path').agg(
    count=('req_path', px.count),
    avg_latency=('latency', px.mean)
)

px.display(df)
```

**R√©sultat** :
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ req_path             ‚îÇ count ‚îÇ avg_latency  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ /api/products        ‚îÇ 15    ‚îÇ 2345ms       ‚îÇ
‚îÇ /api/recommendations ‚îÇ 8     ‚îÇ 1200ms       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Exemple avanc√©** : Requ√™tes SQL les plus lentes par service

```python
import px

# Requ√™tes SQL
df = px.DataFrame(table='mysql_events', start_time='-10m')

# Trier par latence d√©croissante
df = df.sort_values('latency', ascending=False)

# Joindre avec les informations de pod
df = df.merge(
    px.DataFrame(table='process_stats'),
    left_on='upid',
    right_on='upid',
    how='inner'
)

# Top 10 des requ√™tes lentes
df = df.head(10)

# Afficher
df = df[['service', 'req_body', 'latency', 'resp_body']]
px.display(df)
```

### 3. Auto-tracing : Distributed tracing sans instrumentation

Pixie reconstruit automatiquement les **traces distribu√©es** en corr√©lant les requ√™tes r√©seau.

**Comment √ßa marche ?**

1. Pixie capture toutes les requ√™tes HTTP/gRPC avec leurs headers
2. Il lit les **trace IDs** dans les headers (ex: `X-Request-ID`, `traceparent`)
3. Si pas de trace ID, il utilise la **corr√©lation temporelle** et les sockets
4. Il reconstruit le graphe d'appels

**R√©sultat** : Vous obtenez des traces compl√®tes comme avec OpenTelemetry, mais **sans instrumentation** !

```
Trace ID: abc-123-def

frontend:handle_request (50ms)
  ‚îî‚îÄ> backend-api:get_user (45ms)
       ‚îú‚îÄ> postgres:query (30ms)
       ‚îÇ    ‚îî‚îÄ SELECT * FROM users WHERE id = 123
       ‚îî‚îÄ> redis:get (5ms)
            ‚îî‚îÄ GET user:123:cache
```

### 4. Service Map : Topologie automatique

Pixie g√©n√®re automatiquement une **carte de vos services** bas√©e sur le trafic observ√©.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Frontend  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ HTTP
      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Backend API‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ Postgres ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò SQL  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚îÇ Redis Protocol
      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Redis    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Informations sur chaque lien** :
- Protocol utilis√© (HTTP, SQL, etc.)
- Throughput (req/s)
- Latence moyenne/p99
- Taux d'erreur

### 5. Continuous Profiling : Profiling CPU automatique

Pixie fait du **profiling CPU** en continu de tous vos processus avec des stack traces p√©riodiques.

```
Top CPU consumers:

backend-api:
  45% : json.Marshal (encoding/json)
  25% : database/sql.Query
  15% : net/http.(*ServeMux).ServeHTTP
  10% : runtime.gcMarkWorker
  5%  : autres
```

**B√©n√©fice** : Identifier imm√©diatement les fonctions qui consomment le plus de CPU, **sans profiler manuellement**.

### 6. Donn√©es de s√©curit√©

Pixie capture aussi des √©v√©nements de s√©curit√© :

- **Connexions sortantes suspectes** : Un pod qui contacte une IP externe inconnue
- **Scans de ports** : Tentatives de connexion sur de nombreux ports
- **Commandes shell** : Ex√©cutions de bash/sh dans les conteneurs
- **Acc√®s fichiers sensibles** : Lectures de /etc/passwd, cl√©s SSH, etc.

**Exemple d'alerte** :
```
‚ö†Ô∏è  SECURITY EVENT

Pod: suspicious-pod-xyz
Namespace: production
Event: Outbound connection to unknown IP
Destination: 185.x.x.x:443 (Russia)
Protocol: HTTPS
Time: 2025-01-15 14:23:45 UTC
```

## Architecture d√©taill√©e de Pixie

### Composants

Pixie se compose de plusieurs √©l√©ments :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Cluster Kubernetes                     ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  Pixie Cloud (optionnel)               ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Interface web (Live UI)             ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Authentification                    ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Query dispatch                      ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                    ‚îÇ HTTPS                          ‚îÇ
‚îÇ                    ‚Üì                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  Pixie Vizier (dans le cluster)        ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Query broker                        ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Metadata service                    ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Data storage (court terme)          ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                    ‚îÇ                                ‚îÇ
‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ       ‚Üì               ‚Üì           ‚Üì                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ PEM     ‚îÇ  ‚îÇ PEM     ‚îÇ  ‚îÇ PEM     ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ (Node1) ‚îÇ  ‚îÇ (Node2) ‚îÇ  ‚îÇ (Node3) ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ         ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ eBPF    ‚îÇ  ‚îÇ eBPF    ‚îÇ  ‚îÇ eBPF    ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ programs‚îÇ  ‚îÇ programs‚îÇ  ‚îÇ programs‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 1. PEM (Pixie Edge Module)

- **R√¥le** : DaemonSet qui tourne sur chaque n≈ìud
- **Responsabilit√©s** :
  - Charger les programmes eBPF dans le kernel
  - Collecter les donn√©es des BPF maps
  - Parser les protocoles (HTTP, SQL, etc.)
  - Stocker temporairement les donn√©es
  - Ex√©cuter les queries PxL localement

**Note importante** : Les donn√©es restent **sur les n≈ìuds** (pas de transfert vers le cloud par d√©faut). Cela garantit la confidentialit√© et r√©duit les co√ªts r√©seau.

#### 2. Vizier

- **R√¥le** : Contr√¥leur centralis√© (Deployment)
- **Responsabilit√©s** :
  - Dispatcher les queries vers les PEM
  - Agr√©ger les r√©sultats
  - Maintenir les m√©tadonn√©es K8s
  - G√©rer l'acc√®s via API

#### 3. Pixie Cloud (optionnel)

- **R√¥le** : Interface web h√©berg√©e par Pixie/New Relic
- **Responsabilit√©s** :
  - Fournir l'UI web
  - Authentification des utilisateurs
  - Reverse proxy vers les Viziers

**Important** : Vous pouvez aussi d√©ployer Pixie en **mode self-hosted** sans le cloud, tout reste dans votre cluster.

### Flux de donn√©es

Voici ce qui se passe quand vous ex√©cutez une query :

```
1. Utilisateur : "Show me slow SQL queries"
   ‚Üì
2. Pixie UI/CLI : Envoie query PxL au Vizier
   ‚Üì
3. Vizier : Parse la query, dispatch vers tous les PEM
   ‚Üì
4. Chaque PEM :
   ‚îú‚îÄ Lit les BPF maps locales (donn√©es eBPF)
   ‚îú‚îÄ Filtre selon la query
   ‚îî‚îÄ Retourne les r√©sultats
   ‚Üì
5. Vizier : Agr√®ge les r√©sultats de tous les n≈ìuds
   ‚Üì
6. Pixie UI : Affiche les r√©sultats en temps r√©el
```

**Temps de r√©ponse typique** : 100-500 ms pour une query sur un cluster de 100 n≈ìuds !

## Cas d'usage concrets

### 1. Incident response : Debugging en production

**Sc√©nario** : Alerte "Latence √©lev√©e sur le service Payment"

**Avec Pixie** :

```bash
# 1. Voir les requ√™tes HTTP lentes du service Payment
px query "http_data|filter:service=payment,latency>1000"

# R√©sultat instantan√© :
# POST /api/charge  latency=3500ms  status=500

# 2. Voir la requ√™te SQL associ√©e
px query "mysql_events|filter:service=payment,latency>1000"

# R√©sultat :
# SELECT * FROM transactions WHERE user_id IN (...)
# latency=3200ms
# ‚ö†Ô∏è  Pas d'index sur user_id !

# 3. Voir qui appelle ce endpoint
px query "service_map|filter:destination=payment"

# R√©sultat :
# frontend-checkout ‚Üí payment (120 req/s)
```

**Temps de r√©solution** : 5 minutes au lieu de 2 heures !

### 2. Analyse de performance

**Question** : "Pourquoi notre service est lent ?"

```python
import px

# Profiling CPU
df = px.DataFrame(table='stack_traces', start_time='-5m')
df = df[df.service == 'backend-api']

# Top functions by CPU
top_funcs = df.groupby('function_name').agg(
    cpu_pct=('sample_count', px.sum)
)
top_funcs = top_funcs.sort_values('cpu_pct', ascending=False).head(10)
px.display(top_funcs)
```

**R√©sultat** : Vous d√©couvrez qu'une fonction de s√©rialisation JSON consomme 60% du CPU.

### 3. D√©tection d'anomalies

**Anomalie** : "Pic de latence inhabituel"

```python
import px

# Latence HTTP sur les 24 derni√®res heures
df = px.DataFrame(table='http_events', start_time='-24h')

# Calculer latence p99 par heure
df['hour'] = px.bin(df.time_, '1h')
stats = df.groupby('hour').agg(
    p99_latency=('latency', px.quantile, 0.99),
    count=('latency', px.count)
)

px.display(stats, chart_type='line')
```

**R√©sultat** : Graphique montrant que la latence a explos√© entre 14h et 15h.

**Deep dive** : Filtrer les requ√™tes de cette p√©riode pour voir ce qui s'est pass√©.

### 4. Audit de s√©curit√©

```python
import px

# Connexions sortantes vers des IPs externes
df = px.DataFrame(table='conn_stats', start_time='-1h')

# Filtrer les connexions sortantes hors cluster
df = df[df.remote_addr != '10.0.0.0/8']  # Exclure IPs internes
df = df[df.remote_addr != '172.16.0.0/12']
df = df[df.remote_addr != '192.168.0.0/16']

# Grouper par pod et IP de destination
suspicious = df.groupby(['pod', 'remote_addr']).agg(
    conn_count=('remote_addr', px.count)
)

px.display(suspicious)
```

**R√©sultat** : Vous d√©couvrez qu'un pod contacte une IP suspecte 1000 fois/heure.

### 5. Optimisation de co√ªts

```python
import px

# Services qui font le plus de requ√™tes √† la base de donn√©es
df = px.DataFrame(table='mysql_events', start_time='-1d')

# Compter les requ√™tes par service
stats = df.groupby('service').agg(
    query_count=('service', px.count),
    total_latency=('latency', px.sum)
)

stats = stats.sort_values('query_count', ascending=False)
px.display(stats)
```

**R√©sultat** : Vous identifiez qu'un service fait 10M requ√™tes/jour alors qu'un cache r√©duirait √ßa √† 100K.

**Action** : Ajouter Redis = √©conomies importantes sur la DB.

## Pixie vs autres solutions d'observabilit√©

### Comparaison avec OpenTelemetry + Jaeger + Prometheus

| Aspect | OpenTelemetry | Pixie |
|--------|--------------|-------|
| **Instrumentation** | Manuelle (biblioth√®ques) | Automatique (eBPF) |
| **Effort initial** | √âlev√© (modifier le code) | Faible (kubectl apply) |
| **Polyglotte** | Difficile (libs diff√©rentes) | Facile (m√™me m√©canisme) |
| **Services legacy** | ‚ùå Impossible sans code | ‚úÖ Fonctionne out of the box |
| **Overhead** | Moyen √† √©lev√© | Tr√®s faible |
| **Latence des donn√©es** | ~1-5 secondes | Temps r√©el (<100ms) |
| **Granularit√©** | D√©pend de l'instrumentation | Tr√®s fine (tout est captur√©) |
| **Setup** | Complexe (4+ composants) | Simple (1 commande) |
| **Co√ªt storage** | √âlev√© | Faible (donn√©es √©ph√©m√®res) |

**Verdict** : OpenTelemetry est excellent pour des traces structur√©es custom, mais Pixie est imbattable pour de l'observabilit√© instantan√©e sans effort.

### Comparaison avec Datadog/New Relic APM

| Aspect | Datadog APM | Pixie |
|--------|-------------|-------|
| **Instrumentation** | Agent + libs | Automatique (eBPF) |
| **Co√ªt** | $15-40/host/mois | Open-source (gratuit) |
| **Donn√©es retained** | Long terme | Court terme (par d√©faut) |
| **Propri√©taire** | Oui | Open-source |
| **SaaS vs Self-hosted** | SaaS uniquement | Les deux |
| **ML/AI** | Avanc√© | Basique |

**Note** : New Relic (qui a acquis Pixie) propose maintenant une int√©gration o√π Pixie capture les donn√©es et New Relic les stocke/analyse long terme.

### Comparaison avec Cilium Hubble

| Aspect | Cilium Hubble | Pixie |
|--------|--------------|-------|
| **Focus** | Networking L3/L4/L7 | Observabilit√© compl√®te |
| **Protocoles** | Basique (HTTP, DNS) | Avanc√© (SQL, Redis, gRPC...) |
| **M√©triques app** | ‚ùå Non | ‚úÖ Oui (CPU, memory, etc.) |
| **Traces distribu√©es** | ‚ùå Non | ‚úÖ Oui |
| **Profiling** | ‚ùå Non | ‚úÖ Oui |
| **D√©pendance** | N√©cessite Cilium | Standalone |

**Compl√©mentarit√©** : Hubble + Pixie ensemble = observabilit√© ultime !

## Limitations et consid√©rations

### 1. Donn√©es √©ph√©m√®res (par d√©faut)

Pixie stocke les donn√©es **en m√©moire** sur les n≈ìuds, avec une r√©tention de ~24 heures par d√©faut.

**Impact** :
- ‚úÖ Pas de co√ªts de storage
- ‚úÖ Haute performance
- ‚ùå Pas d'analyse historique long terme

**Solution** : Int√©grer avec un syst√®me de stockage long terme (Prometheus, New Relic, etc.).

### 2. Overhead m√©moire

Chaque PEM consomme environ **1-2 GB de RAM** pour stocker les donn√©es r√©centes.

**Mitigation** :
- Ajuster la r√©tention (peut √™tre r√©duite)
- Filtrer les donn√©es collect√©es (certains namespaces uniquement)

### 3. Protocoles propri√©taires

Si votre application utilise un protocole custom/propri√©taire, Pixie ne pourra pas le parser automatiquement.

**Solution** : Contribuer un parser au projet Pixie (open-source !).

### 4. Kernel requis

Pixie n√©cessite :
- **Kernel Linux >= 4.14**
- **BTF activ√©** (pour kernels r√©cents)

La plupart des distributions modernes sont OK, mais v√©rifiez sur des setups anciens.

### 5. Donn√©es sensibles

Pixie capture **tout le trafic**, y compris potentiellement :
- Mots de passe en clair (si dans les requ√™tes HTTP)
- Tokens d'authentification
- Donn√©es personnelles (PII)

**Important** :
- Configurez des **redaction rules** pour masquer les donn√©es sensibles
- Restreignez l'acc√®s √† Pixie (RBAC Kubernetes)
- En mode self-hosted, les donn√©es restent dans votre cluster

**Exemple de redaction** :
```yaml
# Masquer les passwords dans les URLs
apiVersion: px.dev/v1alpha1
kind: RedactionConfig
metadata:
  name: redact-passwords
spec:
  rules:
  - pattern: "password=[^&]*"
    replacement: "password=***REDACTED***"
```

## Int√©gration avec l'√©cosyst√®me

### Avec Prometheus

```python
# Script PxL qui export vers Prometheus
import px

df = px.DataFrame(table='http_events')
# Calculer m√©triques
metrics = df.groupby('service').agg(
    request_count=('service', px.count),
    avg_latency=('latency', px.mean)
)

# Export vers Prometheus remote-write
px.export(metrics, format='prometheus')
```

### Avec Grafana

Pixie a un **datasource Grafana** officiel pour cr√©er des dashboards.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Grafana Dashboard             ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ  [HTTP Requests by Service]        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  backend-api:  1200 req/s   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  frontend:     800 req/s    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  payment:      300 req/s    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ  Data source: Pixie                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Avec OpenTelemetry

Pixie peut exporter ses traces au format OpenTelemetry :

```yaml
# Exporter les traces Pixie vers Jaeger via OTLP
apiVersion: v1
kind: ConfigMap
metadata:
  name: pixie-otel-export
data:
  endpoint: "jaeger-collector:4317"
  protocol: "grpc"
```

### Avec New Relic

Int√©gration native pour envoyer les donn√©es Pixie vers New Relic pour r√©tention long terme.

## Installation et premiers pas

### Installation (m√©thode rapide)

```bash
# 1. Installer le CLI Pixie
bash -c "$(curl -fsSL https://withpixie.ai/install.sh)"

# 2. Se connecter (cr√©e un compte gratuit)
px auth login

# 3. D√©ployer Pixie dans votre cluster
px deploy

# 4. Attendre que tout soit pr√™t (~2 minutes)
px get viziers

# 5. Ouvrir l'UI
px live
```

**C'est tout !** Vous avez maintenant l'observabilit√© compl√®te.

### Premi√®re query

```bash
# Voir toutes les requ√™tes HTTP
px query "http_data"

# Filtrer par service
px query "http_data|filter:service=backend-api"

# Voir les erreurs 5xx
px query "http_data|filter:resp_status>=500"
```

### Scripts PxL utiles (pr√©-install√©s)

Pixie vient avec de nombreux scripts pr√©-configur√©s :

```bash
# Liste des scripts disponibles
px scripts list

# Exemples :
px run px/service_stats       # Vue d'ensemble des services
px run px/http_data           # Requ√™tes HTTP
px run px/mysql_data          # Requ√™tes MySQL
px run px/redis_data          # Commandes Redis
px run px/dns_flow_graph      # Graphe DNS
px run px/pod_cpu_mem         # CPU/M√©moire par pod
px run px/network_connections # Connexions r√©seau
px run px/http_post_requests  # POST requests avec body
```

## Ressources pour aller plus loin

### Documentation officielle

- **Site officiel** : https://px.dev
- **Documentation** : https://docs.px.dev
- **GitHub** : https://github.com/pixie-io/pixie
- **Blog** : https://blog.px.dev

### Tutoriels

- **Getting Started** : https://docs.px.dev/installing-pixie/quick-start/
- **PxL tutorials** : https://docs.px.dev/tutorials/pxl-scripts/
- **YouTube channel** : Vid√©os de d√©monstration

### Communaut√©

- **Pixie Slack** : https://slackin.px.dev
- **GitHub Discussions** : Questions et r√©ponses
- **Twitter** : @pixie_run

### Exemples de scripts PxL

Repository de scripts PxL communautaires :
- https://github.com/pixie-io/pixie/tree/main/src/pxl_scripts

### Int√©grations

- **New Relic** : https://docs.newrelic.com/docs/kubernetes-pixie/
- **Grafana** : https://grafana.com/grafana/plugins/grafana-pixie-datasource/

## Conclusion

Pixie repr√©sente une **r√©volution dans l'observabilit√©** gr√¢ce √† eBPF. C'est l'exemple parfait de comment eBPF peut r√©soudre des probl√®mes complexes de mani√®re √©l√©gante.

**Ce que Pixie d√©montre :**

- ‚úÖ **L'auto-instrumentation fonctionne** : Plus besoin de modifier le code
- ‚úÖ **eBPF est production-ready** : Pixie est utilis√© par des milliers d'entreprises
- ‚úÖ **Performance exceptionnelle** : Overhead n√©gligeable, donn√©es en temps r√©el
- ‚úÖ **Simplicit√© d'usage** : kubectl apply et c'est parti
- ‚úÖ **Visibilit√© compl√®te** : M√™me les services legacy deviennent observables

**Pourquoi c'est important pour vous :**

Si vous g√©rez des applications Kubernetes en production, Pixie est un **game-changer** :
- **Gain de temps** : Debugging 10x plus rapide
- **√âconomies** : Pas besoin d'infrastructure d'observabilit√© lourde
- **S√©r√©nit√©** : Visibilit√© totale √† tout moment

**Pixie + Cilium = Combo gagnant** :
- Cilium pour le networking ultra-performant
- Pixie pour l'observabilit√© instantan√©e
- Les deux bas√©s sur eBPF, z√©ro conflict

---

**Fun facts** :
- Pixie a √©t√© cr√©√© par Zain Asgar, ancien ing√©nieur Google qui travaillait sur... eBPF !
- Le nom "Pixie" vient de "Pixel" (observation fine) + "Magic" (magie d'eBPF)
- Pixie peut parser plus de 20 protocoles diff√©rents automatiquement
- New Relic a pay√© 30+ millions $ pour acqu√©rir Pixie, puis l'a rendu enti√®rement open-source

---

*Note : Cette section donne une vue d'ensemble de Pixie. Pour une utilisation en production, suivez les best practices de s√©curit√© (redaction, RBAC, etc.) et consultez la documentation officielle.*

‚è≠Ô∏è [Ressources pour aller plus loin](/21-introduction-ebpf/06.3-ressources.md)
