üîù Retour au [Sommaire](/SOMMAIRE.md)

# 27.6 Optimisations algorithmiques

## Introduction

Les **optimisations algorithmiques** consistent √† choisir ou concevoir des algorithmes plus efficaces pour r√©soudre un probl√®me donn√©. C'est souvent **le levier d'optimisation le plus puissant** : un bon algorithme peut √™tre **100 √† 1000 fois plus rapide** qu'un mauvais algorithme, m√™me sans aucune autre optimisation !

### La hi√©rarchie des optimisations

```
1. Algorithme efficace         ‚Üê Impact : 100-1000x
2. Structures de donn√©es       ‚Üê Impact : 10-100x
3. Optimisations cache         ‚Üê Impact : 2-10x
4. Optimisations compilateur   ‚Üê Impact : 1.5-3x
5. Optimisations assembleur    ‚Üê Impact : 1.1-1.5x
```

**Citation c√©l√®bre :**

> "Premature optimization is the root of all evil, but choosing a bad algorithm is the root of all performance problems" ‚Äî Adapt√© de Donald Knuth

### Analogie : Choisir le bon v√©hicule

Imaginez que vous devez aller de Paris √† Marseille (800 km) :

- **Marche √† pied** : 200 heures (mauvais algorithme)
- **V√©lo** : 40 heures (algorithme lent)
- **Voiture** : 8 heures (bon algorithme)
- **TGV** : 3 heures (algorithme optimal)

Optimiser la marche √† pied (chaussures plus l√©g√®res, meilleure technique) ne vous fera **jamais** battre le TGV. Il faut d'abord choisir le bon moyen de transport (algorithme) !

---

## Complexit√© algorithmique : Notation Big-O

La **notation Big-O** d√©crit comment le temps d'ex√©cution d'un algorithme √©volue quand la taille des donn√©es augmente.

### Notations courantes

| Notation | Nom | Exemple | √âvolution |
|----------|-----|---------|-----------|
| **O(1)** | Constant | Acc√®s tableau par index | Toujours le m√™me temps |
| **O(log n)** | Logarithmique | Recherche dichotomique | Tr√®s lent |
| **O(n)** | Lin√©aire | Parcours de tableau | Proportionnel √† n |
| **O(n log n)** | Lin√©arithmique | Tri rapide (quicksort) | Acceptable |
| **O(n¬≤)** | Quadratique | Tri √† bulles | Rapide pour petites donn√©es |
| **O(n¬≥)** | Cubique | Multiplication matrices na√Øve | Lent |
| **O(2‚Åø)** | Exponentiel | Probl√®me du voyageur (brute force) | Catastrophique |
| **O(n!)** | Factoriel | Permutations compl√®tes | Inutilisable au-del√† de n=10 |

### Visualisation de la croissance

```
Temps (pour n √©l√©ments)

      ‚îÇ
1000s ‚îÇ                                                    O(2‚Åø)
      ‚îÇ                                                 ‚ï±
      ‚îÇ                                              ‚ï±
100s  ‚îÇ                                          O(n¬≤)
      ‚îÇ                                       ‚ï±
      ‚îÇ                                   ‚ï±
10s   ‚îÇ                              ‚ï±
      ‚îÇ                          ‚ï± O(n log n)
1s    ‚îÇ                     ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      ‚îÇ              ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
0.1s  ‚îÇ      O(log n)  O(n)
      ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> n
      10   100  1000  10000  100000
```

### Exemple concret

Pour **n = 1,000,000** √©l√©ments :

- **O(1)** : 1 op√©ration (instantan√©)
- **O(log n)** : ~20 op√©rations (instantan√©)
- **O(n)** : 1,000,000 op√©rations (~1 ms)
- **O(n log n)** : ~20,000,000 op√©rations (~20 ms)
- **O(n¬≤)** : 1,000,000,000,000 op√©rations (~17 minutes !)
- **O(2‚Åø)** : ... l'univers n'est pas assez vieux

**Conclusion :** Avec de grandes donn√©es, seuls les algorithmes O(1), O(log n), O(n) et O(n log n) sont viables.

---

## Exemples classiques : Bons vs mauvais algorithmes

### Exemple 1 : Recherche dans un tableau

#### Recherche lin√©aire : O(n)

```c
// Chercher une valeur dans un tableau non tri√©
int recherche_lineaire(int *tableau, int taille, int cible) {
    for (int i = 0; i < taille; i++) {
        if (tableau[i] == cible) {
            return i;  // Trouv√© !
        }
    }
    return -1;  // Non trouv√©
}
```

**Complexit√© :** O(n) ‚Äî Dans le pire cas, on doit parcourir tout le tableau.

**Performance :**
- 1,000 √©l√©ments : ~1,000 comparaisons
- 1,000,000 √©l√©ments : ~1,000,000 comparaisons

#### Recherche dichotomique : O(log n)

**Condition :** Le tableau doit √™tre **tri√©** !

```c
// Chercher dans un tableau tri√©
int recherche_dichotomique(int *tableau, int taille, int cible) {
    int gauche = 0;
    int droite = taille - 1;

    while (gauche <= droite) {
        int milieu = gauche + (droite - gauche) / 2;

        if (tableau[milieu] == cible) {
            return milieu;  // Trouv√© !
        }

        if (tableau[milieu] < cible) {
            gauche = milieu + 1;  // Chercher √† droite
        } else {
            droite = milieu - 1;  // Chercher √† gauche
        }
    }

    return -1;  // Non trouv√©
}
```

**Complexit√© :** O(log n) ‚Äî On divise l'espace de recherche par 2 √† chaque √©tape.

**Performance :**
- 1,000 √©l√©ments : ~10 comparaisons
- 1,000,000 √©l√©ments : ~20 comparaisons
- 1,000,000,000 √©l√©ments : ~30 comparaisons

**Benchmark :**

```c
// test_recherche.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define TAILLE 1000000

int main() {
    int *tableau = malloc(TAILLE * sizeof(int));

    // Remplir avec valeurs tri√©es
    for (int i = 0; i < TAILLE; i++) {
        tableau[i] = i;
    }

    clock_t debut, fin;
    int resultat;

    // Recherche lin√©aire
    debut = clock();
    for (int i = 0; i < 1000; i++) {  // 1000 recherches
        resultat = recherche_lineaire(tableau, TAILLE, TAILLE - 1);
    }
    fin = clock();
    printf("Recherche lin√©aire: %.3f ms\n",
           (double)(fin - debut) * 1000 / CLOCKS_PER_SEC);

    // Recherche dichotomique
    debut = clock();
    for (int i = 0; i < 1000; i++) {  // 1000 recherches
        resultat = recherche_dichotomique(tableau, TAILLE, TAILLE - 1);
    }
    fin = clock();
    printf("Recherche dichotomique: %.3f ms\n",
           (double)(fin - debut) * 1000 / CLOCKS_PER_SEC);

    free(tableau);
    return 0;
}
```

**R√©sultats typiques :**
```
Recherche lin√©aire: 3250.5 ms
Recherche dichotomique: 0.8 ms  ‚Üê 4000x plus rapide !
```

**Conclusion :** Si vous faites beaucoup de recherches, **triez d'abord** le tableau, puis utilisez la recherche dichotomique.

---

### Exemple 2 : Tri de donn√©es

#### Tri √† bulles : O(n¬≤)

```c
void tri_bulles(int *tableau, int taille) {
    for (int i = 0; i < taille - 1; i++) {
        for (int j = 0; j < taille - i - 1; j++) {
            if (tableau[j] > tableau[j + 1]) {
                // √âchanger
                int temp = tableau[j];
                tableau[j] = tableau[j + 1];
                tableau[j + 1] = temp;
            }
        }
    }
}
```

**Complexit√© :** O(n¬≤) ‚Äî Double boucle imbriqu√©e.

**Performance :**
- 1,000 √©l√©ments : ~1,000,000 comparaisons (~10 ms)
- 10,000 √©l√©ments : ~100,000,000 comparaisons (~1 seconde)
- 100,000 √©l√©ments : ~10,000,000,000 comparaisons (~2 minutes)

#### Quicksort : O(n log n)

```c
int partition(int *tableau, int bas, int haut) {
    int pivot = tableau[haut];
    int i = bas - 1;

    for (int j = bas; j < haut; j++) {
        if (tableau[j] < pivot) {
            i++;
            // √âchanger tableau[i] et tableau[j]
            int temp = tableau[i];
            tableau[i] = tableau[j];
            tableau[j] = temp;
        }
    }

    // Placer le pivot √† sa position finale
    int temp = tableau[i + 1];
    tableau[i + 1] = tableau[haut];
    tableau[haut] = temp;

    return i + 1;
}

void quicksort(int *tableau, int bas, int haut) {
    if (bas < haut) {
        int pi = partition(tableau, bas, haut);
        quicksort(tableau, bas, pi - 1);
        quicksort(tableau, pi + 1, haut);
    }
}

// Fonction d'entr√©e
void tri_rapide(int *tableau, int taille) {
    quicksort(tableau, 0, taille - 1);
}
```

**Complexit√© :** O(n log n) en moyenne.

**Performance :**
- 1,000 √©l√©ments : ~10,000 comparaisons (~0.1 ms)
- 10,000 √©l√©ments : ~133,000 comparaisons (~1.3 ms)
- 100,000 √©l√©ments : ~1,700,000 comparaisons (~17 ms)

**Benchmark :**

```c
// test_tri.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <string.h>

#define TAILLE 10000

void generer_aleatoire(int *tableau, int taille) {
    for (int i = 0; i < taille; i++) {
        tableau[i] = rand();
    }
}

int main() {
    int *tableau1 = malloc(TAILLE * sizeof(int));
    int *tableau2 = malloc(TAILLE * sizeof(int));

    generer_aleatoire(tableau1, TAILLE);
    memcpy(tableau2, tableau1, TAILLE * sizeof(int));

    clock_t debut, fin;

    // Tri √† bulles
    debut = clock();
    tri_bulles(tableau1, TAILLE);
    fin = clock();
    printf("Tri √† bulles: %.3f ms\n",
           (double)(fin - debut) * 1000 / CLOCKS_PER_SEC);

    // Quicksort
    debut = clock();
    tri_rapide(tableau2, TAILLE);
    fin = clock();
    printf("Quicksort: %.3f ms\n",
           (double)(fin - debut) * 1000 / CLOCKS_PER_SEC);

    free(tableau1);
    free(tableau2);
    return 0;
}
```

**R√©sultats typiques :**
```
Tri √† bulles: 485.3 ms
Quicksort: 1.2 ms  ‚Üê 400x plus rapide !
```

**Conclusion :** Pour trier, utilisez toujours `qsort()` de la stdlib (ou un algorithme O(n log n)). Jamais de tri √† bulles en production !

---

### Exemple 3 : V√©rifier les doublons

#### Algorithme na√Øf : O(n¬≤)

```c
// V√©rifier si un tableau contient des doublons
int contient_doublons_naif(int *tableau, int taille) {
    for (int i = 0; i < taille; i++) {
        for (int j = i + 1; j < taille; j++) {
            if (tableau[i] == tableau[j]) {
                return 1;  // Doublon trouv√©
            }
        }
    }
    return 0;  // Pas de doublon
}
```

**Complexit√© :** O(n¬≤) ‚Äî Double boucle pour comparer chaque paire.

#### Avec tri : O(n log n)

```c
int contient_doublons_tri(int *tableau, int taille) {
    // Copier pour ne pas modifier l'original
    int *copie = malloc(taille * sizeof(int));
    memcpy(copie, tableau, taille * sizeof(int));

    // Trier
    qsort(copie, taille, sizeof(int), compare);

    // V√©rifier les √©l√©ments adjacents
    int resultat = 0;
    for (int i = 0; i < taille - 1; i++) {
        if (copie[i] == copie[i + 1]) {
            resultat = 1;  // Doublon trouv√©
            break;
        }
    }

    free(copie);
    return resultat;
}
```

**Complexit√© :** O(n log n) pour le tri + O(n) pour la v√©rification = O(n log n)

#### Avec table de hachage : O(n)

```c
#include <stdbool.h>

// Utiliser une table de hachage simple (limit√©e aux valeurs positives < MAX)
#define MAX_VAL 1000000

int contient_doublons_hash(int *tableau, int taille) {
    bool *vu = calloc(MAX_VAL, sizeof(bool));

    for (int i = 0; i < taille; i++) {
        if (tableau[i] >= 0 && tableau[i] < MAX_VAL) {
            if (vu[tableau[i]]) {
                free(vu);
                return 1;  // Doublon trouv√©
            }
            vu[tableau[i]] = true;
        }
    }

    free(vu);
    return 0;  // Pas de doublon
}
```

**Complexit√© :** O(n) ‚Äî Un seul parcours du tableau.

**Performance :**

| Taille | Na√Øf O(n¬≤) | Tri O(n log n) | Hash O(n) |
|--------|------------|----------------|-----------|
| 1,000 | 10 ms | 0.5 ms | 0.1 ms |
| 10,000 | 1000 ms | 5 ms | 1 ms |
| 100,000 | 100,000 ms | 60 ms | 10 ms |

**Conclusion :** La table de hachage est la plus rapide, mais n√©cessite de la m√©moire suppl√©mentaire.

---

## Structures de donn√©es et performances

Le choix de la structure de donn√©es a un impact √©norme sur les performances.

### Tableau dynamique vs Liste cha√Æn√©e

| Op√©ration | Tableau | Liste cha√Æn√©e |
|-----------|---------|---------------|
| Acc√®s par index | O(1) ‚úÖ | O(n) ‚ùå |
| Insertion d√©but | O(n) ‚ùå | O(1) ‚úÖ |
| Insertion fin | O(1)* | O(1)* |
| Suppression d√©but | O(n) ‚ùå | O(1) ‚úÖ |
| Suppression milieu | O(n) | O(n) |
| Recherche | O(n) | O(n) |
| Cache-friendly | Oui ‚úÖ | Non ‚ùå |

\* Amortie pour le tableau (avec reallocation), O(1) si on garde un pointeur vers la fin pour la liste.

**R√®gle g√©n√©rale :**
- **Tableau** : Si vous acc√©dez souvent par index et ajoutez/supprimez rarement
- **Liste cha√Æn√©e** : Si vous ins√©rez/supprimez fr√©quemment au d√©but

**En pratique :** Les tableaux sont presque toujours plus rapides gr√¢ce √† la localit√© cache, m√™me pour des insertions/suppressions.

### Table de hachage vs Arbre binaire de recherche

| Op√©ration | Table de hachage | Arbre √©quilibr√© (AVL, Red-Black) |
|-----------|------------------|----------------------------------|
| Recherche | O(1) ‚úÖ | O(log n) |
| Insertion | O(1) ‚úÖ | O(log n) |
| Suppression | O(1) ‚úÖ | O(log n) |
| Ordre tri√© | Non ‚ùå | Oui ‚úÖ |
| Parcours ordonn√© | O(n log n) | O(n) ‚úÖ |
| M√©moire | Plus ‚ùå | Moins ‚úÖ |

**R√®gle g√©n√©rale :**
- **Table de hachage** : Si vous n'avez pas besoin d'ordre
- **Arbre** : Si vous devez maintenir un ordre ou faire des parcours tri√©s

---

## Cas d'√©tude : Comptage de mots

### Probl√®me : Compter les occurrences de chaque mot dans un texte

#### Solution 1 : Tableau de structures (na√Øf)

```c
struct Mot {
    char texte[50];
    int compte;
};

void compter_mots_naif(char **mots, int nb_mots) {
    struct Mot *compteurs = malloc(nb_mots * sizeof(struct Mot));
    int nb_uniques = 0;

    for (int i = 0; i < nb_mots; i++) {
        // Chercher si le mot existe d√©j√†
        int trouve = 0;
        for (int j = 0; j < nb_uniques; j++) {
            if (strcmp(mots[i], compteurs[j].texte) == 0) {
                compteurs[j].compte++;
                trouve = 1;
                break;
            }
        }

        if (!trouve) {
            strcpy(compteurs[nb_uniques].texte, mots[i]);
            compteurs[nb_uniques].compte = 1;
            nb_uniques++;
        }
    }

    free(compteurs);
}
```

**Complexit√© :** O(n¬≤) ‚Äî Pour chaque mot, on parcourt le tableau des mots uniques.

**Performance :**
- 10,000 mots : ~5 secondes
- 100,000 mots : ~500 secondes (8 minutes !)

#### Solution 2 : Tri + comptage

```c
void compter_mots_tri(char **mots, int nb_mots) {
    // Trier les mots
    qsort(mots, nb_mots, sizeof(char*), compare_strings);

    // Compter les mots adjacents identiques
    char *mot_courant = mots[0];
    int compte = 1;

    for (int i = 1; i < nb_mots; i++) {
        if (strcmp(mots[i], mot_courant) == 0) {
            compte++;
        } else {
            printf("%s: %d\n", mot_courant, compte);
            mot_courant = mots[i];
            compte = 1;
        }
    }
    printf("%s: %d\n", mot_courant, compte);
}
```

**Complexit√© :** O(n log n) pour le tri + O(n) pour le comptage = O(n log n)

**Performance :**
- 10,000 mots : ~10 ms
- 100,000 mots : ~120 ms

**Am√©lioration :** 500x plus rapide !

#### Solution 3 : Table de hachage (optimal)

```c
#include <uthash.h>  // Biblioth√®que de table de hachage

struct MotHash {
    char texte[50];      // Cl√©
    int compte;          // Valeur
    UT_hash_handle hh;   // Handle pour uthash
};

void compter_mots_hash(char **mots, int nb_mots) {
    struct MotHash *hash = NULL;

    for (int i = 0; i < nb_mots; i++) {
        struct MotHash *element;

        // Chercher dans la table de hachage
        HASH_FIND_STR(hash, mots[i], element);

        if (element == NULL) {
            // Nouveau mot
            element = malloc(sizeof(struct MotHash));
            strcpy(element->texte, mots[i]);
            element->compte = 1;
            HASH_ADD_STR(hash, texte, element);
        } else {
            // Mot existant
            element->compte++;
        }
    }

    // Afficher les r√©sultats
    struct MotHash *element, *tmp;
    HASH_ITER(hh, hash, element, tmp) {
        printf("%s: %d\n", element->texte, element->compte);
        HASH_DEL(hash, element);
        free(element);
    }
}
```

**Complexit√© :** O(n) ‚Äî Un seul parcours avec des op√©rations O(1) sur la table de hachage.

**Performance :**
- 10,000 mots : ~2 ms
- 100,000 mots : ~20 ms

**Am√©lioration :** 25000x plus rapide que la solution na√Øve !

---

## Memoization : √âviter les calculs redondants

### Exemple : Suite de Fibonacci

#### Version r√©cursive na√Øve : O(2‚Åø)

```c
int fibonacci_naif(int n) {
    if (n <= 1) {
        return n;
    }
    return fibonacci_naif(n - 1) + fibonacci_naif(n - 2);
}
```

**Probl√®me :** Calcule plusieurs fois les m√™mes valeurs !

```
fibonacci(5)
‚îú‚îÄ‚îÄ fibonacci(4)
‚îÇ   ‚îú‚îÄ‚îÄ fibonacci(3)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fibonacci(2)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fibonacci(1) ‚Üê Calcul√©
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fibonacci(0) ‚Üê Calcul√©
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fibonacci(1) ‚Üê Recalcul√© !
‚îÇ   ‚îî‚îÄ‚îÄ fibonacci(2)
‚îÇ       ‚îú‚îÄ‚îÄ fibonacci(1) ‚Üê Recalcul√© !
‚îÇ       ‚îî‚îÄ‚îÄ fibonacci(0) ‚Üê Recalcul√© !
‚îî‚îÄ‚îÄ fibonacci(3)
    ‚îú‚îÄ‚îÄ fibonacci(2)
    ‚îÇ   ‚îú‚îÄ‚îÄ fibonacci(1) ‚Üê Recalcul√© !
    ‚îÇ   ‚îî‚îÄ‚îÄ fibonacci(0) ‚Üê Recalcul√© !
    ‚îî‚îÄ‚îÄ fibonacci(1) ‚Üê Recalcul√© !
```

**Performance :**
- fibonacci(10) : ~177 appels
- fibonacci(20) : ~21,891 appels
- fibonacci(40) : ~2,692,537,283 appels (~10 secondes !)
- fibonacci(50) : ... des heures

#### Version avec memoization : O(n)

```c
#define MAX_N 100
long long memo[MAX_N];

void init_memo() {
    for (int i = 0; i < MAX_N; i++) {
        memo[i] = -1;  // -1 = pas encore calcul√©
    }
}

long long fibonacci_memo(int n) {
    if (n <= 1) {
        return n;
    }

    // D√©j√† calcul√© ?
    if (memo[n] != -1) {
        return memo[n];
    }

    // Calculer et m√©moriser
    memo[n] = fibonacci_memo(n - 1) + fibonacci_memo(n - 2);
    return memo[n];
}
```

**Performance :**
- fibonacci(10) : 19 appels
- fibonacci(20) : 39 appels
- fibonacci(40) : 79 appels (~0.0001 secondes)
- fibonacci(50) : 99 appels (~0.0001 secondes)

**Am√©lioration :** 100,000x plus rapide pour n=40 !

#### Version it√©rative : O(n), encore plus efficace

```c
long long fibonacci_iteratif(int n) {
    if (n <= 1) return n;

    long long prev = 0, curr = 1;

    for (int i = 2; i <= n; i++) {
        long long next = prev + curr;
        prev = curr;
        curr = next;
    }

    return curr;
}
```

**Avantages :**
- Pas de r√©cursion (pas de risque de stack overflow)
- Pas besoin de m√©moire suppl√©mentaire (juste 2 variables)
- Plus cache-friendly

---

## Algorithmes de recherche de motifs

### Recherche na√Øve dans une cha√Æne : O(n√óm)

```c
// Chercher un motif dans un texte
int recherche_naive(const char *texte, const char *motif) {
    int n = strlen(texte);
    int m = strlen(motif);

    for (int i = 0; i <= n - m; i++) {
        int j;
        for (j = 0; j < m; j++) {
            if (texte[i + j] != motif[j]) {
                break;
            }
        }
        if (j == m) {
            return i;  // Trouv√© √† la position i
        }
    }

    return -1;  // Non trouv√©
}
```

**Complexit√© :** O(n√óm) o√π n = longueur du texte, m = longueur du motif

### Algorithme KMP (Knuth-Morris-Pratt) : O(n+m)

**Id√©e :** Utiliser les informations d√©j√† compar√©es pour √©viter de recomparer.

```c
// Calculer la table de pr√©fixes
void calculer_lps(const char *motif, int m, int *lps) {
    int longueur = 0;
    lps[0] = 0;
    int i = 1;

    while (i < m) {
        if (motif[i] == motif[longueur]) {
            longueur++;
            lps[i] = longueur;
            i++;
        } else {
            if (longueur != 0) {
                longueur = lps[longueur - 1];
            } else {
                lps[i] = 0;
                i++;
            }
        }
    }
}

int recherche_kmp(const char *texte, const char *motif) {
    int n = strlen(texte);
    int m = strlen(motif);

    int *lps = malloc(m * sizeof(int));
    calculer_lps(motif, m, lps);

    int i = 0;  // Index pour texte
    int j = 0;  // Index pour motif

    while (i < n) {
        if (motif[j] == texte[i]) {
            i++;
            j++;
        }

        if (j == m) {
            free(lps);
            return i - j;  // Trouv√©
        } else if (i < n && motif[j] != texte[i]) {
            if (j != 0) {
                j = lps[j - 1];
            } else {
                i++;
            }
        }
    }

    free(lps);
    return -1;  // Non trouv√©
}
```

**Complexit√© :** O(n + m) ‚Äî Plus efficace pour de longs textes et motifs.

**Performance :**
- Texte de 1,000,000 caract√®res, motif de 100 caract√®res
- Na√Øf : ~100 ms
- KMP : ~15 ms

**Note :** En pratique, `strstr()` de la stdlib utilise souvent Boyer-Moore ou d'autres algorithmes optimis√©s.

---

## Diviser pour r√©gner (Divide and Conquer)

### Principe

Diviser un gros probl√®me en petits sous-probl√®mes plus faciles √† r√©soudre.

**Exemples d'algorithmes :**
- Quicksort
- Mergesort
- Recherche dichotomique
- Multiplication de matrices de Strassen

### Cas d'√©tude : Trouver le maximum dans un tableau

#### Version lin√©aire : O(n)

```c
int trouver_max(int *tableau, int taille) {
    int max = tableau[0];
    for (int i = 1; i < taille; i++) {
        if (tableau[i] > max) {
            max = tableau[i];
        }
    }
    return max;
}
```

#### Version diviser pour r√©gner : O(n) aussi, mais parall√©lisable

```c
int trouver_max_divide(int *tableau, int debut, int fin) {
    // Cas de base : un seul √©l√©ment
    if (debut == fin) {
        return tableau[debut];
    }

    // Diviser
    int milieu = debut + (fin - debut) / 2;

    // Conqu√©rir r√©cursivement
    int max_gauche = trouver_max_divide(tableau, debut, milieu);
    int max_droite = trouver_max_divide(tableau, milieu + 1, fin);

    // Combiner
    return (max_gauche > max_droite) ? max_gauche : max_droite;
}
```

**Avantage :** Cette version est facilement parall√©lisable (on peut calculer max_gauche et max_droite en parall√®le).

---

## Programmation dynamique

### Principe

R√©soudre un probl√®me en le d√©composant en sous-probl√®mes **qui se chevauchent**, et m√©moriser les r√©sultats (memoization ou tabulation).

**Diff√©rence avec diviser pour r√©gner :**
- **Diviser pour r√©gner** : Sous-probl√®mes **ind√©pendants**
- **Programmation dynamique** : Sous-probl√®mes **qui se chevauchent**

### Exemple : Probl√®me du sac √† dos (Knapsack)

**Probl√®me :** Vous avez un sac avec une capacit√© maximale et des objets avec poids et valeurs. Maximiser la valeur totale sans d√©passer la capacit√©.

#### Solution r√©cursive na√Øve : O(2‚Åø)

```c
int knapsack_naif(int capacite, int *poids, int *valeurs, int n) {
    // Cas de base
    if (n == 0 || capacite == 0) {
        return 0;
    }

    // Si le dernier objet est trop lourd
    if (poids[n - 1] > capacite) {
        return knapsack_naif(capacite, poids, valeurs, n - 1);
    }

    // Comparer : inclure vs exclure l'objet
    int avec = valeurs[n - 1] +
               knapsack_naif(capacite - poids[n - 1], poids, valeurs, n - 1);
    int sans = knapsack_naif(capacite, poids, valeurs, n - 1);

    return (avec > sans) ? avec : sans;
}
```

**Performance :** Exponentiel, inutilisable pour n > 20.

#### Solution avec programmation dynamique : O(n√ócapacit√©)

```c
int knapsack_dp(int capacite, int *poids, int *valeurs, int n) {
    // Table pour m√©moriser les r√©sultats
    int **dp = malloc((n + 1) * sizeof(int*));
    for (int i = 0; i <= n; i++) {
        dp[i] = calloc(capacite + 1, sizeof(int));
    }

    // Remplir la table de mani√®re it√©rative
    for (int i = 1; i <= n; i++) {
        for (int w = 1; w <= capacite; w++) {
            if (poids[i - 1] <= w) {
                // On peut inclure l'objet
                int avec = valeurs[i - 1] + dp[i - 1][w - poids[i - 1]];
                int sans = dp[i - 1][w];
                dp[i][w] = (avec > sans) ? avec : sans;
            } else {
                // Trop lourd
                dp[i][w] = dp[i - 1][w];
            }
        }
    }

    int resultat = dp[n][capacite];

    // Lib√©rer la m√©moire
    for (int i = 0; i <= n; i++) {
        free(dp[i]);
    }
    free(dp);

    return resultat;
}
```

**Performance :**
- n=20, capacit√©=100 : ~0.001 secondes (vs plusieurs minutes pour la version na√Øve)
- n=100, capacit√©=1000 : ~0.1 secondes

---

## Algorithmes gloutons (Greedy)

### Principe

√Ä chaque √©tape, faire le choix **localement optimal** en esp√©rant qu'il m√®ne au r√©sultat global optimal.

**Avantages :**
- ‚úÖ Simples √† impl√©menter
- ‚úÖ Rapides (souvent O(n log n))

**Inconv√©nients :**
- ‚ùå Ne garantissent pas toujours l'optimum
- ‚ùå Difficile de prouver la correction

### Exemple : Probl√®me du rendu de monnaie

**Probl√®me :** Rendre une somme avec le minimum de pi√®ces.

**Syst√®me de pi√®ces europ√©en :** 1, 2, 5, 10, 20, 50 centimes, 1‚Ç¨, 2‚Ç¨

#### Algorithme glouton

```c
void rendre_monnaie(int montant, int *pieces, int nb_pieces) {
    int compte[nb_pieces];
    for (int i = 0; i < nb_pieces; i++) {
        compte[i] = 0;
    }

    // Trier les pi√®ces par ordre d√©croissant
    qsort(pieces, nb_pieces, sizeof(int), compare_desc);

    // Prendre la plus grosse pi√®ce possible √† chaque fois
    for (int i = 0; i < nb_pieces; i++) {
        while (montant >= pieces[i]) {
            montant -= pieces[i];
            compte[i]++;
        }
    }

    // Afficher le r√©sultat
    for (int i = 0; i < nb_pieces; i++) {
        if (compte[i] > 0) {
            printf("%d pi√®ce(s) de %d centimes\n", compte[i], pieces[i]);
        }
    }
}
```

**Exemple :** Rendre 87 centimes
- 1 pi√®ce de 50
- 1 pi√®ce de 20
- 1 pi√®ce de 10
- 1 pi√®ce de 5
- 1 pi√®ce de 2
**Total : 5 pi√®ces** (optimal ‚úÖ)

**Note :** L'algorithme glouton fonctionne pour le syst√®me europ√©en, mais pas pour tous les syst√®mes de pi√®ces !

**Contre-exemple :**
Pi√®ces : {1, 3, 4}, montant : 6
- Glouton : 4 + 1 + 1 = **3 pi√®ces**
- Optimal : 3 + 3 = **2 pi√®ces** ‚ùå

---

## Checklist pour choisir un algorithme

Avant d'impl√©menter :

1. ‚úÖ **Quelle est la taille typique des donn√©es ?**
   - Petite (n < 100) : M√™me un O(n¬≤) va bien
   - Moyenne (100 < n < 10,000) : O(n log n) recommand√©
   - Grande (n > 10,000) : O(n) ou O(n log n) obligatoire

2. ‚úÖ **Quelle op√©ration est la plus fr√©quente ?**
   - Recherche ‚Üí Tri + recherche dichotomique ou table de hachage
   - Insertion/suppression ‚Üí Liste ou arbre √©quilibr√©
   - Acc√®s par index ‚Üí Tableau

3. ‚úÖ **Y a-t-il des contraintes m√©moire ?**
   - Peu de m√©moire ‚Üí Algorithme en place (quicksort vs mergesort)
   - Beaucoup de m√©moire ‚Üí Table de hachage, memoization

4. ‚úÖ **Les donn√©es ont-elles des propri√©t√©s particuli√®res ?**
   - D√©j√† tri√©es ‚Üí Profiter du tri
   - Beaucoup de doublons ‚Üí Compression, table de hachage
   - Pattern pr√©visible ‚Üí Profiter du pattern

5. ‚úÖ **Ai-je besoin de l'optimum ou d'une approximation suffit ?**
   - Optimum ‚Üí Algorithme exact (parfois co√ªteux)
   - Approximation acceptable ‚Üí Algorithme glouton ou heuristique

---

## R√©sum√© des algorithmes par probl√®me

| Probl√®me | Algorithme | Complexit√© | Notes |
|----------|-----------|------------|-------|
| **Tri** | Quicksort, Mergesort | O(n log n) | Utiliser `qsort()` |
| **Recherche (non tri√©)** | Lin√©aire | O(n) | Trier si recherches fr√©quentes |
| **Recherche (tri√©)** | Dichotomique | O(log n) | Tr√®s rapide |
| **Recherche (hash)** | Table de hachage | O(1) | Le plus rapide |
| **Min/Max** | Parcours lin√©aire | O(n) | Optimal |
| **Ki√®me plus petit** | QuickSelect | O(n) en moyenne | Plus rapide que tri complet |
| **Plus court chemin** | Dijkstra | O((V+E) log V) | Graphes pond√©r√©s |
| **Arbre couvrant minimum** | Kruskal, Prim | O(E log V) | Graphes |
| **Multiplication matrices** | Strassen | O(n^2.807) | Pour tr√®s grandes matrices |

---

## Outils pour analyser la complexit√©

### Analyse th√©orique

Compter les op√©rations en fonction de n :

```c
// Exemple
for (int i = 0; i < n; i++) {           // n it√©rations
    for (int j = 0; j < n; j++) {       // n it√©rations
        tableau[i][j] = i + j;          // O(1)
    }
}
// Complexit√© : O(n¬≤)
```

### Analyse empirique

Mesurer le temps d'ex√©cution pour diff√©rentes valeurs de n :

```c
// test_complexite.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

void algorithme(int n) {
    // Votre algorithme ici
}

int main() {
    int tailles[] = {100, 1000, 10000, 100000};

    for (int i = 0; i < 4; i++) {
        int n = tailles[i];

        clock_t debut = clock();
        algorithme(n);
        clock_t fin = clock();

        double temps = (double)(fin - debut) / CLOCKS_PER_SEC;
        printf("n = %6d : %.6f secondes\n", n, temps);
    }

    return 0;
}
```

**Analyser la croissance :**
- Si le temps double quand n double ‚Üí O(n)
- Si le temps quadruple quand n double ‚Üí O(n¬≤)
- Si le temps augmente faiblement ‚Üí O(log n) ou O(n log n)

---

## Erreurs courantes √† √©viter

### ‚ùå Optimiser pr√©matur√©ment

**Probl√®me :** Passer du temps √† micro-optimiser un algorithme O(n) alors qu'un algorithme O(n¬≤) domine le temps d'ex√©cution.

**Solution :** Profiler d'abord, identifier les vrais goulots, puis optimiser.

### ‚ùå Choisir une structure de donn√©es inadapt√©e

**Exemple :** Utiliser une liste cha√Æn√©e pour faire beaucoup d'acc√®s par index.

**Solution :** Choisir la structure selon les op√©rations les plus fr√©quentes.

### ‚ùå Ignorer les constantes et le surco√ªt

Un algorithme O(n log n) avec une grosse constante peut √™tre plus lent qu'un O(n¬≤) bien optimis√© pour de petites valeurs de n.

**Exemple :** Quicksort vs Insertion sort
- Quicksort : O(n log n), mais overhead de r√©cursion
- Insertion sort : O(n¬≤), mais tr√®s rapide pour n < 20

**Solution pratique :** Hybrides comme Timsort (utilis√© en Python) qui combine plusieurs algorithmes selon la taille.

### ‚ùå N√©gliger la localit√© de cache

Un algorithme th√©oriquement optimal mais cache-hostile peut √™tre plus lent qu'un algorithme moins optimal mais cache-friendly.

**Solution :** Consid√©rer aussi les aspects bas-niveau (cf. section 27.4).

---

## Pour aller plus loin

### Livres recommand√©s

- **"Introduction to Algorithms"** (CLRS) ‚Äî Cormen, Leiserson, Rivest, Stein (bible des algorithmes)
- **"The Algorithm Design Manual"** ‚Äî Steven Skiena (plus pratique)
- **"Algorithms"** ‚Äî Robert Sedgewick (avec impl√©mentations en C)
- **"Programming Pearls"** ‚Äî Jon Bentley (optimisations pratiques)

### Ressources en ligne

- **Big-O Cheat Sheet** : https://www.bigocheatsheet.com/
- **VisuAlgo** : https://visualgo.net/ (visualisation d'algorithmes)
- **GeeksforGeeks** : https://www.geeksforgeeks.org/fundamentals-of-algorithms/
- **LeetCode** : https://leetcode.com/ (pratique avec exercices)

### Cours en ligne

- **MIT OpenCourseWare - Introduction to Algorithms**
- **Princeton Algorithms (Coursera)** ‚Äî Robert Sedgewick
- **Khan Academy - Algorithms**

---

## Conclusion

Les optimisations algorithmiques sont le **levier le plus puissant** pour am√©liorer les performances :

1. ‚úÖ **Choisir le bon algorithme** peut vous faire gagner 100-1000x
2. ‚úÖ **Big-O n'est pas tout** : Consid√©rer aussi les constantes, le cache, et les cas pratiques
3. ‚úÖ **Profiler avant d'optimiser** : Ne pas deviner, mesurer !
4. ‚úÖ **Trade-offs** : Temps vs m√©moire, simplicit√© vs performance
5. ‚úÖ **Structures de donn√©es** : Le bon choix est crucial

**Hi√©rarchie des optimisations (rappel) :**

```
1. Algorithme O(n) vs O(n¬≤)        ‚Üí 1000x plus rapide
2. Structure de donn√©es adapt√©e    ‚Üí 100x plus rapide
3. Optimisations cache             ‚Üí 10x plus rapide
4. Flags de compilation (-O2 -O3)  ‚Üí 3x plus rapide
5. Micro-optimisations             ‚Üí 1.5x plus rapide
```

**Citation finale :**

> "The fastest algorithm is the one that never runs" ‚Äî Anonymous

Traduction : Le meilleur algorithme est celui qu'on n'ex√©cute pas ‚Üí √âviter le travail inutile (caching, memoization) est souvent plus efficace que d'optimiser le code !

**R√®gle d'or :** Commencez toujours par le bon algorithme, puis optimisez si n√©cessaire. Ne micro-optimisez jamais un algorithme fondamentalement mauvais !

---

*Prochaine section : 27.7 Vectorisation et SIMD*

‚è≠Ô∏è [Vectorisation et SIMD](/27-optimisation-performance/07-vectorisation-simd.md)
